{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, time, random, keras, pickle, gc\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from face_verification.facenet import basenet\n",
    "from face_verification.facenet import triplet_net\n",
    "from face_verification.facenet import triplet_loss\n",
    "from face_verification.facenet import train_triplet_generator\n",
    "from face_verification.facenet import test_triplet_generator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t# person = 8631\t # images = 2113881\n",
      "Test:\t# person =  500\t # images =  116568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0054_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0029_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0202_02.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0037_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0046_01.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                                          path\n",
       "0  n000002  ./images/vgg2_face/train/n000002/0054_01.jpg\n",
       "1  n000002  ./images/vgg2_face/train/n000002/0029_01.jpg\n",
       "2  n000002  ./images/vgg2_face/train/n000002/0202_02.jpg\n",
       "3  n000002  ./images/vgg2_face/train/n000002/0037_01.jpg\n",
       "4  n000002  ./images/vgg2_face/train/n000002/0046_01.jpg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg2_train = pd.read_csv('./images/vgg2_train_path.csv')\n",
    "vgg2_test = pd.read_csv('./images/vgg2_test_path.csv')\n",
    "\n",
    "print('Train:\\t# person ={0:5d}\\t # images ={1:8d}'.format(len(vgg2_train['name'].unique()), \n",
    "                                                           len(vgg2_train)))\n",
    "print('Test:\\t# person ={0:5d}\\t # images ={1:8d}'.format(len(vgg2_test['name'].unique()),\n",
    "                                                          len(vgg2_test)))\n",
    "\n",
    "vgg2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process the train and test dataframe\n",
    "def path_to_list(df):\n",
    "    \"\"\" function to merge df into the name and path list format \"\"\"\n",
    "    paths = list(df['path'].values)\n",
    "    count = len(paths)\n",
    "    \n",
    "    return pd.Series([count, paths], index=['count', 'paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "      <th>paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n000002</td>\n",
       "      <td>198</td>\n",
       "      <td>[./images/vgg2_face/train/n000002/0054_01.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n000003</td>\n",
       "      <td>143</td>\n",
       "      <td>[./images/vgg2_face/train/n000003/0054_01.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n000004</td>\n",
       "      <td>334</td>\n",
       "      <td>[./images/vgg2_face/train/n000004/0054_01.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n000005</td>\n",
       "      <td>67</td>\n",
       "      <td>[./images/vgg2_face/train/n000005/0430_02.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n000006</td>\n",
       "      <td>374</td>\n",
       "      <td>[./images/vgg2_face/train/n000006/0154_01.jpg,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  count                                              paths\n",
       "0  n000002    198  [./images/vgg2_face/train/n000002/0054_01.jpg,...\n",
       "1  n000003    143  [./images/vgg2_face/train/n000003/0054_01.jpg,...\n",
       "2  n000004    334  [./images/vgg2_face/train/n000004/0054_01.jpg,...\n",
       "3  n000005     67  [./images/vgg2_face/train/n000005/0430_02.jpg,...\n",
       "4  n000006    374  [./images/vgg2_face/train/n000006/0154_01.jpg,..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg2_train_df = vgg2_train.groupby('name').apply(path_to_list).reset_index()\n",
    "vgg2_test_df = vgg2_test.groupby('name').apply(path_to_list).reset_index()\n",
    "\n",
    "vgg2_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Triplet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproduciable purpose\n",
    "seed = 42\n",
    "K.clear_session()\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3148: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 102, 102, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 48, 48, 64)   9472        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 48, 48, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 48, 64)   0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 50, 50, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 24, 24, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lrn_1 (Lambda)                  (None, 24, 24, 64)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 24, 24, 64)   4160        lrn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 24, 24, 64)   256         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 24, 24, 64)   0           bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 26, 26, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 24, 24, 192)  110784      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 24, 24, 192)  768         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 24, 192)  0           bn3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lrn_2 (Lambda)                  (None, 24, 24, 192)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 26, 26, 192)  0           lrn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 192)  0           zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_conv1 (Conv2D) (None, 12, 12, 96)   18528       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_conv1 (Conv2D) (None, 12, 12, 16)   3088        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_bn1 (BatchNorm (None, 12, 12, 16)   64          inception_3a_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 12, 96)   0           inception_3a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 12, 12, 16)   0           inception_3a_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 192)    0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 14, 14, 96)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 16, 16, 16)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_pool_conv (Conv2D) (None, 5, 5, 32)     6176        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_conv2 (Conv2D) (None, 12, 12, 32)   12832       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_pool_bn (BatchNorm (None, 5, 5, 32)     128         inception_3a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_1x1_conv (Conv2D)  (None, 12, 12, 64)   12352       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_bn2 (BatchNorm (None, 12, 12, 32)   128         inception_3a_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5, 5, 32)     0           inception_3a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 12, 12, 128)  0           inception_3a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 12, 12, 32)   0           inception_3a_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 12, 12, 32)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 12, 12, 64)   0           inception_3a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 zero_padding2d_7[0][0]           \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_conv1 (Conv2D) (None, 12, 12, 96)   24672       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_conv1 (Conv2D) (None, 12, 12, 32)   8224        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3b_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 12, 12, 96)   0           inception_3b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 12, 12, 32)   0           inception_3b_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 4, 4, 256)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 14, 14, 96)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 16, 16, 32)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_pool_conv (Conv2D) (None, 4, 4, 64)     16448       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_conv2 (Conv2D) (None, 12, 12, 64)   51264       zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_pool_bn (BatchNorm (None, 4, 4, 64)     256         inception_3b_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_1x1_conv (Conv2D)  (None, 12, 12, 64)   16448       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_bn2 (BatchNorm (None, 12, 12, 64)   256         inception_3b_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 64)     0           inception_3b_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 12, 12, 128)  0           inception_3b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 12, 12, 64)   0           inception_3b_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 12, 12, 64)   0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 12, 12, 64)   0           inception_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 12, 12, 320)  0           activation_11[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "                                                                 zero_padding2d_10[0][0]          \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_conv1 (Conv2D) (None, 12, 12, 128)  41088       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_conv1 (Conv2D) (None, 12, 12, 32)   10272       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_bn1 (BatchNorm (None, 12, 12, 128)  512         inception_3c_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3c_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 12, 12, 128)  0           inception_3c_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 12, 12, 32)   0           inception_3c_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 14, 14, 128)  0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 16, 16, 32)   0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_conv2 (Conv2D) (None, 6, 6, 256)    295168      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_bn2 (BatchNorm (None, 6, 6, 256)    1024        inception_3c_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_3c_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 320)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 6, 6, 256)    0           inception_3c_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 6, 6, 64)     0           inception_3c_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 6, 6, 320)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 6, 6, 640)    0           activation_17[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "                                                                 zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_conv1 (Conv2D) (None, 6, 6, 96)     61536       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_conv1 (Conv2D) (None, 6, 6, 32)     20512       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_bn1 (BatchNorm (None, 6, 6, 96)     384         inception_4a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_bn1 (BatchNorm (None, 6, 6, 32)     128         inception_4a_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 6, 6, 96)     0           inception_4a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 6, 6, 32)     0           inception_4a_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 2, 2, 640)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 8, 8, 96)     0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 10, 10, 32)   0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_pool_conv (Conv2D) (None, 2, 2, 128)    82048       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_conv2 (Conv2D) (None, 6, 6, 192)    166080      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_pool_bn (BatchNorm (None, 2, 2, 128)    512         inception_4a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_1x1_conv (Conv2D)  (None, 6, 6, 256)    164096      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_bn2 (BatchNorm (None, 6, 6, 192)    768         inception_4a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_4a_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 2, 128)    0           inception_4a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_1x1_bn (BatchNorma (None, 6, 6, 256)    1024        inception_4a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 6, 6, 192)    0           inception_4a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 6, 6, 64)     0           inception_4a_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 6, 6, 128)    0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 6, 6, 256)    0           inception_4a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 6, 6, 640)    0           activation_21[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "                                                                 zero_padding2d_16[0][0]          \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_conv1 (Conv2D) (None, 6, 6, 160)    102560      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_conv1 (Conv2D) (None, 6, 6, 64)     41024       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_bn1 (BatchNorm (None, 6, 6, 160)    640         inception_4b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_bn1 (BatchNorm (None, 6, 6, 64)     256         inception_4b_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 6, 6, 160)    0           inception_4b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 6, 6, 64)     0           inception_4b_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 8, 8, 160)    0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 10, 10, 64)   0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_conv2 (Conv2D) (None, 3, 3, 256)    368896      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_conv2 (Conv2D) (None, 3, 3, 128)    204928      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_bn2 (BatchNorm (None, 3, 3, 256)    1024        inception_4b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_bn2 (BatchNorm (None, 3, 3, 128)    512         inception_4b_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 640)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 3, 3, 256)    0           inception_4b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 3, 3, 128)    0           inception_4b_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 3, 3, 640)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 1024)   0           activation_27[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_conv1 (Conv2D) (None, 3, 3, 96)     98400       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 3, 3, 96)     0           inception_5a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 1024)   0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 5, 5, 96)     0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_pool_conv (Conv2D) (None, 1, 1, 96)     98400       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_1x1_conv (Conv2D)  (None, 3, 3, 256)    262400      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 1, 1, 96)     0           inception_5a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 3, 3, 384)    0           inception_5a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 3, 3, 96)     0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 3, 3, 256)    0           inception_5a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 3, 3, 736)    0           activation_31[0][0]              \n",
      "                                                                 zero_padding2d_21[0][0]          \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_conv1 (Conv2D) (None, 3, 3, 96)     70752       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 3, 3, 96)     0           inception_5b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 736)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 5, 5, 96)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_pool_conv (Conv2D) (None, 1, 1, 96)     70752       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5b_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_1x1_conv (Conv2D)  (None, 3, 3, 256)    188672      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1, 1, 96)     0           inception_5b_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 3, 3, 384)    0           inception_5b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 3, 3, 96)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 3, 3, 256)    0           inception_5b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 3, 3, 736)    0           activation_35[0][0]              \n",
      "                                                                 zero_padding2d_23[0][0]          \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 736)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 736)          0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 128)          94336       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "norm_layer (Lambda)             (None, 128)          0           dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,743,280\n",
      "Trainable params: 3,733,968\n",
      "Non-trainable params: 9,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the base-cnn model\n",
    "base_model = basenet(output_shape=128)\n",
    "\n",
    "# # visualization\n",
    "# plot_model(base_model, show_shapes=True, to_file='./results/base-model.png')\n",
    "# plot_model(base_model, show_shapes=True, to_file='./results/base-model.pdf')\n",
    "\n",
    "# base-model summary\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 128)          3743280     anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Lambda)                 (None, 3, 128)       0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,743,280\n",
      "Trainable params: 3,733,968\n",
      "Non-trainable params: 9,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the triplet-network model\n",
    "triplet_model = triplet_net(base_model=base_model, input_shape=(96, 96, 3))\n",
    "\n",
    "# # visualization\n",
    "# plot_model(triplet_model, show_shapes=True, to_file='./results/triplet-model.png')\n",
    "# plot_model(triplet_model, show_shapes=True, to_file='./results/triplet-model.pdf')\n",
    "\n",
    "# base-model summary\n",
    "triplet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define learning scheduler\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\" Learning rate schedule \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 900:\n",
    "        lr *= 1e-1\n",
    "    elif epoch > 800:\n",
    "        lr *= 2e-1\n",
    "    elif epoch > 700:\n",
    "        lr *= 3e-1\n",
    "    elif epoch > 600:\n",
    "        lr *= 4e-1\n",
    "    elif epoch > 500:\n",
    "        lr *= 5e-1\n",
    "    elif epoch > 400:\n",
    "        lr *= 6e-1\n",
    "    elif epoch > 300:\n",
    "        lr *= 7e-1\n",
    "    elif epoch > 200:\n",
    "        lr *= 8e-1\n",
    "    elif epoch > 100:\n",
    "        lr *= 9e-1\n",
    "        \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoing Folder:\t ./models/margin-04-20180805-0307\n"
     ]
    }
   ],
   "source": [
    "# define optimizer\n",
    "opt = keras.optimizers.Adam(lr=lr_schedule(0))\n",
    "\n",
    "# create checkpoint folder\n",
    "path = './models/margin-04-' + time.strftime('%Y%m%d-%H%M')\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "print('Checkpoing Folder:\\t', path)    \n",
    "\n",
    "# create call backs\n",
    "checkpoint = ModelCheckpoint(filepath=path + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                             monitor='val_loss', verbose=0, save_best_only=False, \n",
    "                             save_weights_only=False, mode='auto', period=10)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# compile the model\n",
    "triplet_model.compile(optimizer=opt, loss=triplet_loss(0.4))\n",
    "\n",
    "# define training and test dataset image generator\n",
    "train_generator = train_triplet_generator(vgg2_train_df, batch_size=128)\n",
    "test_generator = test_triplet_generator(vgg2_test_df, batch_size=100, loops=10, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 124s - loss: 40.0089 - val_loss: 31.5086\n",
      "Epoch 2/1000\n",
      " - 107s - loss: 32.6067 - val_loss: 32.3811\n",
      "Epoch 3/1000\n",
      " - 103s - loss: 28.6594 - val_loss: 31.6191\n",
      "Epoch 4/1000\n",
      " - 103s - loss: 26.1724 - val_loss: 25.2402\n",
      "Epoch 5/1000\n",
      " - 102s - loss: 23.8639 - val_loss: 25.4233\n",
      "Epoch 6/1000\n",
      " - 104s - loss: 22.7689 - val_loss: 25.3402\n",
      "Epoch 7/1000\n",
      " - 101s - loss: 22.0094 - val_loss: 26.1359\n",
      "Epoch 8/1000\n",
      " - 101s - loss: 20.9979 - val_loss: 22.4610\n",
      "Epoch 9/1000\n",
      " - 100s - loss: 20.6865 - val_loss: 25.9964\n",
      "Epoch 10/1000\n",
      " - 101s - loss: 20.1298 - val_loss: 20.8170\n",
      "Epoch 11/1000\n",
      " - 100s - loss: 19.3858 - val_loss: 16.5570\n",
      "Epoch 12/1000\n",
      " - 99s - loss: 19.2461 - val_loss: 18.6117\n",
      "Epoch 13/1000\n",
      " - 101s - loss: 18.5327 - val_loss: 28.4599\n",
      "Epoch 14/1000\n",
      " - 98s - loss: 18.5019 - val_loss: 23.6473\n",
      "Epoch 15/1000\n",
      " - 98s - loss: 18.3653 - val_loss: 19.4087\n",
      "Epoch 16/1000\n",
      " - 98s - loss: 17.5659 - val_loss: 16.8669\n",
      "Epoch 17/1000\n",
      " - 98s - loss: 16.7823 - val_loss: 14.8842\n",
      "Epoch 18/1000\n",
      " - 97s - loss: 16.8024 - val_loss: 14.7542\n",
      "Epoch 19/1000\n",
      " - 99s - loss: 16.7425 - val_loss: 20.7608\n",
      "Epoch 20/1000\n",
      " - 97s - loss: 17.3573 - val_loss: 15.5193\n",
      "Epoch 21/1000\n",
      " - 98s - loss: 16.7101 - val_loss: 15.2396\n",
      "Epoch 22/1000\n",
      " - 98s - loss: 15.5028 - val_loss: 18.1193\n",
      "Epoch 23/1000\n",
      " - 97s - loss: 15.8407 - val_loss: 14.2633\n",
      "Epoch 24/1000\n",
      " - 98s - loss: 16.1651 - val_loss: 16.1217\n",
      "Epoch 25/1000\n",
      " - 97s - loss: 15.0401 - val_loss: 14.3329\n",
      "Epoch 26/1000\n",
      " - 98s - loss: 14.7223 - val_loss: 14.2199\n",
      "Epoch 27/1000\n",
      " - 98s - loss: 14.8768 - val_loss: 13.0246\n",
      "Epoch 28/1000\n",
      " - 97s - loss: 14.8045 - val_loss: 14.5724\n",
      "Epoch 29/1000\n",
      " - 97s - loss: 14.7225 - val_loss: 12.3099\n",
      "Epoch 30/1000\n",
      " - 97s - loss: 13.8224 - val_loss: 12.9567\n",
      "Epoch 31/1000\n",
      " - 97s - loss: 13.6238 - val_loss: 13.6821\n",
      "Epoch 32/1000\n",
      " - 98s - loss: 14.0241 - val_loss: 15.1367\n",
      "Epoch 33/1000\n",
      " - 97s - loss: 13.4400 - val_loss: 14.8713\n",
      "Epoch 34/1000\n",
      " - 98s - loss: 13.6821 - val_loss: 13.5895\n",
      "Epoch 35/1000\n",
      " - 97s - loss: 13.2837 - val_loss: 11.8123\n",
      "Epoch 36/1000\n",
      " - 96s - loss: 13.8874 - val_loss: 13.1653\n",
      "Epoch 37/1000\n",
      " - 97s - loss: 13.4474 - val_loss: 12.1690\n",
      "Epoch 38/1000\n",
      " - 97s - loss: 13.8512 - val_loss: 14.0536\n",
      "Epoch 39/1000\n",
      " - 97s - loss: 13.3742 - val_loss: 12.9456\n",
      "Epoch 40/1000\n",
      " - 97s - loss: 13.5767 - val_loss: 11.0029\n",
      "Epoch 41/1000\n",
      " - 97s - loss: 13.2533 - val_loss: 10.9735\n",
      "Epoch 42/1000\n",
      " - 97s - loss: 13.2088 - val_loss: 10.8442\n",
      "Epoch 43/1000\n",
      " - 97s - loss: 12.7666 - val_loss: 11.5528\n",
      "Epoch 44/1000\n",
      " - 97s - loss: 12.3223 - val_loss: 14.0842\n",
      "Epoch 45/1000\n",
      " - 97s - loss: 12.0241 - val_loss: 10.6559\n",
      "Epoch 46/1000\n",
      " - 97s - loss: 12.6455 - val_loss: 11.8673\n",
      "Epoch 47/1000\n",
      " - 98s - loss: 12.2175 - val_loss: 11.7779\n",
      "Epoch 48/1000\n",
      " - 98s - loss: 12.2833 - val_loss: 11.9134\n",
      "Epoch 49/1000\n",
      " - 97s - loss: 12.7678 - val_loss: 12.3402\n",
      "Epoch 50/1000\n",
      " - 98s - loss: 11.9258 - val_loss: 10.9515\n",
      "Epoch 51/1000\n",
      " - 97s - loss: 11.6437 - val_loss: 11.4186\n",
      "Epoch 52/1000\n",
      " - 98s - loss: 12.2222 - val_loss: 11.1423\n",
      "Epoch 53/1000\n",
      " - 97s - loss: 12.2752 - val_loss: 11.8163\n",
      "Epoch 54/1000\n",
      " - 97s - loss: 12.1468 - val_loss: 9.5191\n",
      "Epoch 55/1000\n",
      " - 97s - loss: 12.0114 - val_loss: 12.2832\n",
      "Epoch 56/1000\n",
      " - 98s - loss: 11.6405 - val_loss: 11.8962\n",
      "Epoch 57/1000\n",
      " - 97s - loss: 11.4406 - val_loss: 10.6309\n",
      "Epoch 58/1000\n",
      " - 97s - loss: 11.0586 - val_loss: 11.8552\n",
      "Epoch 59/1000\n",
      " - 97s - loss: 11.5263 - val_loss: 10.6418\n",
      "Epoch 60/1000\n",
      " - 98s - loss: 11.4106 - val_loss: 9.8949\n",
      "Epoch 61/1000\n",
      " - 97s - loss: 11.2411 - val_loss: 12.6909\n",
      "Epoch 62/1000\n",
      " - 97s - loss: 11.1974 - val_loss: 10.3059\n",
      "Epoch 63/1000\n",
      " - 97s - loss: 11.5135 - val_loss: 11.9545\n",
      "Epoch 64/1000\n",
      " - 97s - loss: 11.3424 - val_loss: 11.0806\n",
      "Epoch 65/1000\n",
      " - 97s - loss: 11.1436 - val_loss: 11.9828\n",
      "Epoch 66/1000\n",
      " - 98s - loss: 11.8228 - val_loss: 12.0649\n",
      "Epoch 67/1000\n",
      " - 97s - loss: 10.6264 - val_loss: 8.7789\n",
      "Epoch 68/1000\n",
      " - 97s - loss: 11.4049 - val_loss: 11.7769\n",
      "Epoch 69/1000\n",
      " - 98s - loss: 10.7048 - val_loss: 14.0198\n",
      "Epoch 70/1000\n",
      " - 98s - loss: 11.0179 - val_loss: 11.8080\n",
      "Epoch 71/1000\n",
      " - 97s - loss: 10.9457 - val_loss: 10.1291\n",
      "Epoch 72/1000\n",
      " - 98s - loss: 10.7562 - val_loss: 11.0663\n",
      "Epoch 73/1000\n",
      " - 97s - loss: 10.7969 - val_loss: 9.4399\n",
      "Epoch 74/1000\n",
      " - 97s - loss: 11.2817 - val_loss: 9.5794\n",
      "Epoch 75/1000\n",
      " - 98s - loss: 10.6872 - val_loss: 9.9800\n",
      "Epoch 76/1000\n",
      " - 97s - loss: 10.8893 - val_loss: 11.0644\n",
      "Epoch 77/1000\n",
      " - 97s - loss: 10.8860 - val_loss: 9.2628\n",
      "Epoch 78/1000\n",
      " - 97s - loss: 10.7682 - val_loss: 10.7582\n",
      "Epoch 79/1000\n",
      " - 98s - loss: 10.7705 - val_loss: 9.2364\n",
      "Epoch 80/1000\n",
      " - 97s - loss: 10.7554 - val_loss: 9.9678\n",
      "Epoch 81/1000\n",
      " - 97s - loss: 10.9456 - val_loss: 10.1214\n",
      "Epoch 82/1000\n",
      " - 97s - loss: 10.1832 - val_loss: 10.1881\n",
      "Epoch 83/1000\n",
      " - 97s - loss: 10.2337 - val_loss: 7.7644\n",
      "Epoch 84/1000\n",
      " - 97s - loss: 10.6840 - val_loss: 10.8382\n",
      "Epoch 85/1000\n",
      " - 97s - loss: 10.5881 - val_loss: 11.6990\n",
      "Epoch 86/1000\n",
      " - 97s - loss: 10.6977 - val_loss: 9.2111\n",
      "Epoch 87/1000\n",
      " - 98s - loss: 9.6775 - val_loss: 9.7881\n",
      "Epoch 88/1000\n",
      " - 98s - loss: 10.5575 - val_loss: 9.6321\n",
      "Epoch 89/1000\n",
      " - 97s - loss: 10.8191 - val_loss: 14.5889\n",
      "Epoch 90/1000\n",
      " - 98s - loss: 10.5261 - val_loss: 10.2470\n",
      "Epoch 91/1000\n",
      " - 97s - loss: 10.0731 - val_loss: 9.9778\n",
      "Epoch 92/1000\n",
      " - 98s - loss: 9.9322 - val_loss: 12.5125\n",
      "Epoch 93/1000\n",
      " - 97s - loss: 10.0532 - val_loss: 9.9542\n",
      "Epoch 94/1000\n",
      " - 97s - loss: 9.7427 - val_loss: 9.1869\n",
      "Epoch 95/1000\n",
      " - 96s - loss: 9.9352 - val_loss: 9.4264\n",
      "Epoch 96/1000\n",
      " - 97s - loss: 9.9944 - val_loss: 9.2708\n",
      "Epoch 97/1000\n",
      " - 97s - loss: 9.8329 - val_loss: 8.9500\n",
      "Epoch 98/1000\n",
      " - 98s - loss: 9.4864 - val_loss: 10.3171\n",
      "Epoch 99/1000\n",
      " - 98s - loss: 9.8615 - val_loss: 9.4148\n",
      "Epoch 100/1000\n",
      " - 97s - loss: 9.5414 - val_loss: 10.1721\n",
      "Epoch 101/1000\n",
      " - 97s - loss: 9.6271 - val_loss: 10.0592\n",
      "Epoch 102/1000\n",
      " - 97s - loss: 9.9405 - val_loss: 10.1649\n",
      "Epoch 103/1000\n",
      " - 97s - loss: 9.2708 - val_loss: 8.5720\n",
      "Epoch 104/1000\n",
      " - 97s - loss: 8.9919 - val_loss: 8.7338\n",
      "Epoch 105/1000\n",
      " - 97s - loss: 9.8148 - val_loss: 8.8307\n",
      "Epoch 106/1000\n",
      " - 98s - loss: 9.2092 - val_loss: 8.9170\n",
      "Epoch 107/1000\n",
      " - 97s - loss: 8.7202 - val_loss: 8.9276\n",
      "Epoch 108/1000\n",
      " - 97s - loss: 9.6051 - val_loss: 9.6933\n",
      "Epoch 109/1000\n",
      " - 97s - loss: 9.4978 - val_loss: 8.7815\n",
      "Epoch 110/1000\n",
      " - 97s - loss: 9.5501 - val_loss: 8.5840\n",
      "Epoch 111/1000\n",
      " - 97s - loss: 9.3120 - val_loss: 10.5901\n",
      "Epoch 112/1000\n",
      " - 97s - loss: 9.0836 - val_loss: 8.7662\n",
      "Epoch 113/1000\n",
      " - 97s - loss: 9.6078 - val_loss: 8.4302\n",
      "Epoch 114/1000\n",
      " - 97s - loss: 9.2201 - val_loss: 8.6508\n",
      "Epoch 115/1000\n",
      " - 97s - loss: 9.3884 - val_loss: 9.7809\n",
      "Epoch 116/1000\n",
      " - 97s - loss: 9.3515 - val_loss: 10.5131\n",
      "Epoch 117/1000\n",
      " - 97s - loss: 9.2882 - val_loss: 8.6080\n",
      "Epoch 118/1000\n",
      " - 97s - loss: 8.6663 - val_loss: 8.6287\n",
      "Epoch 119/1000\n",
      " - 97s - loss: 8.9373 - val_loss: 8.3465\n",
      "Epoch 120/1000\n",
      " - 97s - loss: 9.2251 - val_loss: 9.0618\n",
      "Epoch 121/1000\n",
      " - 97s - loss: 8.6692 - val_loss: 7.5885\n",
      "Epoch 122/1000\n",
      " - 97s - loss: 8.9619 - val_loss: 8.3908\n",
      "Epoch 123/1000\n",
      " - 97s - loss: 8.7436 - val_loss: 8.6658\n",
      "Epoch 124/1000\n",
      " - 97s - loss: 9.1444 - val_loss: 8.4602\n",
      "Epoch 125/1000\n",
      " - 96s - loss: 9.1412 - val_loss: 7.0764\n",
      "Epoch 126/1000\n",
      " - 97s - loss: 8.6401 - val_loss: 8.4678\n",
      "Epoch 127/1000\n",
      " - 97s - loss: 9.0594 - val_loss: 11.4116\n",
      "Epoch 128/1000\n",
      " - 97s - loss: 8.9988 - val_loss: 8.6571\n",
      "Epoch 129/1000\n",
      " - 97s - loss: 9.2193 - val_loss: 7.3311\n",
      "Epoch 130/1000\n",
      " - 97s - loss: 8.3191 - val_loss: 9.7520\n",
      "Epoch 131/1000\n",
      " - 97s - loss: 9.0314 - val_loss: 10.7473\n",
      "Epoch 132/1000\n",
      " - 97s - loss: 8.7086 - val_loss: 7.3711\n",
      "Epoch 133/1000\n",
      " - 97s - loss: 8.4804 - val_loss: 7.4298\n",
      "Epoch 134/1000\n",
      " - 97s - loss: 8.4888 - val_loss: 7.9702\n",
      "Epoch 135/1000\n",
      " - 97s - loss: 8.1927 - val_loss: 9.0167\n",
      "Epoch 136/1000\n",
      " - 97s - loss: 8.4428 - val_loss: 9.2224\n",
      "Epoch 137/1000\n",
      " - 97s - loss: 8.3724 - val_loss: 8.7491\n",
      "Epoch 138/1000\n",
      " - 97s - loss: 8.7118 - val_loss: 8.2048\n",
      "Epoch 139/1000\n",
      " - 97s - loss: 8.7937 - val_loss: 9.4463\n",
      "Epoch 140/1000\n",
      " - 97s - loss: 8.5510 - val_loss: 8.1294\n",
      "Epoch 141/1000\n",
      " - 97s - loss: 8.4967 - val_loss: 8.1759\n",
      "Epoch 142/1000\n",
      " - 97s - loss: 8.7004 - val_loss: 7.5779\n",
      "Epoch 143/1000\n",
      " - 97s - loss: 7.7354 - val_loss: 8.1611\n",
      "Epoch 144/1000\n",
      " - 97s - loss: 7.9111 - val_loss: 8.3510\n",
      "Epoch 145/1000\n",
      " - 97s - loss: 8.3922 - val_loss: 8.4210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      " - 97s - loss: 8.0648 - val_loss: 7.9215\n",
      "Epoch 147/1000\n",
      " - 98s - loss: 8.3520 - val_loss: 7.2693\n",
      "Epoch 148/1000\n",
      " - 96s - loss: 8.7528 - val_loss: 7.5097\n",
      "Epoch 149/1000\n",
      " - 97s - loss: 8.5136 - val_loss: 8.1548\n",
      "Epoch 150/1000\n",
      " - 97s - loss: 8.2884 - val_loss: 8.3431\n",
      "Epoch 151/1000\n",
      " - 97s - loss: 8.6452 - val_loss: 8.9640\n",
      "Epoch 152/1000\n",
      " - 97s - loss: 8.5878 - val_loss: 8.5065\n",
      "Epoch 153/1000\n",
      " - 97s - loss: 8.8431 - val_loss: 7.9941\n",
      "Epoch 154/1000\n",
      " - 97s - loss: 7.8667 - val_loss: 7.3447\n",
      "Epoch 155/1000\n",
      " - 97s - loss: 8.1747 - val_loss: 7.3608\n",
      "Epoch 156/1000\n",
      " - 96s - loss: 8.1328 - val_loss: 8.5627\n",
      "Epoch 157/1000\n",
      " - 97s - loss: 8.3157 - val_loss: 7.7723\n",
      "Epoch 158/1000\n",
      " - 97s - loss: 8.1300 - val_loss: 6.5810\n",
      "Epoch 159/1000\n",
      " - 97s - loss: 8.1348 - val_loss: 6.7459\n",
      "Epoch 160/1000\n",
      " - 97s - loss: 8.2319 - val_loss: 12.1413\n",
      "Epoch 161/1000\n",
      " - 97s - loss: 8.0119 - val_loss: 8.0014\n",
      "Epoch 162/1000\n",
      " - 97s - loss: 8.0255 - val_loss: 9.2457\n",
      "Epoch 163/1000\n",
      " - 97s - loss: 8.0321 - val_loss: 8.2676\n",
      "Epoch 164/1000\n",
      " - 97s - loss: 7.8495 - val_loss: 7.1463\n",
      "Epoch 165/1000\n",
      " - 97s - loss: 8.2104 - val_loss: 7.9288\n",
      "Epoch 166/1000\n",
      " - 97s - loss: 8.0482 - val_loss: 7.0086\n",
      "Epoch 167/1000\n",
      " - 97s - loss: 8.0220 - val_loss: 8.0538\n",
      "Epoch 168/1000\n",
      " - 97s - loss: 7.9076 - val_loss: 8.1247\n",
      "Epoch 169/1000\n",
      " - 97s - loss: 8.0466 - val_loss: 7.3898\n",
      "Epoch 170/1000\n",
      " - 97s - loss: 8.0649 - val_loss: 8.4136\n",
      "Epoch 171/1000\n",
      " - 97s - loss: 8.2786 - val_loss: 7.3050\n",
      "Epoch 172/1000\n",
      " - 97s - loss: 7.9409 - val_loss: 7.2114\n",
      "Epoch 173/1000\n",
      " - 97s - loss: 7.8218 - val_loss: 7.8063\n",
      "Epoch 174/1000\n",
      " - 97s - loss: 8.0367 - val_loss: 8.0654\n",
      "Epoch 175/1000\n",
      " - 97s - loss: 7.5764 - val_loss: 7.4573\n",
      "Epoch 176/1000\n",
      " - 97s - loss: 8.1243 - val_loss: 7.6925\n",
      "Epoch 177/1000\n",
      " - 97s - loss: 7.5908 - val_loss: 7.9845\n",
      "Epoch 178/1000\n",
      " - 97s - loss: 7.6877 - val_loss: 8.1953\n",
      "Epoch 179/1000\n",
      " - 97s - loss: 7.6706 - val_loss: 7.7118\n",
      "Epoch 180/1000\n",
      " - 97s - loss: 7.9269 - val_loss: 7.1912\n",
      "Epoch 181/1000\n",
      " - 97s - loss: 7.8222 - val_loss: 7.7251\n",
      "Epoch 182/1000\n",
      " - 97s - loss: 8.0222 - val_loss: 7.8827\n",
      "Epoch 183/1000\n",
      " - 98s - loss: 8.2543 - val_loss: 7.6281\n",
      "Epoch 184/1000\n",
      " - 97s - loss: 7.7368 - val_loss: 7.3791\n",
      "Epoch 185/1000\n",
      " - 97s - loss: 7.5203 - val_loss: 7.4426\n",
      "Epoch 186/1000\n",
      " - 97s - loss: 7.9218 - val_loss: 9.5626\n",
      "Epoch 187/1000\n",
      " - 97s - loss: 7.8704 - val_loss: 6.7610\n",
      "Epoch 188/1000\n",
      " - 96s - loss: 7.6920 - val_loss: 7.7357\n",
      "Epoch 189/1000\n",
      " - 96s - loss: 7.3874 - val_loss: 7.2709\n",
      "Epoch 190/1000\n",
      " - 97s - loss: 7.6376 - val_loss: 7.4392\n",
      "Epoch 191/1000\n",
      " - 97s - loss: 7.0987 - val_loss: 6.2624\n",
      "Epoch 192/1000\n",
      " - 97s - loss: 7.3640 - val_loss: 6.6746\n",
      "Epoch 193/1000\n",
      " - 96s - loss: 7.8169 - val_loss: 7.6683\n",
      "Epoch 194/1000\n",
      " - 96s - loss: 7.3658 - val_loss: 8.2503\n",
      "Epoch 195/1000\n",
      " - 96s - loss: 7.6011 - val_loss: 7.6705\n",
      "Epoch 196/1000\n",
      " - 97s - loss: 8.0086 - val_loss: 7.9184\n",
      "Epoch 197/1000\n",
      " - 96s - loss: 7.7962 - val_loss: 8.4363\n",
      "Epoch 198/1000\n",
      " - 97s - loss: 7.8488 - val_loss: 7.1466\n",
      "Epoch 199/1000\n",
      " - 96s - loss: 7.6298 - val_loss: 7.7333\n",
      "Epoch 200/1000\n",
      " - 96s - loss: 7.4222 - val_loss: 6.9922\n",
      "Epoch 201/1000\n",
      " - 96s - loss: 7.3942 - val_loss: 7.5728\n",
      "Epoch 202/1000\n",
      " - 97s - loss: 7.3411 - val_loss: 6.5544\n",
      "Epoch 203/1000\n",
      " - 96s - loss: 7.3559 - val_loss: 7.7771\n",
      "Epoch 204/1000\n",
      " - 97s - loss: 7.4221 - val_loss: 8.2215\n",
      "Epoch 205/1000\n",
      " - 96s - loss: 7.5384 - val_loss: 6.3359\n",
      "Epoch 206/1000\n",
      " - 97s - loss: 7.7713 - val_loss: 7.0644\n",
      "Epoch 207/1000\n",
      " - 96s - loss: 7.4025 - val_loss: 9.1093\n",
      "Epoch 208/1000\n",
      " - 97s - loss: 7.2424 - val_loss: 6.3485\n",
      "Epoch 209/1000\n",
      " - 96s - loss: 7.6402 - val_loss: 6.6595\n",
      "Epoch 210/1000\n",
      " - 97s - loss: 7.1483 - val_loss: 6.3638\n",
      "Epoch 211/1000\n",
      " - 97s - loss: 7.5330 - val_loss: 7.3454\n",
      "Epoch 212/1000\n",
      " - 97s - loss: 7.3175 - val_loss: 6.6258\n",
      "Epoch 213/1000\n",
      " - 97s - loss: 7.7625 - val_loss: 6.7858\n",
      "Epoch 214/1000\n",
      " - 97s - loss: 6.4396 - val_loss: 6.2338\n",
      "Epoch 215/1000\n",
      " - 97s - loss: 7.5162 - val_loss: 7.0272\n",
      "Epoch 216/1000\n",
      " - 97s - loss: 7.2346 - val_loss: 6.9356\n",
      "Epoch 217/1000\n",
      " - 98s - loss: 7.1173 - val_loss: 7.9495\n",
      "Epoch 218/1000\n",
      " - 97s - loss: 7.0052 - val_loss: 6.5279\n",
      "Epoch 219/1000\n",
      " - 97s - loss: 7.2609 - val_loss: 8.0996\n",
      "Epoch 220/1000\n",
      " - 97s - loss: 7.3715 - val_loss: 7.1711\n",
      "Epoch 221/1000\n",
      " - 97s - loss: 7.3796 - val_loss: 6.1209\n",
      "Epoch 222/1000\n",
      " - 97s - loss: 7.4645 - val_loss: 6.2482\n",
      "Epoch 223/1000\n",
      " - 97s - loss: 7.3707 - val_loss: 7.5003\n",
      "Epoch 224/1000\n",
      " - 98s - loss: 7.4452 - val_loss: 8.3642\n",
      "Epoch 225/1000\n",
      " - 97s - loss: 7.2552 - val_loss: 7.2205\n",
      "Epoch 226/1000\n",
      " - 97s - loss: 7.3487 - val_loss: 6.3674\n",
      "Epoch 227/1000\n",
      " - 97s - loss: 7.1623 - val_loss: 6.6839\n",
      "Epoch 228/1000\n",
      " - 97s - loss: 6.9858 - val_loss: 7.0507\n",
      "Epoch 229/1000\n",
      " - 97s - loss: 6.7777 - val_loss: 7.4264\n",
      "Epoch 230/1000\n",
      " - 97s - loss: 7.3882 - val_loss: 6.4291\n",
      "Epoch 231/1000\n",
      " - 96s - loss: 6.7524 - val_loss: 7.0239\n",
      "Epoch 232/1000\n",
      " - 97s - loss: 6.2932 - val_loss: 6.6881\n",
      "Epoch 233/1000\n",
      " - 97s - loss: 6.9820 - val_loss: 6.7246\n",
      "Epoch 234/1000\n",
      " - 97s - loss: 6.9761 - val_loss: 7.3145\n",
      "Epoch 235/1000\n",
      " - 96s - loss: 7.1227 - val_loss: 6.6862\n",
      "Epoch 236/1000\n",
      " - 97s - loss: 7.2006 - val_loss: 6.4725\n",
      "Epoch 237/1000\n",
      " - 96s - loss: 6.8119 - val_loss: 6.6230\n",
      "Epoch 238/1000\n",
      " - 97s - loss: 6.6923 - val_loss: 6.2492\n",
      "Epoch 239/1000\n",
      " - 97s - loss: 6.6293 - val_loss: 7.2083\n",
      "Epoch 240/1000\n",
      " - 97s - loss: 6.9894 - val_loss: 6.8687\n",
      "Epoch 241/1000\n",
      " - 97s - loss: 7.2194 - val_loss: 7.5023\n",
      "Epoch 242/1000\n",
      " - 96s - loss: 7.2360 - val_loss: 7.3902\n",
      "Epoch 243/1000\n",
      " - 97s - loss: 6.7863 - val_loss: 6.8748\n",
      "Epoch 244/1000\n",
      " - 96s - loss: 6.9032 - val_loss: 6.5230\n",
      "Epoch 245/1000\n",
      " - 97s - loss: 7.2233 - val_loss: 7.1534\n",
      "Epoch 246/1000\n",
      " - 97s - loss: 6.9968 - val_loss: 6.2652\n",
      "Epoch 247/1000\n",
      " - 97s - loss: 7.1232 - val_loss: 6.9144\n",
      "Epoch 248/1000\n",
      " - 96s - loss: 6.8832 - val_loss: 7.4347\n",
      "Epoch 249/1000\n",
      " - 97s - loss: 6.9199 - val_loss: 6.7000\n",
      "Epoch 250/1000\n",
      " - 97s - loss: 7.2145 - val_loss: 6.6702\n",
      "Epoch 251/1000\n",
      " - 97s - loss: 6.8979 - val_loss: 7.1780\n",
      "Epoch 252/1000\n",
      " - 97s - loss: 7.1145 - val_loss: 6.9368\n",
      "Epoch 253/1000\n",
      " - 96s - loss: 6.7328 - val_loss: 6.1408\n",
      "Epoch 254/1000\n",
      " - 97s - loss: 7.0602 - val_loss: 7.3099\n",
      "Epoch 255/1000\n",
      " - 97s - loss: 7.2645 - val_loss: 7.3021\n",
      "Epoch 256/1000\n",
      " - 97s - loss: 6.8261 - val_loss: 6.6614\n",
      "Epoch 257/1000\n",
      " - 96s - loss: 6.8467 - val_loss: 6.1939\n",
      "Epoch 258/1000\n",
      " - 97s - loss: 6.8215 - val_loss: 6.1011\n",
      "Epoch 259/1000\n",
      " - 97s - loss: 6.9829 - val_loss: 6.4304\n",
      "Epoch 260/1000\n",
      " - 97s - loss: 6.5664 - val_loss: 6.5264\n",
      "Epoch 261/1000\n",
      " - 97s - loss: 6.6347 - val_loss: 7.2906\n",
      "Epoch 262/1000\n",
      " - 97s - loss: 6.7113 - val_loss: 7.3378\n",
      "Epoch 263/1000\n",
      " - 97s - loss: 7.0029 - val_loss: 6.2816\n",
      "Epoch 264/1000\n",
      " - 96s - loss: 6.3726 - val_loss: 5.8519\n",
      "Epoch 265/1000\n",
      " - 97s - loss: 6.8084 - val_loss: 6.2275\n",
      "Epoch 266/1000\n",
      " - 96s - loss: 6.6138 - val_loss: 7.7106\n",
      "Epoch 267/1000\n",
      " - 97s - loss: 6.6435 - val_loss: 6.8689\n",
      "Epoch 268/1000\n",
      " - 97s - loss: 6.9729 - val_loss: 6.3008\n",
      "Epoch 269/1000\n",
      " - 97s - loss: 6.6534 - val_loss: 6.4817\n",
      "Epoch 270/1000\n",
      " - 97s - loss: 6.3835 - val_loss: 6.2091\n",
      "Epoch 271/1000\n",
      " - 97s - loss: 6.5846 - val_loss: 5.7157\n",
      "Epoch 272/1000\n",
      " - 96s - loss: 6.9368 - val_loss: 6.3873\n",
      "Epoch 273/1000\n",
      " - 97s - loss: 6.8267 - val_loss: 6.2417\n",
      "Epoch 274/1000\n",
      " - 97s - loss: 6.8599 - val_loss: 6.3703\n",
      "Epoch 275/1000\n",
      " - 97s - loss: 6.5257 - val_loss: 6.0480\n",
      "Epoch 276/1000\n",
      " - 97s - loss: 6.1861 - val_loss: 5.9804\n",
      "Epoch 277/1000\n",
      " - 97s - loss: 6.6308 - val_loss: 5.3338\n",
      "Epoch 278/1000\n",
      " - 97s - loss: 6.5315 - val_loss: 6.4237\n",
      "Epoch 279/1000\n",
      " - 97s - loss: 6.6200 - val_loss: 5.5221\n",
      "Epoch 280/1000\n",
      " - 97s - loss: 6.9203 - val_loss: 7.3730\n",
      "Epoch 281/1000\n",
      " - 96s - loss: 6.6845 - val_loss: 5.8655\n",
      "Epoch 282/1000\n",
      " - 97s - loss: 6.1739 - val_loss: 8.5969\n",
      "Epoch 283/1000\n",
      " - 97s - loss: 6.5996 - val_loss: 5.7642\n",
      "Epoch 284/1000\n",
      " - 97s - loss: 6.3962 - val_loss: 7.0096\n",
      "Epoch 285/1000\n",
      " - 97s - loss: 6.6662 - val_loss: 6.8775\n",
      "Epoch 286/1000\n",
      " - 97s - loss: 7.0932 - val_loss: 7.4874\n",
      "Epoch 287/1000\n",
      " - 97s - loss: 6.4771 - val_loss: 6.0771\n",
      "Epoch 288/1000\n",
      " - 97s - loss: 6.4819 - val_loss: 5.9870\n",
      "Epoch 289/1000\n",
      " - 97s - loss: 6.1826 - val_loss: 5.8715\n",
      "Epoch 290/1000\n",
      " - 96s - loss: 6.6543 - val_loss: 6.7038\n",
      "Epoch 291/1000\n",
      " - 97s - loss: 6.5724 - val_loss: 6.3322\n",
      "Epoch 292/1000\n",
      " - 97s - loss: 6.7055 - val_loss: 6.0954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      " - 96s - loss: 6.3306 - val_loss: 6.6296\n",
      "Epoch 294/1000\n",
      " - 97s - loss: 6.2931 - val_loss: 6.4828\n",
      "Epoch 295/1000\n",
      " - 96s - loss: 5.8558 - val_loss: 6.5538\n",
      "Epoch 296/1000\n",
      " - 97s - loss: 6.2583 - val_loss: 6.3919\n",
      "Epoch 297/1000\n",
      " - 97s - loss: 6.6240 - val_loss: 6.7393\n",
      "Epoch 298/1000\n",
      " - 97s - loss: 6.1230 - val_loss: 6.5907\n",
      "Epoch 299/1000\n",
      " - 96s - loss: 6.1465 - val_loss: 5.6400\n",
      "Epoch 300/1000\n",
      " - 97s - loss: 6.7429 - val_loss: 6.4782\n",
      "Epoch 301/1000\n",
      " - 97s - loss: 6.5322 - val_loss: 6.1781\n",
      "Epoch 302/1000\n",
      " - 97s - loss: 6.7549 - val_loss: 6.2731\n",
      "Epoch 303/1000\n",
      " - 97s - loss: 6.3642 - val_loss: 5.4806\n",
      "Epoch 304/1000\n",
      " - 97s - loss: 6.3453 - val_loss: 6.0490\n",
      "Epoch 305/1000\n",
      " - 97s - loss: 6.0176 - val_loss: 6.6804\n",
      "Epoch 306/1000\n",
      " - 97s - loss: 6.2479 - val_loss: 5.8003\n",
      "Epoch 307/1000\n",
      " - 97s - loss: 6.6488 - val_loss: 6.1088\n",
      "Epoch 308/1000\n",
      " - 97s - loss: 5.9501 - val_loss: 6.3639\n",
      "Epoch 309/1000\n",
      " - 97s - loss: 6.1280 - val_loss: 7.2259\n",
      "Epoch 310/1000\n",
      " - 96s - loss: 6.2597 - val_loss: 5.9506\n",
      "Epoch 311/1000\n",
      " - 97s - loss: 6.2805 - val_loss: 6.1647\n",
      "Epoch 312/1000\n",
      " - 97s - loss: 6.2383 - val_loss: 5.2810\n",
      "Epoch 313/1000\n",
      " - 97s - loss: 6.0722 - val_loss: 6.0871\n",
      "Epoch 314/1000\n",
      " - 96s - loss: 6.5216 - val_loss: 5.6161\n",
      "Epoch 315/1000\n",
      " - 97s - loss: 6.2534 - val_loss: 6.4023\n",
      "Epoch 316/1000\n",
      " - 97s - loss: 6.1482 - val_loss: 5.8468\n",
      "Epoch 317/1000\n",
      " - 97s - loss: 6.1301 - val_loss: 6.2657\n",
      "Epoch 318/1000\n",
      " - 97s - loss: 6.0961 - val_loss: 6.7439\n",
      "Epoch 319/1000\n",
      " - 97s - loss: 6.2537 - val_loss: 5.9802\n",
      "Epoch 320/1000\n",
      " - 96s - loss: 5.9269 - val_loss: 5.5614\n",
      "Epoch 321/1000\n",
      " - 97s - loss: 6.2114 - val_loss: 5.8326\n",
      "Epoch 322/1000\n",
      " - 97s - loss: 6.0875 - val_loss: 5.7897\n",
      "Epoch 323/1000\n",
      " - 97s - loss: 6.0307 - val_loss: 6.0017\n",
      "Epoch 324/1000\n",
      " - 96s - loss: 5.8782 - val_loss: 5.2204\n",
      "Epoch 325/1000\n",
      " - 97s - loss: 6.4079 - val_loss: 6.0721\n",
      "Epoch 326/1000\n",
      " - 96s - loss: 6.1481 - val_loss: 5.5293\n",
      "Epoch 327/1000\n",
      " - 97s - loss: 6.4646 - val_loss: 5.7215\n",
      "Epoch 328/1000\n",
      " - 97s - loss: 5.8019 - val_loss: 7.0222\n",
      "Epoch 329/1000\n",
      " - 96s - loss: 6.1864 - val_loss: 8.2773\n",
      "Epoch 330/1000\n",
      " - 97s - loss: 6.3049 - val_loss: 5.8288\n",
      "Epoch 331/1000\n",
      " - 97s - loss: 6.2645 - val_loss: 6.5144\n",
      "Epoch 332/1000\n",
      " - 97s - loss: 6.2953 - val_loss: 5.9921\n",
      "Epoch 333/1000\n",
      " - 97s - loss: 6.0444 - val_loss: 6.5246\n",
      "Epoch 334/1000\n",
      " - 97s - loss: 5.9000 - val_loss: 6.4445\n",
      "Epoch 335/1000\n",
      " - 96s - loss: 6.2443 - val_loss: 6.4617\n",
      "Epoch 336/1000\n",
      " - 96s - loss: 6.3884 - val_loss: 6.6516\n",
      "Epoch 337/1000\n",
      " - 97s - loss: 6.3198 - val_loss: 5.7192\n",
      "Epoch 338/1000\n",
      " - 97s - loss: 6.1662 - val_loss: 6.0041\n",
      "Epoch 339/1000\n",
      " - 97s - loss: 6.0233 - val_loss: 5.4630\n",
      "Epoch 340/1000\n",
      " - 97s - loss: 6.2089 - val_loss: 6.5533\n",
      "Epoch 341/1000\n",
      " - 97s - loss: 5.9621 - val_loss: 7.1968\n",
      "Epoch 342/1000\n",
      " - 97s - loss: 6.2098 - val_loss: 6.2725\n",
      "Epoch 343/1000\n",
      " - 97s - loss: 6.6006 - val_loss: 6.8648\n",
      "Epoch 344/1000\n",
      " - 97s - loss: 6.1368 - val_loss: 5.6061\n",
      "Epoch 345/1000\n",
      " - 97s - loss: 5.9519 - val_loss: 5.8369\n",
      "Epoch 346/1000\n",
      " - 96s - loss: 6.2094 - val_loss: 6.1218\n",
      "Epoch 347/1000\n",
      " - 97s - loss: 5.9109 - val_loss: 6.1573\n",
      "Epoch 348/1000\n",
      " - 97s - loss: 6.2182 - val_loss: 5.1865\n",
      "Epoch 349/1000\n",
      " - 97s - loss: 6.3359 - val_loss: 5.5365\n",
      "Epoch 350/1000\n",
      " - 97s - loss: 6.3885 - val_loss: 5.7688\n",
      "Epoch 351/1000\n",
      " - 97s - loss: 6.3673 - val_loss: 5.8193\n",
      "Epoch 352/1000\n",
      " - 97s - loss: 6.0114 - val_loss: 5.1099\n",
      "Epoch 353/1000\n",
      " - 97s - loss: 5.4859 - val_loss: 6.5196\n",
      "Epoch 354/1000\n",
      " - 97s - loss: 5.7147 - val_loss: 6.6512\n",
      "Epoch 355/1000\n",
      " - 97s - loss: 5.7922 - val_loss: 5.7850\n",
      "Epoch 356/1000\n",
      " - 97s - loss: 6.0451 - val_loss: 6.2467\n",
      "Epoch 357/1000\n",
      " - 97s - loss: 6.0721 - val_loss: 5.3578\n",
      "Epoch 358/1000\n",
      " - 97s - loss: 5.6319 - val_loss: 5.9886\n",
      "Epoch 359/1000\n",
      " - 96s - loss: 6.1834 - val_loss: 5.9671\n",
      "Epoch 360/1000\n",
      " - 97s - loss: 6.0951 - val_loss: 7.5356\n",
      "Epoch 361/1000\n",
      " - 97s - loss: 5.9847 - val_loss: 5.6352\n",
      "Epoch 362/1000\n",
      " - 97s - loss: 6.0819 - val_loss: 5.9213\n",
      "Epoch 363/1000\n",
      " - 97s - loss: 5.8695 - val_loss: 5.8280\n",
      "Epoch 364/1000\n",
      " - 97s - loss: 6.0062 - val_loss: 5.6478\n",
      "Epoch 365/1000\n",
      " - 97s - loss: 5.8411 - val_loss: 7.4415\n",
      "Epoch 366/1000\n",
      " - 96s - loss: 5.5774 - val_loss: 5.7851\n",
      "Epoch 367/1000\n",
      " - 97s - loss: 6.2551 - val_loss: 6.2687\n",
      "Epoch 368/1000\n",
      " - 96s - loss: 5.5181 - val_loss: 5.5408\n",
      "Epoch 369/1000\n",
      " - 97s - loss: 6.0237 - val_loss: 5.8640\n",
      "Epoch 370/1000\n",
      " - 97s - loss: 6.0054 - val_loss: 5.1501\n",
      "Epoch 371/1000\n",
      " - 97s - loss: 6.0723 - val_loss: 5.7393\n",
      "Epoch 372/1000\n",
      " - 97s - loss: 6.2644 - val_loss: 5.5882\n",
      "Epoch 373/1000\n",
      " - 97s - loss: 5.8670 - val_loss: 5.8967\n",
      "Epoch 374/1000\n",
      " - 97s - loss: 5.8375 - val_loss: 6.5003\n",
      "Epoch 375/1000\n",
      " - 97s - loss: 5.8462 - val_loss: 6.4206\n",
      "Epoch 376/1000\n",
      " - 97s - loss: 6.1348 - val_loss: 5.8677\n",
      "Epoch 377/1000\n",
      " - 96s - loss: 5.6499 - val_loss: 6.1439\n",
      "Epoch 378/1000\n",
      " - 97s - loss: 6.1067 - val_loss: 5.6883\n",
      "Epoch 379/1000\n",
      " - 96s - loss: 5.6374 - val_loss: 5.7714\n",
      "Epoch 380/1000\n",
      " - 96s - loss: 5.8167 - val_loss: 6.3060\n",
      "Epoch 381/1000\n",
      " - 97s - loss: 5.8216 - val_loss: 7.0990\n",
      "Epoch 382/1000\n",
      " - 97s - loss: 5.6884 - val_loss: 5.4229\n",
      "Epoch 383/1000\n",
      " - 97s - loss: 5.9629 - val_loss: 5.2023\n",
      "Epoch 384/1000\n",
      " - 97s - loss: 5.8583 - val_loss: 5.7189\n",
      "Epoch 385/1000\n",
      " - 97s - loss: 6.1105 - val_loss: 6.9619\n",
      "Epoch 386/1000\n",
      " - 97s - loss: 5.7838 - val_loss: 5.8872\n",
      "Epoch 387/1000\n",
      " - 97s - loss: 6.5100 - val_loss: 5.3138\n",
      "Epoch 388/1000\n",
      " - 97s - loss: 5.7255 - val_loss: 6.1766\n",
      "Epoch 389/1000\n",
      " - 97s - loss: 5.6405 - val_loss: 5.7923\n",
      "Epoch 390/1000\n",
      " - 97s - loss: 5.9057 - val_loss: 5.2071\n",
      "Epoch 391/1000\n",
      " - 97s - loss: 5.4481 - val_loss: 5.5628\n",
      "Epoch 392/1000\n",
      " - 97s - loss: 5.6393 - val_loss: 5.4416\n",
      "Epoch 393/1000\n",
      " - 97s - loss: 5.8959 - val_loss: 5.7737\n",
      "Epoch 394/1000\n",
      " - 97s - loss: 6.0589 - val_loss: 6.0354\n",
      "Epoch 395/1000\n",
      " - 97s - loss: 5.6629 - val_loss: 5.1370\n",
      "Epoch 396/1000\n",
      " - 97s - loss: 5.8123 - val_loss: 5.7399\n",
      "Epoch 397/1000\n",
      " - 97s - loss: 5.5673 - val_loss: 6.0410\n",
      "Epoch 398/1000\n",
      " - 97s - loss: 5.6586 - val_loss: 5.5504\n",
      "Epoch 399/1000\n",
      " - 96s - loss: 6.0574 - val_loss: 5.3744\n",
      "Epoch 400/1000\n",
      " - 97s - loss: 6.0005 - val_loss: 5.3508\n",
      "Epoch 401/1000\n",
      " - 97s - loss: 5.5405 - val_loss: 5.2718\n",
      "Epoch 402/1000\n",
      " - 97s - loss: 6.1343 - val_loss: 5.0723\n",
      "Epoch 403/1000\n",
      " - 97s - loss: 5.9430 - val_loss: 5.5825\n",
      "Epoch 404/1000\n",
      " - 96s - loss: 5.6149 - val_loss: 5.6624\n",
      "Epoch 405/1000\n",
      " - 97s - loss: 5.2785 - val_loss: 5.6172\n",
      "Epoch 406/1000\n",
      " - 96s - loss: 5.8327 - val_loss: 5.4774\n",
      "Epoch 407/1000\n",
      " - 96s - loss: 5.8937 - val_loss: 5.0183\n",
      "Epoch 408/1000\n",
      " - 96s - loss: 5.1930 - val_loss: 4.6437\n",
      "Epoch 409/1000\n",
      " - 96s - loss: 5.6478 - val_loss: 5.0769\n",
      "Epoch 410/1000\n",
      " - 97s - loss: 5.0162 - val_loss: 5.5500\n",
      "Epoch 411/1000\n",
      " - 96s - loss: 5.2081 - val_loss: 5.3405\n",
      "Epoch 412/1000\n",
      " - 97s - loss: 5.9667 - val_loss: 5.7129\n",
      "Epoch 413/1000\n",
      " - 97s - loss: 5.7452 - val_loss: 6.9566\n",
      "Epoch 414/1000\n",
      " - 97s - loss: 5.0682 - val_loss: 5.2149\n",
      "Epoch 415/1000\n",
      " - 97s - loss: 5.6383 - val_loss: 5.5847\n",
      "Epoch 416/1000\n",
      " - 96s - loss: 5.5211 - val_loss: 5.0558\n",
      "Epoch 417/1000\n",
      " - 97s - loss: 5.6642 - val_loss: 5.3644\n",
      "Epoch 418/1000\n",
      " - 97s - loss: 5.5899 - val_loss: 5.0080\n",
      "Epoch 419/1000\n",
      " - 96s - loss: 5.4748 - val_loss: 5.8176\n",
      "Epoch 420/1000\n",
      " - 97s - loss: 5.3724 - val_loss: 5.3136\n",
      "Epoch 421/1000\n",
      " - 96s - loss: 5.3378 - val_loss: 5.2050\n",
      "Epoch 422/1000\n",
      " - 96s - loss: 5.4751 - val_loss: 5.5868\n",
      "Epoch 423/1000\n",
      " - 97s - loss: 5.9076 - val_loss: 6.5553\n",
      "Epoch 424/1000\n",
      " - 96s - loss: 5.6630 - val_loss: 5.4201\n",
      "Epoch 425/1000\n",
      " - 97s - loss: 5.2871 - val_loss: 5.5665\n",
      "Epoch 426/1000\n",
      " - 96s - loss: 5.2990 - val_loss: 5.9769\n",
      "Epoch 427/1000\n",
      " - 97s - loss: 5.6518 - val_loss: 6.2036\n",
      "Epoch 428/1000\n",
      " - 96s - loss: 5.2688 - val_loss: 4.8893\n",
      "Epoch 429/1000\n",
      " - 96s - loss: 5.3597 - val_loss: 4.7466\n",
      "Epoch 430/1000\n",
      " - 96s - loss: 5.4325 - val_loss: 5.1590\n",
      "Epoch 431/1000\n",
      " - 97s - loss: 5.5263 - val_loss: 5.7585\n",
      "Epoch 432/1000\n",
      " - 97s - loss: 5.2312 - val_loss: 4.7299\n",
      "Epoch 433/1000\n",
      " - 97s - loss: 5.1459 - val_loss: 5.8948\n",
      "Epoch 434/1000\n",
      " - 96s - loss: 5.8054 - val_loss: 6.0739\n",
      "Epoch 435/1000\n",
      " - 96s - loss: 5.3552 - val_loss: 6.2873\n",
      "Epoch 436/1000\n",
      " - 97s - loss: 5.5014 - val_loss: 4.7623\n",
      "Epoch 437/1000\n",
      " - 97s - loss: 5.5069 - val_loss: 5.2349\n",
      "Epoch 438/1000\n",
      " - 97s - loss: 5.1012 - val_loss: 5.6234\n",
      "Epoch 439/1000\n",
      " - 96s - loss: 5.6960 - val_loss: 5.9896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/1000\n",
      " - 97s - loss: 5.2707 - val_loss: 5.1119\n",
      "Epoch 441/1000\n",
      " - 97s - loss: 5.2499 - val_loss: 4.9282\n",
      "Epoch 442/1000\n",
      " - 97s - loss: 5.5826 - val_loss: 5.2444\n",
      "Epoch 443/1000\n",
      " - 97s - loss: 5.6254 - val_loss: 5.7827\n",
      "Epoch 444/1000\n",
      " - 97s - loss: 5.1471 - val_loss: 5.2617\n",
      "Epoch 445/1000\n",
      " - 97s - loss: 5.3999 - val_loss: 4.7270\n",
      "Epoch 446/1000\n",
      " - 97s - loss: 5.5784 - val_loss: 4.7217\n",
      "Epoch 447/1000\n",
      " - 98s - loss: 5.2370 - val_loss: 5.2839\n",
      "Epoch 448/1000\n",
      " - 97s - loss: 5.0280 - val_loss: 4.8210\n",
      "Epoch 449/1000\n",
      " - 98s - loss: 5.2448 - val_loss: 6.2923\n",
      "Epoch 450/1000\n",
      " - 97s - loss: 5.3588 - val_loss: 5.6192\n",
      "Epoch 451/1000\n",
      " - 97s - loss: 4.9527 - val_loss: 5.3286\n",
      "Epoch 452/1000\n",
      " - 97s - loss: 5.2976 - val_loss: 5.6920\n",
      "Epoch 453/1000\n",
      " - 97s - loss: 5.5633 - val_loss: 5.2365\n",
      "Epoch 454/1000\n",
      " - 97s - loss: 5.7810 - val_loss: 6.1209\n",
      "Epoch 455/1000\n",
      " - 97s - loss: 5.5670 - val_loss: 5.4697\n",
      "Epoch 456/1000\n",
      " - 97s - loss: 5.1358 - val_loss: 4.8891\n",
      "Epoch 457/1000\n",
      " - 97s - loss: 5.3054 - val_loss: 5.0526\n",
      "Epoch 458/1000\n",
      " - 97s - loss: 5.1801 - val_loss: 5.5768\n",
      "Epoch 459/1000\n",
      " - 97s - loss: 5.1570 - val_loss: 4.9299\n",
      "Epoch 460/1000\n",
      " - 97s - loss: 5.4226 - val_loss: 5.8618\n",
      "Epoch 461/1000\n",
      " - 97s - loss: 5.1425 - val_loss: 4.8834\n",
      "Epoch 462/1000\n",
      " - 97s - loss: 5.9752 - val_loss: 4.8057\n",
      "Epoch 463/1000\n",
      " - 97s - loss: 5.0878 - val_loss: 5.0634\n",
      "Epoch 464/1000\n",
      " - 97s - loss: 5.1479 - val_loss: 6.1635\n",
      "Epoch 465/1000\n",
      " - 97s - loss: 5.2563 - val_loss: 4.7216\n",
      "Epoch 466/1000\n",
      " - 97s - loss: 5.2790 - val_loss: 4.9513\n",
      "Epoch 467/1000\n",
      " - 97s - loss: 5.4460 - val_loss: 4.6137\n",
      "Epoch 468/1000\n",
      " - 97s - loss: 5.5688 - val_loss: 4.5882\n",
      "Epoch 469/1000\n",
      " - 97s - loss: 5.3956 - val_loss: 4.9801\n",
      "Epoch 470/1000\n",
      " - 97s - loss: 5.3426 - val_loss: 5.4673\n",
      "Epoch 471/1000\n",
      " - 97s - loss: 5.4199 - val_loss: 5.0247\n",
      "Epoch 472/1000\n",
      " - 97s - loss: 5.2148 - val_loss: 5.8340\n",
      "Epoch 473/1000\n",
      " - 97s - loss: 5.3651 - val_loss: 4.9406\n",
      "Epoch 474/1000\n",
      " - 97s - loss: 5.2151 - val_loss: 5.1314\n",
      "Epoch 475/1000\n",
      " - 97s - loss: 5.3170 - val_loss: 6.2489\n",
      "Epoch 476/1000\n",
      " - 98s - loss: 5.6593 - val_loss: 5.0577\n",
      "Epoch 477/1000\n",
      " - 97s - loss: 5.2473 - val_loss: 5.5081\n",
      "Epoch 478/1000\n",
      " - 97s - loss: 5.5286 - val_loss: 5.9501\n",
      "Epoch 479/1000\n",
      " - 97s - loss: 5.1531 - val_loss: 4.7284\n",
      "Epoch 480/1000\n",
      " - 98s - loss: 5.5453 - val_loss: 5.2971\n",
      "Epoch 481/1000\n",
      " - 96s - loss: 5.4215 - val_loss: 4.9763\n",
      "Epoch 482/1000\n",
      " - 96s - loss: 5.3173 - val_loss: 4.9315\n",
      "Epoch 483/1000\n",
      " - 97s - loss: 5.5732 - val_loss: 5.2303\n",
      "Epoch 484/1000\n",
      " - 97s - loss: 5.0641 - val_loss: 5.4785\n",
      "Epoch 485/1000\n",
      " - 97s - loss: 5.0328 - val_loss: 5.6931\n",
      "Epoch 486/1000\n",
      " - 96s - loss: 5.5070 - val_loss: 6.0526\n",
      "Epoch 487/1000\n",
      " - 97s - loss: 5.3099 - val_loss: 4.7852\n",
      "Epoch 488/1000\n",
      " - 97s - loss: 4.9353 - val_loss: 6.7303\n",
      "Epoch 489/1000\n",
      " - 97s - loss: 5.6118 - val_loss: 4.4556\n",
      "Epoch 490/1000\n",
      " - 97s - loss: 4.9724 - val_loss: 4.8849\n",
      "Epoch 491/1000\n",
      " - 97s - loss: 5.1794 - val_loss: 5.3980\n",
      "Epoch 492/1000\n",
      " - 97s - loss: 5.0758 - val_loss: 5.2213\n",
      "Epoch 493/1000\n",
      " - 97s - loss: 5.3250 - val_loss: 5.5708\n",
      "Epoch 494/1000\n",
      " - 97s - loss: 5.2882 - val_loss: 5.4131\n",
      "Epoch 495/1000\n",
      " - 97s - loss: 5.3933 - val_loss: 5.6930\n",
      "Epoch 496/1000\n",
      " - 97s - loss: 5.6554 - val_loss: 6.0502\n",
      "Epoch 497/1000\n",
      " - 97s - loss: 5.4006 - val_loss: 4.9441\n",
      "Epoch 498/1000\n",
      " - 97s - loss: 5.0308 - val_loss: 4.7398\n",
      "Epoch 499/1000\n",
      " - 97s - loss: 5.1166 - val_loss: 5.3788\n",
      "Epoch 500/1000\n",
      " - 97s - loss: 4.9916 - val_loss: 5.0063\n",
      "Epoch 501/1000\n",
      " - 96s - loss: 5.1496 - val_loss: 5.0957\n",
      "Epoch 502/1000\n",
      " - 97s - loss: 5.4446 - val_loss: 5.4603\n",
      "Epoch 503/1000\n",
      " - 97s - loss: 5.2561 - val_loss: 5.0618\n",
      "Epoch 504/1000\n",
      " - 97s - loss: 5.0237 - val_loss: 4.9708\n",
      "Epoch 505/1000\n",
      " - 97s - loss: 5.0768 - val_loss: 5.3130\n",
      "Epoch 506/1000\n",
      " - 97s - loss: 4.9297 - val_loss: 4.9196\n",
      "Epoch 507/1000\n",
      " - 97s - loss: 5.0359 - val_loss: 4.7601\n",
      "Epoch 508/1000\n",
      " - 97s - loss: 5.2213 - val_loss: 5.1180\n",
      "Epoch 509/1000\n",
      " - 97s - loss: 4.8916 - val_loss: 4.9468\n",
      "Epoch 510/1000\n",
      " - 97s - loss: 4.6593 - val_loss: 4.9717\n",
      "Epoch 511/1000\n",
      " - 97s - loss: 5.1804 - val_loss: 5.1450\n",
      "Epoch 512/1000\n",
      " - 97s - loss: 4.7765 - val_loss: 4.6904\n",
      "Epoch 513/1000\n",
      " - 97s - loss: 4.9529 - val_loss: 5.1991\n",
      "Epoch 514/1000\n",
      " - 97s - loss: 5.1713 - val_loss: 5.1988\n",
      "Epoch 515/1000\n",
      " - 97s - loss: 4.8202 - val_loss: 5.3679\n",
      "Epoch 516/1000\n",
      " - 97s - loss: 5.0796 - val_loss: 4.8492\n",
      "Epoch 517/1000\n",
      " - 97s - loss: 4.8174 - val_loss: 4.8879\n",
      "Epoch 518/1000\n",
      " - 97s - loss: 5.2125 - val_loss: 5.0065\n",
      "Epoch 519/1000\n",
      " - 97s - loss: 4.5618 - val_loss: 5.8473\n",
      "Epoch 520/1000\n",
      " - 97s - loss: 4.9300 - val_loss: 4.8141\n",
      "Epoch 521/1000\n",
      " - 97s - loss: 5.0488 - val_loss: 4.8432\n",
      "Epoch 522/1000\n",
      " - 97s - loss: 4.8126 - val_loss: 5.1865\n",
      "Epoch 523/1000\n",
      " - 97s - loss: 5.2793 - val_loss: 5.2558\n",
      "Epoch 524/1000\n",
      " - 98s - loss: 4.9822 - val_loss: 5.4460\n",
      "Epoch 525/1000\n",
      " - 97s - loss: 5.1644 - val_loss: 4.8918\n",
      "Epoch 526/1000\n",
      " - 98s - loss: 4.7357 - val_loss: 5.6038\n",
      "Epoch 527/1000\n",
      " - 97s - loss: 5.3908 - val_loss: 5.1690\n",
      "Epoch 528/1000\n",
      " - 97s - loss: 4.7799 - val_loss: 5.1934\n",
      "Epoch 529/1000\n",
      " - 97s - loss: 4.9860 - val_loss: 5.2033\n",
      "Epoch 530/1000\n",
      " - 97s - loss: 4.9144 - val_loss: 5.3940\n",
      "Epoch 531/1000\n",
      " - 97s - loss: 4.9008 - val_loss: 4.6631\n",
      "Epoch 532/1000\n",
      " - 97s - loss: 4.9274 - val_loss: 4.8127\n",
      "Epoch 533/1000\n",
      " - 98s - loss: 4.9499 - val_loss: 5.1723\n",
      "Epoch 534/1000\n",
      " - 97s - loss: 4.6311 - val_loss: 5.5649\n",
      "Epoch 535/1000\n",
      " - 97s - loss: 5.0077 - val_loss: 5.3383\n",
      "Epoch 536/1000\n",
      " - 97s - loss: 4.8937 - val_loss: 5.2761\n",
      "Epoch 537/1000\n",
      " - 98s - loss: 4.5707 - val_loss: 5.2923\n",
      "Epoch 538/1000\n",
      " - 97s - loss: 5.0054 - val_loss: 4.6623\n",
      "Epoch 539/1000\n",
      " - 98s - loss: 4.8407 - val_loss: 5.0262\n",
      "Epoch 540/1000\n",
      " - 96s - loss: 4.7521 - val_loss: 5.0096\n",
      "Epoch 541/1000\n",
      " - 98s - loss: 4.7738 - val_loss: 4.5597\n",
      "Epoch 542/1000\n",
      " - 97s - loss: 5.3568 - val_loss: 6.3124\n",
      "Epoch 543/1000\n",
      " - 97s - loss: 4.7535 - val_loss: 4.5974\n",
      "Epoch 544/1000\n",
      " - 97s - loss: 4.5895 - val_loss: 5.0737\n",
      "Epoch 545/1000\n",
      " - 97s - loss: 5.2241 - val_loss: 5.5268\n",
      "Epoch 546/1000\n",
      " - 98s - loss: 4.8073 - val_loss: 4.6457\n",
      "Epoch 547/1000\n",
      " - 97s - loss: 4.6071 - val_loss: 5.8027\n",
      "Epoch 548/1000\n",
      " - 97s - loss: 4.8776 - val_loss: 5.5636\n",
      "Epoch 549/1000\n",
      " - 97s - loss: 4.6393 - val_loss: 4.7005\n",
      "Epoch 550/1000\n",
      " - 97s - loss: 5.2431 - val_loss: 4.7535\n",
      "Epoch 551/1000\n",
      " - 97s - loss: 4.9670 - val_loss: 4.4932\n",
      "Epoch 552/1000\n",
      " - 97s - loss: 5.2175 - val_loss: 4.9615\n",
      "Epoch 553/1000\n",
      " - 97s - loss: 5.2048 - val_loss: 5.8892\n",
      "Epoch 554/1000\n",
      " - 97s - loss: 4.6454 - val_loss: 4.7167\n",
      "Epoch 555/1000\n",
      " - 97s - loss: 4.7940 - val_loss: 4.5201\n",
      "Epoch 556/1000\n",
      " - 98s - loss: 4.8878 - val_loss: 4.1783\n",
      "Epoch 557/1000\n",
      " - 98s - loss: 5.3503 - val_loss: 4.6362\n",
      "Epoch 558/1000\n",
      " - 97s - loss: 4.8744 - val_loss: 4.7335\n",
      "Epoch 559/1000\n",
      " - 97s - loss: 4.9489 - val_loss: 4.9893\n",
      "Epoch 560/1000\n",
      " - 97s - loss: 4.6698 - val_loss: 4.4638\n",
      "Epoch 561/1000\n",
      " - 97s - loss: 5.0670 - val_loss: 5.0525\n",
      "Epoch 562/1000\n",
      " - 96s - loss: 5.0537 - val_loss: 4.1451\n",
      "Epoch 563/1000\n",
      " - 97s - loss: 5.2212 - val_loss: 4.2482\n",
      "Epoch 564/1000\n",
      " - 97s - loss: 4.7281 - val_loss: 5.4351\n",
      "Epoch 565/1000\n",
      " - 97s - loss: 4.7143 - val_loss: 4.4628\n",
      "Epoch 566/1000\n",
      " - 97s - loss: 4.8429 - val_loss: 4.8178\n",
      "Epoch 567/1000\n",
      " - 98s - loss: 4.9654 - val_loss: 4.7506\n",
      "Epoch 568/1000\n",
      " - 97s - loss: 4.4447 - val_loss: 4.3951\n",
      "Epoch 569/1000\n",
      " - 97s - loss: 4.7654 - val_loss: 4.9218\n",
      "Epoch 570/1000\n",
      " - 98s - loss: 4.7875 - val_loss: 5.7416\n",
      "Epoch 571/1000\n",
      " - 97s - loss: 5.2250 - val_loss: 4.7607\n",
      "Epoch 572/1000\n",
      " - 97s - loss: 4.5642 - val_loss: 5.0959\n",
      "Epoch 573/1000\n",
      " - 97s - loss: 4.7024 - val_loss: 5.2621\n",
      "Epoch 574/1000\n",
      " - 97s - loss: 4.7167 - val_loss: 4.8803\n",
      "Epoch 575/1000\n",
      " - 97s - loss: 4.5955 - val_loss: 4.4835\n",
      "Epoch 576/1000\n",
      " - 98s - loss: 4.9379 - val_loss: 4.6655\n",
      "Epoch 577/1000\n",
      " - 96s - loss: 5.0112 - val_loss: 4.1378\n",
      "Epoch 578/1000\n",
      " - 97s - loss: 4.7599 - val_loss: 4.6887\n",
      "Epoch 579/1000\n",
      " - 97s - loss: 4.7211 - val_loss: 5.5540\n",
      "Epoch 580/1000\n",
      " - 97s - loss: 4.7359 - val_loss: 4.4705\n",
      "Epoch 581/1000\n",
      " - 97s - loss: 4.8040 - val_loss: 5.1281\n",
      "Epoch 582/1000\n",
      " - 97s - loss: 4.6396 - val_loss: 4.6434\n",
      "Epoch 583/1000\n",
      " - 97s - loss: 4.8771 - val_loss: 4.7008\n",
      "Epoch 584/1000\n",
      " - 96s - loss: 4.7599 - val_loss: 4.5903\n",
      "Epoch 585/1000\n",
      " - 97s - loss: 5.0186 - val_loss: 5.1359\n",
      "Epoch 586/1000\n",
      " - 97s - loss: 4.7305 - val_loss: 4.4868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 587/1000\n",
      " - 97s - loss: 4.8970 - val_loss: 4.2844\n",
      "Epoch 588/1000\n",
      " - 97s - loss: 5.1592 - val_loss: 4.8619\n",
      "Epoch 589/1000\n",
      " - 97s - loss: 4.9000 - val_loss: 5.4816\n",
      "Epoch 590/1000\n",
      " - 97s - loss: 4.7122 - val_loss: 5.0212\n",
      "Epoch 591/1000\n",
      " - 96s - loss: 4.2835 - val_loss: 5.0790\n",
      "Epoch 592/1000\n",
      " - 98s - loss: 4.4383 - val_loss: 5.5175\n",
      "Epoch 593/1000\n",
      " - 97s - loss: 4.7123 - val_loss: 5.1167\n",
      "Epoch 594/1000\n",
      " - 97s - loss: 4.9227 - val_loss: 4.5683\n",
      "Epoch 595/1000\n",
      " - 97s - loss: 4.9479 - val_loss: 4.5841\n",
      "Epoch 596/1000\n",
      " - 97s - loss: 4.9139 - val_loss: 4.3763\n",
      "Epoch 597/1000\n",
      " - 97s - loss: 4.7471 - val_loss: 4.5207\n",
      "Epoch 598/1000\n",
      " - 97s - loss: 4.6880 - val_loss: 5.3543\n",
      "Epoch 599/1000\n",
      " - 97s - loss: 4.6117 - val_loss: 5.0272\n",
      "Epoch 600/1000\n",
      " - 97s - loss: 4.7195 - val_loss: 4.7083\n",
      "Epoch 601/1000\n",
      " - 97s - loss: 4.7355 - val_loss: 4.9672\n",
      "Epoch 602/1000\n",
      " - 97s - loss: 4.7100 - val_loss: 5.0037\n",
      "Epoch 603/1000\n",
      " - 97s - loss: 5.0393 - val_loss: 5.1975\n",
      "Epoch 604/1000\n",
      " - 97s - loss: 4.5841 - val_loss: 4.6859\n",
      "Epoch 605/1000\n",
      " - 97s - loss: 4.3871 - val_loss: 4.4210\n",
      "Epoch 606/1000\n",
      " - 97s - loss: 4.3613 - val_loss: 4.9563\n",
      "Epoch 607/1000\n",
      " - 97s - loss: 4.5807 - val_loss: 4.7396\n",
      "Epoch 608/1000\n",
      " - 96s - loss: 4.5634 - val_loss: 4.5379\n",
      "Epoch 609/1000\n",
      " - 97s - loss: 4.6355 - val_loss: 4.4407\n",
      "Epoch 610/1000\n",
      " - 97s - loss: 4.5815 - val_loss: 4.3955\n",
      "Epoch 611/1000\n",
      " - 96s - loss: 4.5438 - val_loss: 4.6711\n",
      "Epoch 612/1000\n",
      " - 97s - loss: 4.3280 - val_loss: 4.6936\n",
      "Epoch 613/1000\n",
      " - 96s - loss: 4.4136 - val_loss: 4.7900\n",
      "Epoch 614/1000\n",
      " - 98s - loss: 4.2592 - val_loss: 4.4287\n",
      "Epoch 615/1000\n",
      " - 97s - loss: 4.4920 - val_loss: 4.9656\n",
      "Epoch 616/1000\n",
      " - 97s - loss: 4.7131 - val_loss: 4.7242\n",
      "Epoch 617/1000\n",
      " - 97s - loss: 4.5871 - val_loss: 4.0725\n",
      "Epoch 618/1000\n",
      " - 97s - loss: 4.2030 - val_loss: 4.9558\n",
      "Epoch 619/1000\n",
      " - 97s - loss: 4.6333 - val_loss: 5.0553\n",
      "Epoch 620/1000\n",
      " - 96s - loss: 4.3608 - val_loss: 3.9853\n",
      "Epoch 621/1000\n",
      " - 97s - loss: 4.3581 - val_loss: 5.0538\n",
      "Epoch 622/1000\n",
      " - 96s - loss: 4.5342 - val_loss: 4.4649\n",
      "Epoch 623/1000\n",
      " - 97s - loss: 4.4913 - val_loss: 4.8940\n",
      "Epoch 624/1000\n",
      " - 97s - loss: 4.6849 - val_loss: 3.9105\n",
      "Epoch 625/1000\n",
      " - 97s - loss: 4.6912 - val_loss: 4.0391\n",
      "Epoch 626/1000\n",
      " - 97s - loss: 4.7731 - val_loss: 5.1967\n",
      "Epoch 627/1000\n",
      " - 97s - loss: 4.6148 - val_loss: 4.6623\n",
      "Epoch 628/1000\n",
      " - 97s - loss: 4.6736 - val_loss: 4.4072\n",
      "Epoch 629/1000\n",
      " - 97s - loss: 4.1532 - val_loss: 4.1384\n",
      "Epoch 630/1000\n",
      " - 97s - loss: 4.3867 - val_loss: 4.8491\n",
      "Epoch 631/1000\n",
      " - 97s - loss: 4.4642 - val_loss: 4.7412\n",
      "Epoch 632/1000\n",
      " - 97s - loss: 4.3035 - val_loss: 4.1701\n",
      "Epoch 633/1000\n",
      " - 97s - loss: 3.9631 - val_loss: 4.5311\n",
      "Epoch 634/1000\n",
      " - 98s - loss: 4.5433 - val_loss: 4.6855\n",
      "Epoch 635/1000\n",
      " - 96s - loss: 4.4141 - val_loss: 5.3020\n",
      "Epoch 636/1000\n",
      " - 97s - loss: 4.5166 - val_loss: 4.8399\n",
      "Epoch 637/1000\n",
      " - 97s - loss: 4.4640 - val_loss: 5.0692\n",
      "Epoch 638/1000\n",
      " - 96s - loss: 4.7095 - val_loss: 4.4214\n",
      "Epoch 639/1000\n",
      " - 97s - loss: 4.6587 - val_loss: 4.3181\n",
      "Epoch 640/1000\n",
      " - 97s - loss: 4.6579 - val_loss: 4.5266\n",
      "Epoch 641/1000\n",
      " - 97s - loss: 4.2482 - val_loss: 3.7048\n",
      "Epoch 642/1000\n",
      " - 97s - loss: 4.4934 - val_loss: 5.1624\n",
      "Epoch 643/1000\n",
      " - 97s - loss: 4.5470 - val_loss: 4.4422\n",
      "Epoch 644/1000\n",
      " - 97s - loss: 4.4198 - val_loss: 3.8712\n",
      "Epoch 645/1000\n",
      " - 97s - loss: 4.5417 - val_loss: 3.8512\n",
      "Epoch 646/1000\n",
      " - 97s - loss: 4.3446 - val_loss: 4.5548\n",
      "Epoch 647/1000\n",
      " - 97s - loss: 4.4304 - val_loss: 4.5303\n",
      "Epoch 648/1000\n",
      " - 97s - loss: 4.2144 - val_loss: 4.6408\n",
      "Epoch 649/1000\n",
      " - 97s - loss: 4.4782 - val_loss: 4.6859\n",
      "Epoch 650/1000\n",
      " - 97s - loss: 4.5918 - val_loss: 4.5510\n",
      "Epoch 651/1000\n",
      " - 97s - loss: 4.5946 - val_loss: 4.5215\n",
      "Epoch 652/1000\n",
      " - 97s - loss: 4.5539 - val_loss: 3.9283\n",
      "Epoch 653/1000\n",
      " - 97s - loss: 4.2458 - val_loss: 4.4750\n",
      "Epoch 654/1000\n",
      " - 97s - loss: 4.3708 - val_loss: 4.6800\n",
      "Epoch 655/1000\n",
      " - 97s - loss: 4.4060 - val_loss: 4.1885\n",
      "Epoch 656/1000\n",
      " - 98s - loss: 4.4175 - val_loss: 4.4300\n",
      "Epoch 657/1000\n",
      " - 97s - loss: 4.9286 - val_loss: 4.2261\n",
      "Epoch 658/1000\n",
      " - 97s - loss: 4.3945 - val_loss: 3.8906\n",
      "Epoch 659/1000\n",
      " - 96s - loss: 4.4993 - val_loss: 4.9528\n",
      "Epoch 660/1000\n",
      " - 97s - loss: 4.5602 - val_loss: 4.2608\n",
      "Epoch 661/1000\n",
      " - 97s - loss: 4.4661 - val_loss: 4.5175\n",
      "Epoch 662/1000\n",
      " - 97s - loss: 4.4183 - val_loss: 4.5108\n",
      "Epoch 663/1000\n",
      " - 97s - loss: 4.4276 - val_loss: 4.5424\n",
      "Epoch 664/1000\n",
      " - 98s - loss: 4.6061 - val_loss: 4.7565\n",
      "Epoch 665/1000\n",
      " - 97s - loss: 4.2921 - val_loss: 5.1325\n",
      "Epoch 666/1000\n",
      " - 97s - loss: 4.4487 - val_loss: 4.3146\n",
      "Epoch 667/1000\n",
      " - 97s - loss: 4.6604 - val_loss: 4.2940\n",
      "Epoch 668/1000\n",
      " - 97s - loss: 4.3165 - val_loss: 4.1934\n",
      "Epoch 669/1000\n",
      " - 97s - loss: 4.4861 - val_loss: 4.9049\n",
      "Epoch 670/1000\n",
      " - 97s - loss: 4.5247 - val_loss: 4.1855\n",
      "Epoch 671/1000\n",
      " - 96s - loss: 4.0921 - val_loss: 4.3692\n",
      "Epoch 672/1000\n",
      " - 98s - loss: 4.2631 - val_loss: 5.3676\n",
      "Epoch 673/1000\n",
      " - 97s - loss: 4.0352 - val_loss: 5.1631\n",
      "Epoch 674/1000\n",
      " - 97s - loss: 4.5338 - val_loss: 4.1733\n",
      "Epoch 675/1000\n",
      " - 97s - loss: 4.2201 - val_loss: 4.5215\n",
      "Epoch 676/1000\n",
      " - 97s - loss: 4.7275 - val_loss: 4.4110\n",
      "Epoch 677/1000\n",
      " - 97s - loss: 4.1961 - val_loss: 5.2215\n",
      "Epoch 678/1000\n",
      " - 97s - loss: 4.6642 - val_loss: 4.1919\n",
      "Epoch 679/1000\n",
      " - 97s - loss: 4.4992 - val_loss: 4.3543\n",
      "Epoch 680/1000\n",
      " - 97s - loss: 4.6349 - val_loss: 3.8444\n",
      "Epoch 681/1000\n",
      " - 97s - loss: 4.5326 - val_loss: 4.5046\n",
      "Epoch 682/1000\n",
      " - 97s - loss: 4.3197 - val_loss: 5.6373\n",
      "Epoch 683/1000\n",
      " - 98s - loss: 4.4157 - val_loss: 4.4637\n",
      "Epoch 684/1000\n",
      " - 96s - loss: 4.3767 - val_loss: 4.9396\n",
      "Epoch 685/1000\n",
      " - 97s - loss: 4.2511 - val_loss: 4.3227\n",
      "Epoch 686/1000\n",
      " - 97s - loss: 4.4852 - val_loss: 4.7445\n",
      "Epoch 687/1000\n",
      " - 97s - loss: 3.9102 - val_loss: 4.3682\n",
      "Epoch 688/1000\n",
      " - 97s - loss: 4.4946 - val_loss: 4.2463\n",
      "Epoch 689/1000\n",
      " - 98s - loss: 4.3916 - val_loss: 4.1758\n",
      "Epoch 690/1000\n",
      " - 97s - loss: 4.4543 - val_loss: 4.1815\n",
      "Epoch 691/1000\n",
      " - 97s - loss: 4.4629 - val_loss: 3.7884\n",
      "Epoch 692/1000\n",
      " - 98s - loss: 4.6096 - val_loss: 3.9531\n",
      "Epoch 693/1000\n",
      " - 96s - loss: 4.5716 - val_loss: 3.6194\n",
      "Epoch 694/1000\n",
      " - 97s - loss: 4.3295 - val_loss: 4.1802\n",
      "Epoch 695/1000\n",
      " - 97s - loss: 3.9649 - val_loss: 4.6355\n",
      "Epoch 696/1000\n",
      " - 97s - loss: 4.8158 - val_loss: 4.8870\n",
      "Epoch 697/1000\n",
      " - 97s - loss: 4.3572 - val_loss: 5.2507\n",
      "Epoch 698/1000\n",
      " - 97s - loss: 4.5873 - val_loss: 4.1714\n",
      "Epoch 699/1000\n",
      " - 97s - loss: 4.1682 - val_loss: 5.2049\n",
      "Epoch 700/1000\n",
      " - 97s - loss: 4.2550 - val_loss: 4.8098\n",
      "Epoch 701/1000\n",
      " - 97s - loss: 4.6670 - val_loss: 5.0181\n",
      "Epoch 702/1000\n",
      " - 97s - loss: 4.4474 - val_loss: 4.6117\n",
      "Epoch 703/1000\n",
      " - 97s - loss: 4.4155 - val_loss: 4.1870\n",
      "Epoch 704/1000\n",
      " - 97s - loss: 4.5229 - val_loss: 4.5057\n",
      "Epoch 705/1000\n",
      " - 97s - loss: 3.9838 - val_loss: 4.4173\n",
      "Epoch 706/1000\n",
      " - 97s - loss: 4.2589 - val_loss: 4.0015\n",
      "Epoch 707/1000\n",
      " - 97s - loss: 4.1419 - val_loss: 4.4424\n",
      "Epoch 708/1000\n",
      " - 97s - loss: 4.1418 - val_loss: 5.1209\n",
      "Epoch 709/1000\n",
      " - 97s - loss: 4.0085 - val_loss: 4.3460\n",
      "Epoch 710/1000\n",
      " - 97s - loss: 4.2738 - val_loss: 3.6478\n",
      "Epoch 711/1000\n",
      " - 97s - loss: 4.4478 - val_loss: 3.9797\n",
      "Epoch 712/1000\n",
      " - 97s - loss: 4.3885 - val_loss: 4.2531\n",
      "Epoch 713/1000\n",
      " - 97s - loss: 3.9591 - val_loss: 4.0551\n",
      "Epoch 714/1000\n",
      " - 97s - loss: 3.9050 - val_loss: 3.7616\n",
      "Epoch 715/1000\n",
      " - 97s - loss: 4.2333 - val_loss: 4.1994\n",
      "Epoch 716/1000\n",
      " - 97s - loss: 4.1098 - val_loss: 4.4156\n",
      "Epoch 717/1000\n",
      " - 97s - loss: 3.9860 - val_loss: 4.1175\n",
      "Epoch 718/1000\n",
      " - 97s - loss: 4.4563 - val_loss: 5.1885\n",
      "Epoch 719/1000\n",
      " - 98s - loss: 3.9691 - val_loss: 4.0512\n",
      "Epoch 720/1000\n",
      " - 97s - loss: 4.1891 - val_loss: 5.0691\n",
      "Epoch 721/1000\n",
      " - 98s - loss: 4.1159 - val_loss: 4.7510\n",
      "Epoch 722/1000\n",
      " - 96s - loss: 4.1731 - val_loss: 4.1810\n",
      "Epoch 723/1000\n",
      " - 97s - loss: 4.0318 - val_loss: 4.1841\n",
      "Epoch 724/1000\n",
      " - 97s - loss: 4.4242 - val_loss: 4.3834\n",
      "Epoch 725/1000\n",
      " - 97s - loss: 3.9212 - val_loss: 3.9794\n",
      "Epoch 726/1000\n",
      " - 97s - loss: 4.0174 - val_loss: 4.9553\n",
      "Epoch 727/1000\n",
      " - 97s - loss: 4.1731 - val_loss: 3.8056\n",
      "Epoch 728/1000\n",
      " - 96s - loss: 3.6387 - val_loss: 3.6040\n",
      "Epoch 729/1000\n",
      " - 97s - loss: 4.0921 - val_loss: 4.2664\n",
      "Epoch 730/1000\n",
      " - 97s - loss: 4.3036 - val_loss: 4.0901\n",
      "Epoch 731/1000\n",
      " - 98s - loss: 4.3444 - val_loss: 4.1965\n",
      "Epoch 732/1000\n",
      " - 97s - loss: 4.3743 - val_loss: 4.5267\n",
      "Epoch 733/1000\n",
      " - 97s - loss: 4.2176 - val_loss: 4.5632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 734/1000\n",
      " - 96s - loss: 4.1393 - val_loss: 3.8429\n",
      "Epoch 735/1000\n",
      " - 97s - loss: 4.3397 - val_loss: 3.9408\n",
      "Epoch 736/1000\n",
      " - 97s - loss: 4.1745 - val_loss: 4.4865\n",
      "Epoch 737/1000\n",
      " - 97s - loss: 3.9926 - val_loss: 4.8354\n",
      "Epoch 738/1000\n",
      " - 97s - loss: 4.0663 - val_loss: 4.2356\n",
      "Epoch 739/1000\n",
      " - 97s - loss: 4.1170 - val_loss: 4.1395\n",
      "Epoch 740/1000\n",
      " - 97s - loss: 4.2838 - val_loss: 4.3525\n",
      "Epoch 741/1000\n",
      " - 97s - loss: 4.1891 - val_loss: 4.1692\n",
      "Epoch 742/1000\n",
      " - 97s - loss: 4.0913 - val_loss: 4.1170\n",
      "Epoch 743/1000\n",
      " - 97s - loss: 4.2084 - val_loss: 3.9948\n",
      "Epoch 744/1000\n",
      " - 97s - loss: 4.1156 - val_loss: 5.0367\n",
      "Epoch 745/1000\n",
      " - 97s - loss: 4.3461 - val_loss: 4.3819\n",
      "Epoch 746/1000\n",
      " - 97s - loss: 4.3319 - val_loss: 3.4154\n",
      "Epoch 747/1000\n",
      " - 97s - loss: 3.9708 - val_loss: 4.3349\n",
      "Epoch 748/1000\n",
      " - 96s - loss: 3.9271 - val_loss: 4.4173\n",
      "Epoch 749/1000\n",
      " - 97s - loss: 4.1776 - val_loss: 4.1981\n",
      "Epoch 750/1000\n",
      " - 97s - loss: 4.7287 - val_loss: 3.7832\n",
      "Epoch 751/1000\n",
      " - 97s - loss: 4.0769 - val_loss: 4.2573\n",
      "Epoch 752/1000\n",
      " - 97s - loss: 4.0209 - val_loss: 3.8262\n",
      "Epoch 753/1000\n",
      " - 97s - loss: 4.2080 - val_loss: 3.3229\n",
      "Epoch 754/1000\n",
      " - 97s - loss: 4.2399 - val_loss: 4.2889\n",
      "Epoch 755/1000\n",
      " - 97s - loss: 4.4250 - val_loss: 3.4299\n",
      "Epoch 756/1000\n",
      " - 97s - loss: 4.3907 - val_loss: 3.5827\n",
      "Epoch 757/1000\n",
      " - 97s - loss: 4.2410 - val_loss: 4.3184\n",
      "Epoch 758/1000\n",
      " - 97s - loss: 4.1803 - val_loss: 4.3262\n",
      "Epoch 759/1000\n",
      " - 97s - loss: 4.2028 - val_loss: 4.2669\n",
      "Epoch 760/1000\n",
      " - 97s - loss: 3.9329 - val_loss: 4.6488\n",
      "Epoch 761/1000\n",
      " - 97s - loss: 4.1290 - val_loss: 3.8095\n",
      "Epoch 762/1000\n",
      " - 97s - loss: 4.1375 - val_loss: 3.7258\n",
      "Epoch 763/1000\n",
      " - 97s - loss: 4.2911 - val_loss: 4.8593\n",
      "Epoch 764/1000\n",
      " - 96s - loss: 4.1454 - val_loss: 4.5507\n",
      "Epoch 765/1000\n",
      " - 98s - loss: 4.3149 - val_loss: 3.4961\n",
      "Epoch 766/1000\n",
      " - 97s - loss: 4.0834 - val_loss: 3.5523\n",
      "Epoch 767/1000\n",
      " - 97s - loss: 4.2059 - val_loss: 4.1393\n",
      "Epoch 768/1000\n",
      " - 97s - loss: 4.3438 - val_loss: 4.8232\n",
      "Epoch 769/1000\n",
      " - 97s - loss: 4.3224 - val_loss: 4.3562\n",
      "Epoch 770/1000\n",
      " - 97s - loss: 3.9939 - val_loss: 3.6693\n",
      "Epoch 771/1000\n",
      " - 97s - loss: 4.1884 - val_loss: 4.9718\n",
      "Epoch 772/1000\n",
      " - 97s - loss: 4.2593 - val_loss: 4.0372\n",
      "Epoch 773/1000\n",
      " - 97s - loss: 4.3374 - val_loss: 3.6649\n",
      "Epoch 774/1000\n",
      " - 97s - loss: 3.9126 - val_loss: 5.2902\n",
      "Epoch 775/1000\n",
      " - 97s - loss: 4.0553 - val_loss: 5.1084\n",
      "Epoch 776/1000\n",
      " - 97s - loss: 4.4291 - val_loss: 4.6804\n",
      "Epoch 777/1000\n",
      " - 97s - loss: 4.2247 - val_loss: 3.9780\n",
      "Epoch 778/1000\n",
      " - 97s - loss: 4.1351 - val_loss: 4.0748\n",
      "Epoch 779/1000\n",
      " - 97s - loss: 4.1985 - val_loss: 3.8035\n",
      "Epoch 780/1000\n",
      " - 98s - loss: 3.9444 - val_loss: 4.9179\n",
      "Epoch 781/1000\n",
      " - 97s - loss: 4.1948 - val_loss: 4.0782\n",
      "Epoch 782/1000\n",
      " - 97s - loss: 4.1842 - val_loss: 4.0633\n",
      "Epoch 783/1000\n",
      " - 97s - loss: 4.2848 - val_loss: 4.3634\n",
      "Epoch 784/1000\n",
      " - 97s - loss: 4.1850 - val_loss: 4.3480\n",
      "Epoch 785/1000\n",
      " - 97s - loss: 4.2723 - val_loss: 4.1134\n",
      "Epoch 786/1000\n",
      " - 97s - loss: 4.0613 - val_loss: 4.5083\n",
      "Epoch 787/1000\n",
      " - 97s - loss: 4.0509 - val_loss: 4.4568\n",
      "Epoch 788/1000\n",
      " - 97s - loss: 4.2212 - val_loss: 4.2454\n",
      "Epoch 789/1000\n",
      " - 97s - loss: 3.7358 - val_loss: 4.4988\n",
      "Epoch 790/1000\n",
      " - 97s - loss: 3.9154 - val_loss: 4.4441\n",
      "Epoch 791/1000\n",
      " - 97s - loss: 3.9949 - val_loss: 4.5201\n",
      "Epoch 792/1000\n",
      " - 97s - loss: 3.7669 - val_loss: 3.7687\n",
      "Epoch 793/1000\n",
      " - 97s - loss: 3.8839 - val_loss: 4.5816\n",
      "Epoch 794/1000\n",
      " - 96s - loss: 4.0787 - val_loss: 3.9781\n",
      "Epoch 795/1000\n",
      " - 96s - loss: 4.1931 - val_loss: 4.5189\n",
      "Epoch 796/1000\n",
      " - 97s - loss: 3.9807 - val_loss: 4.3653\n",
      "Epoch 797/1000\n",
      " - 96s - loss: 4.0193 - val_loss: 4.1052\n",
      "Epoch 798/1000\n",
      " - 97s - loss: 4.2827 - val_loss: 4.6597\n",
      "Epoch 799/1000\n",
      " - 97s - loss: 4.0458 - val_loss: 4.4695\n",
      "Epoch 800/1000\n",
      " - 97s - loss: 4.0717 - val_loss: 3.8548\n",
      "Epoch 801/1000\n",
      " - 97s - loss: 3.9423 - val_loss: 4.2663\n",
      "Epoch 802/1000\n",
      " - 98s - loss: 3.8318 - val_loss: 3.9376\n",
      "Epoch 803/1000\n",
      " - 97s - loss: 3.9550 - val_loss: 4.0237\n",
      "Epoch 804/1000\n",
      " - 97s - loss: 4.0275 - val_loss: 4.0826\n",
      "Epoch 805/1000\n",
      " - 97s - loss: 3.6917 - val_loss: 3.9356\n",
      "Epoch 806/1000\n",
      " - 97s - loss: 4.1366 - val_loss: 3.8248\n",
      "Epoch 807/1000\n",
      " - 97s - loss: 3.8749 - val_loss: 3.8339\n",
      "Epoch 808/1000\n",
      " - 97s - loss: 4.1350 - val_loss: 3.8368\n",
      "Epoch 809/1000\n",
      " - 97s - loss: 4.1215 - val_loss: 3.7773\n",
      "Epoch 810/1000\n",
      " - 97s - loss: 3.9950 - val_loss: 3.1847\n",
      "Epoch 811/1000\n",
      " - 98s - loss: 4.2265 - val_loss: 3.9849\n",
      "Epoch 812/1000\n",
      " - 97s - loss: 4.1494 - val_loss: 3.5719\n",
      "Epoch 813/1000\n",
      " - 97s - loss: 4.0545 - val_loss: 4.4565\n",
      "Epoch 814/1000\n",
      " - 97s - loss: 4.0474 - val_loss: 4.2213\n",
      "Epoch 815/1000\n",
      " - 97s - loss: 3.8779 - val_loss: 3.5772\n",
      "Epoch 816/1000\n",
      " - 97s - loss: 3.8278 - val_loss: 3.8954\n",
      "Epoch 817/1000\n",
      " - 97s - loss: 3.9237 - val_loss: 4.1127\n",
      "Epoch 818/1000\n",
      " - 97s - loss: 3.6555 - val_loss: 3.7577\n",
      "Epoch 819/1000\n",
      " - 98s - loss: 3.9685 - val_loss: 4.2432\n",
      "Epoch 820/1000\n",
      " - 96s - loss: 3.9512 - val_loss: 3.5297\n",
      "Epoch 821/1000\n",
      " - 97s - loss: 3.6984 - val_loss: 3.9556\n",
      "Epoch 822/1000\n",
      " - 97s - loss: 3.9667 - val_loss: 4.1013\n",
      "Epoch 823/1000\n",
      " - 97s - loss: 3.9297 - val_loss: 4.3786\n",
      "Epoch 824/1000\n",
      " - 97s - loss: 3.9084 - val_loss: 3.2665\n",
      "Epoch 825/1000\n",
      " - 96s - loss: 3.9939 - val_loss: 4.3872\n",
      "Epoch 826/1000\n",
      " - 97s - loss: 3.5899 - val_loss: 4.1224\n",
      "Epoch 827/1000\n",
      " - 96s - loss: 4.0250 - val_loss: 4.4854\n",
      "Epoch 828/1000\n",
      " - 97s - loss: 3.9397 - val_loss: 4.9683\n",
      "Epoch 829/1000\n",
      " - 97s - loss: 3.6764 - val_loss: 4.0480\n",
      "Epoch 830/1000\n",
      " - 97s - loss: 4.0891 - val_loss: 4.1779\n",
      "Epoch 831/1000\n",
      " - 97s - loss: 3.7214 - val_loss: 4.1879\n",
      "Epoch 832/1000\n",
      " - 96s - loss: 3.9226 - val_loss: 4.2404\n",
      "Epoch 833/1000\n",
      " - 97s - loss: 4.1701 - val_loss: 4.4524\n",
      "Epoch 834/1000\n",
      " - 97s - loss: 3.5835 - val_loss: 4.4098\n",
      "Epoch 835/1000\n",
      " - 97s - loss: 3.9253 - val_loss: 3.4600\n",
      "Epoch 836/1000\n",
      " - 97s - loss: 3.8108 - val_loss: 4.3728\n",
      "Epoch 837/1000\n",
      " - 96s - loss: 3.9224 - val_loss: 3.7994\n",
      "Epoch 838/1000\n",
      " - 97s - loss: 3.9873 - val_loss: 3.6712\n",
      "Epoch 839/1000\n",
      " - 97s - loss: 3.9551 - val_loss: 4.0745\n",
      "Epoch 840/1000\n",
      " - 97s - loss: 3.8870 - val_loss: 3.9597\n",
      "Epoch 841/1000\n",
      " - 97s - loss: 4.1222 - val_loss: 4.0531\n",
      "Epoch 842/1000\n",
      " - 97s - loss: 4.1859 - val_loss: 3.7749\n",
      "Epoch 843/1000\n",
      " - 97s - loss: 4.2091 - val_loss: 3.6464\n",
      "Epoch 844/1000\n",
      " - 97s - loss: 4.2546 - val_loss: 4.6289\n",
      "Epoch 845/1000\n",
      " - 97s - loss: 3.8885 - val_loss: 3.9006\n",
      "Epoch 846/1000\n",
      " - 97s - loss: 3.9872 - val_loss: 4.1622\n",
      "Epoch 847/1000\n",
      " - 97s - loss: 3.7930 - val_loss: 4.0449\n",
      "Epoch 848/1000\n",
      " - 97s - loss: 4.3693 - val_loss: 4.4578\n",
      "Epoch 849/1000\n",
      " - 97s - loss: 3.8055 - val_loss: 4.1052\n",
      "Epoch 850/1000\n",
      " - 97s - loss: 3.8654 - val_loss: 3.8751\n",
      "Epoch 851/1000\n",
      " - 97s - loss: 3.7410 - val_loss: 3.9261\n",
      "Epoch 852/1000\n",
      " - 97s - loss: 3.5704 - val_loss: 4.8201\n",
      "Epoch 853/1000\n",
      " - 98s - loss: 3.8299 - val_loss: 4.2431\n",
      "Epoch 854/1000\n",
      " - 97s - loss: 3.8301 - val_loss: 4.4655\n",
      "Epoch 855/1000\n",
      " - 98s - loss: 3.7160 - val_loss: 4.2120\n",
      "Epoch 856/1000\n",
      " - 97s - loss: 3.6825 - val_loss: 4.6939\n",
      "Epoch 857/1000\n",
      " - 96s - loss: 4.0533 - val_loss: 3.8753\n",
      "Epoch 858/1000\n",
      " - 97s - loss: 3.8715 - val_loss: 3.9694\n",
      "Epoch 859/1000\n",
      " - 97s - loss: 4.2536 - val_loss: 3.7343\n",
      "Epoch 860/1000\n",
      " - 97s - loss: 4.0597 - val_loss: 4.0637\n",
      "Epoch 861/1000\n",
      " - 97s - loss: 3.6440 - val_loss: 3.8553\n",
      "Epoch 862/1000\n",
      " - 97s - loss: 3.9460 - val_loss: 4.3581\n",
      "Epoch 863/1000\n",
      " - 97s - loss: 3.5803 - val_loss: 4.1027\n",
      "Epoch 864/1000\n",
      " - 97s - loss: 3.7836 - val_loss: 4.4679\n",
      "Epoch 865/1000\n",
      " - 98s - loss: 4.0880 - val_loss: 4.0172\n",
      "Epoch 866/1000\n",
      " - 97s - loss: 4.3398 - val_loss: 4.0730\n",
      "Epoch 867/1000\n",
      " - 97s - loss: 4.0483 - val_loss: 3.8175\n",
      "Epoch 868/1000\n",
      " - 97s - loss: 3.8707 - val_loss: 3.9700\n",
      "Epoch 869/1000\n",
      " - 97s - loss: 3.6384 - val_loss: 3.9411\n",
      "Epoch 870/1000\n",
      " - 97s - loss: 3.5859 - val_loss: 4.1108\n",
      "Epoch 871/1000\n",
      " - 97s - loss: 3.9049 - val_loss: 3.4818\n",
      "Epoch 872/1000\n",
      " - 97s - loss: 3.7773 - val_loss: 4.0538\n",
      "Epoch 873/1000\n",
      " - 98s - loss: 3.8358 - val_loss: 3.8238\n",
      "Epoch 874/1000\n",
      " - 97s - loss: 4.0899 - val_loss: 4.2048\n",
      "Epoch 875/1000\n",
      " - 97s - loss: 4.1143 - val_loss: 4.0207\n",
      "Epoch 876/1000\n",
      " - 97s - loss: 3.7442 - val_loss: 3.8357\n",
      "Epoch 877/1000\n",
      " - 97s - loss: 3.7946 - val_loss: 3.5837\n",
      "Epoch 878/1000\n",
      " - 98s - loss: 3.7294 - val_loss: 4.1731\n",
      "Epoch 879/1000\n",
      " - 97s - loss: 3.8074 - val_loss: 4.0193\n",
      "Epoch 880/1000\n",
      " - 98s - loss: 3.5645 - val_loss: 3.9072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 881/1000\n",
      " - 97s - loss: 3.8964 - val_loss: 4.1098\n",
      "Epoch 882/1000\n",
      " - 97s - loss: 4.2934 - val_loss: 3.8060\n",
      "Epoch 883/1000\n",
      " - 97s - loss: 3.8445 - val_loss: 3.9350\n",
      "Epoch 884/1000\n",
      " - 98s - loss: 3.7265 - val_loss: 3.6361\n",
      "Epoch 885/1000\n",
      " - 97s - loss: 3.7822 - val_loss: 3.6406\n",
      "Epoch 886/1000\n",
      " - 97s - loss: 3.6720 - val_loss: 4.0093\n",
      "Epoch 887/1000\n",
      " - 97s - loss: 3.9161 - val_loss: 4.0428\n",
      "Epoch 888/1000\n",
      " - 97s - loss: 3.9930 - val_loss: 3.8411\n",
      "Epoch 889/1000\n",
      " - 96s - loss: 3.7850 - val_loss: 3.5592\n",
      "Epoch 890/1000\n",
      " - 97s - loss: 3.8588 - val_loss: 4.2071\n",
      "Epoch 891/1000\n",
      " - 97s - loss: 3.8743 - val_loss: 3.9006\n",
      "Epoch 892/1000\n",
      " - 97s - loss: 3.5432 - val_loss: 3.9718\n",
      "Epoch 893/1000\n",
      " - 97s - loss: 3.7233 - val_loss: 4.1916\n",
      "Epoch 894/1000\n",
      " - 97s - loss: 3.6152 - val_loss: 4.7990\n",
      "Epoch 895/1000\n",
      " - 97s - loss: 3.7192 - val_loss: 3.7411\n",
      "Epoch 896/1000\n",
      " - 97s - loss: 3.8323 - val_loss: 3.4386\n",
      "Epoch 897/1000\n",
      " - 97s - loss: 4.0119 - val_loss: 3.9261\n",
      "Epoch 898/1000\n",
      " - 97s - loss: 3.7727 - val_loss: 3.7390\n",
      "Epoch 899/1000\n",
      " - 98s - loss: 3.7466 - val_loss: 4.3424\n",
      "Epoch 900/1000\n",
      " - 96s - loss: 3.8583 - val_loss: 3.1194\n",
      "Epoch 901/1000\n",
      " - 97s - loss: 3.8971 - val_loss: 3.3326\n",
      "Epoch 902/1000\n",
      " - 96s - loss: 3.8616 - val_loss: 4.7291\n",
      "Epoch 903/1000\n",
      " - 97s - loss: 3.5795 - val_loss: 3.3546\n",
      "Epoch 904/1000\n",
      " - 97s - loss: 4.0053 - val_loss: 3.8507\n",
      "Epoch 905/1000\n",
      " - 96s - loss: 3.6550 - val_loss: 3.9389\n",
      "Epoch 906/1000\n",
      " - 97s - loss: 3.6678 - val_loss: 3.5375\n",
      "Epoch 907/1000\n",
      " - 96s - loss: 3.7371 - val_loss: 4.1414\n",
      "Epoch 908/1000\n",
      " - 97s - loss: 3.6995 - val_loss: 3.9822\n",
      "Epoch 909/1000\n",
      " - 97s - loss: 3.7310 - val_loss: 3.5784\n",
      "Epoch 910/1000\n",
      " - 97s - loss: 3.8116 - val_loss: 3.8641\n",
      "Epoch 911/1000\n",
      " - 97s - loss: 3.8855 - val_loss: 4.4815\n",
      "Epoch 912/1000\n",
      " - 97s - loss: 3.7151 - val_loss: 3.5096\n",
      "Epoch 913/1000\n",
      " - 97s - loss: 3.7173 - val_loss: 3.8181\n",
      "Epoch 914/1000\n",
      " - 97s - loss: 3.6293 - val_loss: 4.2543\n",
      "Epoch 915/1000\n",
      " - 97s - loss: 3.7106 - val_loss: 4.0628\n",
      "Epoch 916/1000\n",
      " - 97s - loss: 3.8290 - val_loss: 4.4623\n",
      "Epoch 917/1000\n",
      " - 97s - loss: 3.6311 - val_loss: 3.5799\n",
      "Epoch 918/1000\n",
      " - 97s - loss: 3.6425 - val_loss: 3.6078\n",
      "Epoch 919/1000\n",
      " - 97s - loss: 3.9900 - val_loss: 3.9579\n",
      "Epoch 920/1000\n",
      " - 98s - loss: 3.7620 - val_loss: 4.4907\n",
      "Epoch 921/1000\n",
      " - 97s - loss: 3.9098 - val_loss: 3.6414\n",
      "Epoch 922/1000\n",
      " - 97s - loss: 3.8168 - val_loss: 3.5108\n",
      "Epoch 923/1000\n",
      " - 97s - loss: 3.4055 - val_loss: 3.8785\n",
      "Epoch 924/1000\n",
      " - 96s - loss: 3.8672 - val_loss: 3.6494\n",
      "Epoch 925/1000\n",
      " - 97s - loss: 3.7066 - val_loss: 4.0559\n",
      "Epoch 926/1000\n",
      " - 97s - loss: 3.7564 - val_loss: 3.5995\n",
      "Epoch 927/1000\n",
      " - 97s - loss: 3.9831 - val_loss: 3.8975\n",
      "Epoch 928/1000\n",
      " - 97s - loss: 3.6218 - val_loss: 3.7476\n",
      "Epoch 929/1000\n",
      " - 97s - loss: 3.5049 - val_loss: 4.0309\n",
      "Epoch 930/1000\n",
      " - 96s - loss: 3.4634 - val_loss: 3.9873\n",
      "Epoch 931/1000\n",
      " - 97s - loss: 3.5611 - val_loss: 3.5420\n",
      "Epoch 932/1000\n",
      " - 97s - loss: 3.7788 - val_loss: 4.2867\n",
      "Epoch 933/1000\n",
      " - 97s - loss: 3.5351 - val_loss: 4.1254\n",
      "Epoch 934/1000\n",
      " - 97s - loss: 3.7231 - val_loss: 3.8031\n",
      "Epoch 935/1000\n",
      " - 97s - loss: 3.7638 - val_loss: 3.3144\n",
      "Epoch 936/1000\n",
      " - 96s - loss: 3.6282 - val_loss: 3.6732\n",
      "Epoch 937/1000\n",
      " - 97s - loss: 3.7057 - val_loss: 3.9735\n",
      "Epoch 938/1000\n",
      " - 97s - loss: 3.6017 - val_loss: 4.3362\n",
      "Epoch 939/1000\n",
      " - 96s - loss: 3.8892 - val_loss: 3.6859\n",
      "Epoch 940/1000\n",
      " - 97s - loss: 3.7265 - val_loss: 4.1455\n",
      "Epoch 941/1000\n",
      " - 97s - loss: 3.8906 - val_loss: 3.8405\n",
      "Epoch 942/1000\n",
      " - 96s - loss: 3.6220 - val_loss: 3.8295\n",
      "Epoch 943/1000\n",
      " - 97s - loss: 3.3617 - val_loss: 3.7863\n",
      "Epoch 944/1000\n",
      " - 97s - loss: 3.5891 - val_loss: 4.0926\n",
      "Epoch 945/1000\n",
      " - 97s - loss: 3.4235 - val_loss: 3.3886\n",
      "Epoch 946/1000\n",
      " - 97s - loss: 3.7384 - val_loss: 4.0270\n",
      "Epoch 947/1000\n",
      " - 97s - loss: 3.7597 - val_loss: 4.3630\n",
      "Epoch 948/1000\n",
      " - 96s - loss: 3.8309 - val_loss: 3.7568\n",
      "Epoch 949/1000\n",
      " - 97s - loss: 3.6826 - val_loss: 3.6884\n",
      "Epoch 950/1000\n",
      " - 97s - loss: 3.6784 - val_loss: 3.9293\n",
      "Epoch 951/1000\n",
      " - 97s - loss: 3.8885 - val_loss: 3.3682\n",
      "Epoch 952/1000\n",
      " - 97s - loss: 3.4207 - val_loss: 3.8035\n",
      "Epoch 953/1000\n",
      " - 97s - loss: 3.6539 - val_loss: 3.9385\n",
      "Epoch 954/1000\n",
      " - 96s - loss: 3.5689 - val_loss: 3.7215\n",
      "Epoch 955/1000\n",
      " - 97s - loss: 3.5211 - val_loss: 3.7812\n",
      "Epoch 956/1000\n",
      " - 97s - loss: 3.7258 - val_loss: 4.0188\n",
      "Epoch 957/1000\n",
      " - 97s - loss: 3.6338 - val_loss: 3.6940\n",
      "Epoch 958/1000\n",
      " - 97s - loss: 3.6677 - val_loss: 3.3118\n",
      "Epoch 959/1000\n",
      " - 97s - loss: 3.7559 - val_loss: 3.8109\n",
      "Epoch 960/1000\n",
      " - 97s - loss: 3.5740 - val_loss: 4.0400\n",
      "Epoch 961/1000\n",
      " - 97s - loss: 3.6270 - val_loss: 3.3395\n",
      "Epoch 962/1000\n",
      " - 97s - loss: 3.6904 - val_loss: 4.0137\n",
      "Epoch 963/1000\n",
      " - 97s - loss: 3.5862 - val_loss: 3.6065\n",
      "Epoch 964/1000\n",
      " - 97s - loss: 3.8909 - val_loss: 4.1161\n",
      "Epoch 965/1000\n",
      " - 96s - loss: 3.3809 - val_loss: 3.4065\n",
      "Epoch 966/1000\n",
      " - 97s - loss: 3.6520 - val_loss: 3.5842\n",
      "Epoch 967/1000\n",
      " - 97s - loss: 4.0185 - val_loss: 3.8544\n",
      "Epoch 968/1000\n",
      " - 98s - loss: 3.8899 - val_loss: 3.4234\n",
      "Epoch 969/1000\n",
      " - 97s - loss: 3.4488 - val_loss: 3.5149\n",
      "Epoch 970/1000\n",
      " - 97s - loss: 3.5630 - val_loss: 3.9302\n",
      "Epoch 971/1000\n",
      " - 97s - loss: 3.3155 - val_loss: 3.5248\n",
      "Epoch 972/1000\n",
      " - 97s - loss: 3.5754 - val_loss: 3.9688\n",
      "Epoch 973/1000\n",
      " - 97s - loss: 3.6271 - val_loss: 3.6105\n",
      "Epoch 974/1000\n",
      " - 96s - loss: 3.6732 - val_loss: 3.3226\n",
      "Epoch 975/1000\n",
      " - 97s - loss: 3.4080 - val_loss: 3.6312\n",
      "Epoch 976/1000\n",
      " - 97s - loss: 3.3048 - val_loss: 4.1627\n",
      "Epoch 977/1000\n",
      " - 97s - loss: 3.7612 - val_loss: 3.5751\n",
      "Epoch 978/1000\n",
      " - 97s - loss: 3.6089 - val_loss: 4.4843\n",
      "Epoch 979/1000\n",
      " - 97s - loss: 3.2878 - val_loss: 3.5537\n",
      "Epoch 980/1000\n",
      " - 97s - loss: 3.8829 - val_loss: 3.6028\n",
      "Epoch 981/1000\n",
      " - 97s - loss: 3.6424 - val_loss: 3.5807\n",
      "Epoch 982/1000\n",
      " - 97s - loss: 3.4798 - val_loss: 3.6336\n",
      "Epoch 983/1000\n",
      " - 97s - loss: 3.4627 - val_loss: 4.3720\n",
      "Epoch 984/1000\n",
      " - 97s - loss: 3.4826 - val_loss: 3.7103\n",
      "Epoch 985/1000\n",
      " - 97s - loss: 3.5385 - val_loss: 3.9236\n",
      "Epoch 986/1000\n",
      " - 97s - loss: 3.4650 - val_loss: 3.7148\n",
      "Epoch 987/1000\n",
      " - 97s - loss: 3.5341 - val_loss: 3.4361\n",
      "Epoch 988/1000\n",
      " - 97s - loss: 3.4965 - val_loss: 3.4366\n",
      "Epoch 989/1000\n",
      " - 97s - loss: 3.6954 - val_loss: 3.9810\n",
      "Epoch 990/1000\n",
      " - 97s - loss: 3.4450 - val_loss: 3.8974\n",
      "Epoch 991/1000\n",
      " - 97s - loss: 3.7989 - val_loss: 3.3536\n",
      "Epoch 992/1000\n",
      " - 97s - loss: 3.4096 - val_loss: 4.2612\n",
      "Epoch 993/1000\n",
      " - 97s - loss: 3.7251 - val_loss: 3.0236\n",
      "Epoch 994/1000\n",
      " - 97s - loss: 3.4665 - val_loss: 3.3446\n",
      "Epoch 995/1000\n",
      " - 97s - loss: 4.2328 - val_loss: 3.4423\n",
      "Epoch 996/1000\n",
      " - 97s - loss: 3.7039 - val_loss: 3.7814\n",
      "Epoch 997/1000\n",
      " - 97s - loss: 3.6144 - val_loss: 3.7186\n",
      "Epoch 998/1000\n",
      " - 97s - loss: 3.6250 - val_loss: 3.9513\n",
      "Epoch 999/1000\n",
      " - 97s - loss: 3.9779 - val_loss: 3.4486\n",
      "Epoch 1000/1000\n",
      " - 97s - loss: 3.6070 - val_loss: 4.3693\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = triplet_model.fit_generator(train_generator, steps_per_epoch=67, epochs=1000, \n",
    "                                      validation_data=test_generator, validation_steps=50, \n",
    "                                      verbose=2, callbacks=callbacks)\n",
    "\n",
    "base_model.save(path + '/facenet-model.h5')\n",
    "pickle.dump(history.history, open(path + '/facenet-history.p', 'wb'))\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training process\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.plot(train_loss, label='Training Loss')\n",
    "ax.plot(val_loss, label='Validation Loss')\n",
    "ax.set_title('Loss vs. Epochs', fontsize=16)\n",
    "ax.set_xlabel('Epochs', fontsize=14)\n",
    "ax.set_ylabel('Loss', fontsize=14)\n",
    "ax.legend(fontsize=14)\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
