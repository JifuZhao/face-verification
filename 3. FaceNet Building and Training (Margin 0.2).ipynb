{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, time, random, keras, pickle, gc\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from face_verification.facenet import basenet\n",
    "from face_verification.facenet import triplet_net\n",
    "from face_verification.facenet import triplet_loss\n",
    "from face_verification.facenet import train_triplet_generator\n",
    "from face_verification.facenet import test_triplet_generator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t# person = 8631\t # images = 2113881\n",
      "Test:\t# person =  500\t # images =  116568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0054_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0029_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0202_02.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0037_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0046_01.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                                          path\n",
       "0  n000002  ./images/vgg2_face/train/n000002/0054_01.jpg\n",
       "1  n000002  ./images/vgg2_face/train/n000002/0029_01.jpg\n",
       "2  n000002  ./images/vgg2_face/train/n000002/0202_02.jpg\n",
       "3  n000002  ./images/vgg2_face/train/n000002/0037_01.jpg\n",
       "4  n000002  ./images/vgg2_face/train/n000002/0046_01.jpg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg2_train = pd.read_csv('./images/vgg2_train_path.csv')\n",
    "vgg2_test = pd.read_csv('./images/vgg2_test_path.csv')\n",
    "\n",
    "print('Train:\\t# person ={0:5d}\\t # images ={1:8d}'.format(len(vgg2_train['name'].unique()), \n",
    "                                                           len(vgg2_train)))\n",
    "print('Test:\\t# person ={0:5d}\\t # images ={1:8d}'.format(len(vgg2_test['name'].unique()),\n",
    "                                                          len(vgg2_test)))\n",
    "\n",
    "vgg2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process the train and test dataframe\n",
    "def path_to_list(df):\n",
    "    \"\"\" function to merge df into the name and path list format \"\"\"\n",
    "    paths = list(df['path'].values)\n",
    "    count = len(paths)\n",
    "    \n",
    "    return pd.Series([count, paths], index=['count', 'paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "      <th>paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n000002</td>\n",
       "      <td>198</td>\n",
       "      <td>[./images/vgg2_face/train/n000002/0054_01.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n000003</td>\n",
       "      <td>143</td>\n",
       "      <td>[./images/vgg2_face/train/n000003/0054_01.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n000004</td>\n",
       "      <td>334</td>\n",
       "      <td>[./images/vgg2_face/train/n000004/0054_01.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n000005</td>\n",
       "      <td>67</td>\n",
       "      <td>[./images/vgg2_face/train/n000005/0430_02.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n000006</td>\n",
       "      <td>374</td>\n",
       "      <td>[./images/vgg2_face/train/n000006/0154_01.jpg,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  count                                              paths\n",
       "0  n000002    198  [./images/vgg2_face/train/n000002/0054_01.jpg,...\n",
       "1  n000003    143  [./images/vgg2_face/train/n000003/0054_01.jpg,...\n",
       "2  n000004    334  [./images/vgg2_face/train/n000004/0054_01.jpg,...\n",
       "3  n000005     67  [./images/vgg2_face/train/n000005/0430_02.jpg,...\n",
       "4  n000006    374  [./images/vgg2_face/train/n000006/0154_01.jpg,..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg2_train_df = vgg2_train.groupby('name').apply(path_to_list).reset_index()\n",
    "vgg2_test_df = vgg2_test.groupby('name').apply(path_to_list).reset_index()\n",
    "\n",
    "vgg2_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Triplet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproduciable purpose\n",
    "seed = 42\n",
    "K.clear_session()\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3148: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 102, 102, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 48, 48, 64)   9472        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 48, 48, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 48, 64)   0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 50, 50, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 24, 24, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lrn_1 (Lambda)                  (None, 24, 24, 64)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 24, 24, 64)   4160        lrn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 24, 24, 64)   256         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 24, 24, 64)   0           bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 26, 26, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 24, 24, 192)  110784      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 24, 24, 192)  768         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 24, 192)  0           bn3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lrn_2 (Lambda)                  (None, 24, 24, 192)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 26, 26, 192)  0           lrn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 192)  0           zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_conv1 (Conv2D) (None, 12, 12, 96)   18528       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_conv1 (Conv2D) (None, 12, 12, 16)   3088        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_bn1 (BatchNorm (None, 12, 12, 16)   64          inception_3a_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 12, 96)   0           inception_3a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 12, 12, 16)   0           inception_3a_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 192)    0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 14, 14, 96)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 16, 16, 16)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_pool_conv (Conv2D) (None, 5, 5, 32)     6176        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_conv2 (Conv2D) (None, 12, 12, 32)   12832       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_pool_bn (BatchNorm (None, 5, 5, 32)     128         inception_3a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_1x1_conv (Conv2D)  (None, 12, 12, 64)   12352       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_bn2 (BatchNorm (None, 12, 12, 32)   128         inception_3a_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5, 5, 32)     0           inception_3a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 12, 12, 128)  0           inception_3a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 12, 12, 32)   0           inception_3a_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 12, 12, 32)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 12, 12, 64)   0           inception_3a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 zero_padding2d_7[0][0]           \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_conv1 (Conv2D) (None, 12, 12, 96)   24672       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_conv1 (Conv2D) (None, 12, 12, 32)   8224        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3b_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 12, 12, 96)   0           inception_3b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 12, 12, 32)   0           inception_3b_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 4, 4, 256)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 14, 14, 96)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 16, 16, 32)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_pool_conv (Conv2D) (None, 4, 4, 64)     16448       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_conv2 (Conv2D) (None, 12, 12, 64)   51264       zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_pool_bn (BatchNorm (None, 4, 4, 64)     256         inception_3b_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_1x1_conv (Conv2D)  (None, 12, 12, 64)   16448       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_bn2 (BatchNorm (None, 12, 12, 64)   256         inception_3b_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 64)     0           inception_3b_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 12, 12, 128)  0           inception_3b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 12, 12, 64)   0           inception_3b_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 12, 12, 64)   0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 12, 12, 64)   0           inception_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 12, 12, 320)  0           activation_11[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "                                                                 zero_padding2d_10[0][0]          \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_conv1 (Conv2D) (None, 12, 12, 128)  41088       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_conv1 (Conv2D) (None, 12, 12, 32)   10272       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_bn1 (BatchNorm (None, 12, 12, 128)  512         inception_3c_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3c_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 12, 12, 128)  0           inception_3c_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 12, 12, 32)   0           inception_3c_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 14, 14, 128)  0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 16, 16, 32)   0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_conv2 (Conv2D) (None, 6, 6, 256)    295168      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_bn2 (BatchNorm (None, 6, 6, 256)    1024        inception_3c_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_3c_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 320)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 6, 6, 256)    0           inception_3c_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 6, 6, 64)     0           inception_3c_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 6, 6, 320)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 6, 6, 640)    0           activation_17[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "                                                                 zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_conv1 (Conv2D) (None, 6, 6, 96)     61536       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_conv1 (Conv2D) (None, 6, 6, 32)     20512       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_bn1 (BatchNorm (None, 6, 6, 96)     384         inception_4a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_bn1 (BatchNorm (None, 6, 6, 32)     128         inception_4a_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 6, 6, 96)     0           inception_4a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 6, 6, 32)     0           inception_4a_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 2, 2, 640)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 8, 8, 96)     0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 10, 10, 32)   0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_pool_conv (Conv2D) (None, 2, 2, 128)    82048       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_conv2 (Conv2D) (None, 6, 6, 192)    166080      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_pool_bn (BatchNorm (None, 2, 2, 128)    512         inception_4a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_1x1_conv (Conv2D)  (None, 6, 6, 256)    164096      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_bn2 (BatchNorm (None, 6, 6, 192)    768         inception_4a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_4a_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 2, 128)    0           inception_4a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_1x1_bn (BatchNorma (None, 6, 6, 256)    1024        inception_4a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 6, 6, 192)    0           inception_4a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 6, 6, 64)     0           inception_4a_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 6, 6, 128)    0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 6, 6, 256)    0           inception_4a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 6, 6, 640)    0           activation_21[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "                                                                 zero_padding2d_16[0][0]          \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_conv1 (Conv2D) (None, 6, 6, 160)    102560      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_conv1 (Conv2D) (None, 6, 6, 64)     41024       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_bn1 (BatchNorm (None, 6, 6, 160)    640         inception_4b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_bn1 (BatchNorm (None, 6, 6, 64)     256         inception_4b_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 6, 6, 160)    0           inception_4b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 6, 6, 64)     0           inception_4b_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 8, 8, 160)    0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 10, 10, 64)   0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_conv2 (Conv2D) (None, 3, 3, 256)    368896      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_conv2 (Conv2D) (None, 3, 3, 128)    204928      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_bn2 (BatchNorm (None, 3, 3, 256)    1024        inception_4b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_bn2 (BatchNorm (None, 3, 3, 128)    512         inception_4b_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 640)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 3, 3, 256)    0           inception_4b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 3, 3, 128)    0           inception_4b_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 3, 3, 640)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 1024)   0           activation_27[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_conv1 (Conv2D) (None, 3, 3, 96)     98400       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 3, 3, 96)     0           inception_5a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 1024)   0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 5, 5, 96)     0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_pool_conv (Conv2D) (None, 1, 1, 96)     98400       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_1x1_conv (Conv2D)  (None, 3, 3, 256)    262400      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 1, 1, 96)     0           inception_5a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 3, 3, 384)    0           inception_5a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 3, 3, 96)     0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 3, 3, 256)    0           inception_5a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 3, 3, 736)    0           activation_31[0][0]              \n",
      "                                                                 zero_padding2d_21[0][0]          \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_conv1 (Conv2D) (None, 3, 3, 96)     70752       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 3, 3, 96)     0           inception_5b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 736)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 5, 5, 96)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_pool_conv (Conv2D) (None, 1, 1, 96)     70752       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5b_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_1x1_conv (Conv2D)  (None, 3, 3, 256)    188672      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1, 1, 96)     0           inception_5b_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 3, 3, 384)    0           inception_5b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 3, 3, 96)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 3, 3, 256)    0           inception_5b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 3, 3, 736)    0           activation_35[0][0]              \n",
      "                                                                 zero_padding2d_23[0][0]          \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 736)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 736)          0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 128)          94336       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "norm_layer (Lambda)             (None, 128)          0           dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,743,280\n",
      "Trainable params: 3,733,968\n",
      "Non-trainable params: 9,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the base-cnn model\n",
    "base_model = basenet(output_shape=128)\n",
    "\n",
    "# # visualization\n",
    "# plot_model(base_model, show_shapes=True, to_file='./results/base-model.png')\n",
    "# plot_model(base_model, show_shapes=True, to_file='./results/base-model.pdf')\n",
    "\n",
    "# base-model summary\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 128)          3743280     anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Lambda)                 (None, 3, 128)       0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,743,280\n",
      "Trainable params: 3,733,968\n",
      "Non-trainable params: 9,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the triplet-network model\n",
    "triplet_model = triplet_net(base_model=base_model, input_shape=(96, 96, 3))\n",
    "\n",
    "# # visualization\n",
    "# plot_model(triplet_model, show_shapes=True, to_file='./results/triplet-model.png')\n",
    "# plot_model(triplet_model, show_shapes=True, to_file='./results/triplet-model.pdf')\n",
    "\n",
    "# base-model summary\n",
    "triplet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define learning scheduler\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\" Learning rate schedule \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 900:\n",
    "        lr *= 1e-1\n",
    "    elif epoch > 800:\n",
    "        lr *= 2e-1\n",
    "    elif epoch > 700:\n",
    "        lr *= 3e-1\n",
    "    elif epoch > 600:\n",
    "        lr *= 4e-1\n",
    "    elif epoch > 500:\n",
    "        lr *= 5e-1\n",
    "    elif epoch > 400:\n",
    "        lr *= 6e-1\n",
    "    elif epoch > 300:\n",
    "        lr *= 7e-1\n",
    "    elif epoch > 200:\n",
    "        lr *= 8e-1\n",
    "    elif epoch > 100:\n",
    "        lr *= 9e-1\n",
    "        \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoing Folder:\t ./models/margin-02-20180802-1957\n"
     ]
    }
   ],
   "source": [
    "# define optimizer\n",
    "opt = keras.optimizers.Adam(lr=lr_schedule(0))\n",
    "\n",
    "# create checkpoint folder\n",
    "path = './models/margin-02-' + time.strftime('%Y%m%d-%H%M')\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "print('Checkpoing Folder:\\t', path)    \n",
    "\n",
    "# create call backs\n",
    "checkpoint = ModelCheckpoint(filepath=path + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                             monitor='val_loss', verbose=0, save_best_only=False, \n",
    "                             save_weights_only=False, mode='auto', period=10)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# compile the model\n",
    "triplet_model.compile(optimizer=opt, loss=triplet_loss(0.2))\n",
    "\n",
    "# define training and test dataset image generator\n",
    "train_generator = train_triplet_generator(vgg2_train_df, batch_size=128)\n",
    "test_generator = test_triplet_generator(vgg2_test_df, batch_size=100, loops=10, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 124s - loss: 19.8618 - val_loss: 16.0560\n",
      "Epoch 2/1000\n",
      " - 103s - loss: 15.7596 - val_loss: 15.7850\n",
      "Epoch 3/1000\n",
      " - 103s - loss: 13.8527 - val_loss: 11.9734\n",
      "Epoch 4/1000\n",
      " - 101s - loss: 12.5798 - val_loss: 11.1762\n",
      "Epoch 5/1000\n",
      " - 101s - loss: 11.3098 - val_loss: 14.9872\n",
      "Epoch 6/1000\n",
      " - 99s - loss: 11.4714 - val_loss: 9.2701\n",
      "Epoch 7/1000\n",
      " - 99s - loss: 10.9632 - val_loss: 11.3390\n",
      "Epoch 8/1000\n",
      " - 98s - loss: 10.7864 - val_loss: 9.3514\n",
      "Epoch 9/1000\n",
      " - 99s - loss: 10.1882 - val_loss: 9.2702\n",
      "Epoch 10/1000\n",
      " - 98s - loss: 9.6797 - val_loss: 8.9340\n",
      "Epoch 11/1000\n",
      " - 97s - loss: 9.4611 - val_loss: 8.5470\n",
      "Epoch 12/1000\n",
      " - 98s - loss: 9.3595 - val_loss: 11.4402\n",
      "Epoch 13/1000\n",
      " - 98s - loss: 9.0354 - val_loss: 9.0181\n",
      "Epoch 14/1000\n",
      " - 99s - loss: 9.2023 - val_loss: 9.2022\n",
      "Epoch 15/1000\n",
      " - 97s - loss: 8.9433 - val_loss: 8.7046\n",
      "Epoch 16/1000\n",
      " - 97s - loss: 8.6497 - val_loss: 8.2774\n",
      "Epoch 17/1000\n",
      " - 98s - loss: 8.7548 - val_loss: 10.9333\n",
      "Epoch 18/1000\n",
      " - 98s - loss: 8.1278 - val_loss: 7.5328\n",
      "Epoch 19/1000\n",
      " - 98s - loss: 8.2473 - val_loss: 8.1141\n",
      "Epoch 20/1000\n",
      " - 98s - loss: 8.2000 - val_loss: 8.2895\n",
      "Epoch 21/1000\n",
      " - 98s - loss: 7.9662 - val_loss: 6.8645\n",
      "Epoch 22/1000\n",
      " - 96s - loss: 7.7695 - val_loss: 7.7668\n",
      "Epoch 23/1000\n",
      " - 98s - loss: 8.2196 - val_loss: 7.7999\n",
      "Epoch 24/1000\n",
      " - 97s - loss: 7.4322 - val_loss: 9.7295\n",
      "Epoch 25/1000\n",
      " - 97s - loss: 7.4161 - val_loss: 6.5902\n",
      "Epoch 26/1000\n",
      " - 96s - loss: 7.2508 - val_loss: 7.3416\n",
      "Epoch 27/1000\n",
      " - 97s - loss: 7.1442 - val_loss: 6.2879\n",
      "Epoch 28/1000\n",
      " - 97s - loss: 7.3017 - val_loss: 6.9110\n",
      "Epoch 29/1000\n",
      " - 96s - loss: 7.1257 - val_loss: 7.1783\n",
      "Epoch 30/1000\n",
      " - 97s - loss: 7.0805 - val_loss: 7.1089\n",
      "Epoch 31/1000\n",
      " - 97s - loss: 6.8929 - val_loss: 6.5422\n",
      "Epoch 32/1000\n",
      " - 97s - loss: 6.7495 - val_loss: 7.2335\n",
      "Epoch 33/1000\n",
      " - 97s - loss: 6.8203 - val_loss: 6.2395\n",
      "Epoch 34/1000\n",
      " - 96s - loss: 7.2218 - val_loss: 5.9908\n",
      "Epoch 35/1000\n",
      " - 96s - loss: 6.7495 - val_loss: 7.1468\n",
      "Epoch 36/1000\n",
      " - 96s - loss: 6.9399 - val_loss: 6.2732\n",
      "Epoch 37/1000\n",
      " - 96s - loss: 6.6952 - val_loss: 6.0584\n",
      "Epoch 38/1000\n",
      " - 96s - loss: 6.4280 - val_loss: 6.7012\n",
      "Epoch 39/1000\n",
      " - 96s - loss: 6.5090 - val_loss: 6.6487\n",
      "Epoch 40/1000\n",
      " - 97s - loss: 6.3345 - val_loss: 5.9670\n",
      "Epoch 41/1000\n",
      " - 96s - loss: 6.3695 - val_loss: 7.2094\n",
      "Epoch 42/1000\n",
      " - 96s - loss: 6.1448 - val_loss: 5.6650\n",
      "Epoch 43/1000\n",
      " - 96s - loss: 6.3640 - val_loss: 5.9369\n",
      "Epoch 44/1000\n",
      " - 96s - loss: 6.2714 - val_loss: 6.2570\n",
      "Epoch 45/1000\n",
      " - 97s - loss: 6.2788 - val_loss: 5.2818\n",
      "Epoch 46/1000\n",
      " - 96s - loss: 6.0386 - val_loss: 5.9629\n",
      "Epoch 47/1000\n",
      " - 96s - loss: 6.2178 - val_loss: 6.2282\n",
      "Epoch 48/1000\n",
      " - 97s - loss: 6.3471 - val_loss: 5.6800\n",
      "Epoch 49/1000\n",
      " - 96s - loss: 6.1041 - val_loss: 5.8017\n",
      "Epoch 50/1000\n",
      " - 96s - loss: 6.0367 - val_loss: 4.7908\n",
      "Epoch 51/1000\n",
      " - 97s - loss: 5.6822 - val_loss: 6.3118\n",
      "Epoch 52/1000\n",
      " - 97s - loss: 5.9396 - val_loss: 7.2391\n",
      "Epoch 53/1000\n",
      " - 97s - loss: 5.9856 - val_loss: 5.8925\n",
      "Epoch 54/1000\n",
      " - 97s - loss: 5.8476 - val_loss: 4.7908\n",
      "Epoch 55/1000\n",
      " - 96s - loss: 5.7282 - val_loss: 5.2601\n",
      "Epoch 56/1000\n",
      " - 97s - loss: 5.8211 - val_loss: 5.9019\n",
      "Epoch 57/1000\n",
      " - 96s - loss: 5.5927 - val_loss: 5.1762\n",
      "Epoch 58/1000\n",
      " - 97s - loss: 5.8381 - val_loss: 5.6791\n",
      "Epoch 59/1000\n",
      " - 97s - loss: 5.5062 - val_loss: 5.7250\n",
      "Epoch 60/1000\n",
      " - 96s - loss: 5.6234 - val_loss: 5.1016\n",
      "Epoch 61/1000\n",
      " - 97s - loss: 5.5760 - val_loss: 5.2490\n",
      "Epoch 62/1000\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = triplet_model.fit_generator(train_generator, steps_per_epoch=67, epochs=1000, \n",
    "                                      validation_data=test_generator, validation_steps=50, \n",
    "                                      verbose=2, callbacks=callbacks)\n",
    "\n",
    "base_model.save(path + '/facenet-model.h5')\n",
    "pickle.dump(history.history, open(path + '/facenet-history.p', 'wb'))\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training process\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.plot(train_loss, label='Training Loss')\n",
    "ax.plot(val_loss, label='Validation Loss')\n",
    "ax.set_title('Loss vs. Epochs', fontsize=16)\n",
    "ax.set_xlabel('Epochs', fontsize=14)\n",
    "ax.set_ylabel('Loss', fontsize=14)\n",
    "ax.legend(fontsize=14)\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
