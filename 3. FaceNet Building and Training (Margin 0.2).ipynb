{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, time, random, keras, pickle, gc\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from face_verification.facenet import basenet\n",
    "from face_verification.facenet import triplet_net\n",
    "from face_verification.facenet import triplet_loss\n",
    "from face_verification.facenet import train_triplet_generator\n",
    "from face_verification.facenet import test_triplet_generator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t# person = 8631\t # images = 2113881\n",
      "Test:\t# person =  500\t # images =  116568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0054_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0029_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0202_02.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0037_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0046_01.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                                          path\n",
       "0  n000002  ./images/vgg2_face/train/n000002/0054_01.jpg\n",
       "1  n000002  ./images/vgg2_face/train/n000002/0029_01.jpg\n",
       "2  n000002  ./images/vgg2_face/train/n000002/0202_02.jpg\n",
       "3  n000002  ./images/vgg2_face/train/n000002/0037_01.jpg\n",
       "4  n000002  ./images/vgg2_face/train/n000002/0046_01.jpg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg2_train = pd.read_csv('./images/vgg2_train_path.csv')\n",
    "vgg2_test = pd.read_csv('./images/vgg2_test_path.csv')\n",
    "\n",
    "print('Train:\\t# person ={0:5d}\\t # images ={1:8d}'.format(len(vgg2_train['name'].unique()), \n",
    "                                                           len(vgg2_train)))\n",
    "print('Test:\\t# person ={0:5d}\\t # images ={1:8d}'.format(len(vgg2_test['name'].unique()),\n",
    "                                                          len(vgg2_test)))\n",
    "\n",
    "vgg2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process the train and test dataframe\n",
    "def path_to_list(df):\n",
    "    \"\"\" function to merge df into the name and path list format \"\"\"\n",
    "    paths = list(df['path'].values)\n",
    "    count = len(paths)\n",
    "    \n",
    "    return pd.Series([count, paths], index=['count', 'paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "      <th>paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n000002</td>\n",
       "      <td>198</td>\n",
       "      <td>[./images/vgg2_face/train/n000002/0054_01.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n000003</td>\n",
       "      <td>143</td>\n",
       "      <td>[./images/vgg2_face/train/n000003/0054_01.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n000004</td>\n",
       "      <td>334</td>\n",
       "      <td>[./images/vgg2_face/train/n000004/0054_01.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n000005</td>\n",
       "      <td>67</td>\n",
       "      <td>[./images/vgg2_face/train/n000005/0430_02.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n000006</td>\n",
       "      <td>374</td>\n",
       "      <td>[./images/vgg2_face/train/n000006/0154_01.jpg,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  count                                              paths\n",
       "0  n000002    198  [./images/vgg2_face/train/n000002/0054_01.jpg,...\n",
       "1  n000003    143  [./images/vgg2_face/train/n000003/0054_01.jpg,...\n",
       "2  n000004    334  [./images/vgg2_face/train/n000004/0054_01.jpg,...\n",
       "3  n000005     67  [./images/vgg2_face/train/n000005/0430_02.jpg,...\n",
       "4  n000006    374  [./images/vgg2_face/train/n000006/0154_01.jpg,..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg2_train_df = vgg2_train.groupby('name').apply(path_to_list).reset_index()\n",
    "vgg2_test_df = vgg2_test.groupby('name').apply(path_to_list).reset_index()\n",
    "\n",
    "vgg2_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Triplet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproduciable purpose\n",
    "seed = 42\n",
    "K.clear_session()\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3148: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 102, 102, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 48, 48, 64)   9472        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 48, 48, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 48, 64)   0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 50, 50, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 24, 24, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lrn_1 (Lambda)                  (None, 24, 24, 64)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 24, 24, 64)   4160        lrn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 24, 24, 64)   256         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 24, 24, 64)   0           bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 26, 26, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 24, 24, 192)  110784      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 24, 24, 192)  768         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 24, 192)  0           bn3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lrn_2 (Lambda)                  (None, 24, 24, 192)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 26, 26, 192)  0           lrn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 192)  0           zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_conv1 (Conv2D) (None, 12, 12, 96)   18528       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_conv1 (Conv2D) (None, 12, 12, 16)   3088        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_bn1 (BatchNorm (None, 12, 12, 16)   64          inception_3a_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 12, 96)   0           inception_3a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 12, 12, 16)   0           inception_3a_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 192)    0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 14, 14, 96)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 16, 16, 16)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_pool_conv (Conv2D) (None, 5, 5, 32)     6176        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_conv2 (Conv2D) (None, 12, 12, 32)   12832       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_pool_bn (BatchNorm (None, 5, 5, 32)     128         inception_3a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_1x1_conv (Conv2D)  (None, 12, 12, 64)   12352       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_bn2 (BatchNorm (None, 12, 12, 32)   128         inception_3a_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5, 5, 32)     0           inception_3a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 12, 12, 128)  0           inception_3a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 12, 12, 32)   0           inception_3a_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 12, 12, 32)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 12, 12, 64)   0           inception_3a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 zero_padding2d_7[0][0]           \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_conv1 (Conv2D) (None, 12, 12, 96)   24672       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_conv1 (Conv2D) (None, 12, 12, 32)   8224        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3b_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 12, 12, 96)   0           inception_3b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 12, 12, 32)   0           inception_3b_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 4, 4, 256)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 14, 14, 96)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 16, 16, 32)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_pool_conv (Conv2D) (None, 4, 4, 64)     16448       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_conv2 (Conv2D) (None, 12, 12, 64)   51264       zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_pool_bn (BatchNorm (None, 4, 4, 64)     256         inception_3b_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_1x1_conv (Conv2D)  (None, 12, 12, 64)   16448       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_bn2 (BatchNorm (None, 12, 12, 64)   256         inception_3b_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 64)     0           inception_3b_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 12, 12, 128)  0           inception_3b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 12, 12, 64)   0           inception_3b_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 12, 12, 64)   0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 12, 12, 64)   0           inception_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 12, 12, 320)  0           activation_11[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "                                                                 zero_padding2d_10[0][0]          \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_conv1 (Conv2D) (None, 12, 12, 128)  41088       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_conv1 (Conv2D) (None, 12, 12, 32)   10272       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_bn1 (BatchNorm (None, 12, 12, 128)  512         inception_3c_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3c_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 12, 12, 128)  0           inception_3c_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 12, 12, 32)   0           inception_3c_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 14, 14, 128)  0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 16, 16, 32)   0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_conv2 (Conv2D) (None, 6, 6, 256)    295168      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_bn2 (BatchNorm (None, 6, 6, 256)    1024        inception_3c_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_3c_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 320)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 6, 6, 256)    0           inception_3c_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 6, 6, 64)     0           inception_3c_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 6, 6, 320)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 6, 6, 640)    0           activation_17[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "                                                                 zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_conv1 (Conv2D) (None, 6, 6, 96)     61536       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_conv1 (Conv2D) (None, 6, 6, 32)     20512       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_bn1 (BatchNorm (None, 6, 6, 96)     384         inception_4a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_bn1 (BatchNorm (None, 6, 6, 32)     128         inception_4a_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 6, 6, 96)     0           inception_4a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 6, 6, 32)     0           inception_4a_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 2, 2, 640)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 8, 8, 96)     0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 10, 10, 32)   0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_pool_conv (Conv2D) (None, 2, 2, 128)    82048       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_conv2 (Conv2D) (None, 6, 6, 192)    166080      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_pool_bn (BatchNorm (None, 2, 2, 128)    512         inception_4a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_1x1_conv (Conv2D)  (None, 6, 6, 256)    164096      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_bn2 (BatchNorm (None, 6, 6, 192)    768         inception_4a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_4a_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 2, 128)    0           inception_4a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_1x1_bn (BatchNorma (None, 6, 6, 256)    1024        inception_4a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 6, 6, 192)    0           inception_4a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 6, 6, 64)     0           inception_4a_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 6, 6, 128)    0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 6, 6, 256)    0           inception_4a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 6, 6, 640)    0           activation_21[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "                                                                 zero_padding2d_16[0][0]          \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_conv1 (Conv2D) (None, 6, 6, 160)    102560      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_conv1 (Conv2D) (None, 6, 6, 64)     41024       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_bn1 (BatchNorm (None, 6, 6, 160)    640         inception_4b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_bn1 (BatchNorm (None, 6, 6, 64)     256         inception_4b_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 6, 6, 160)    0           inception_4b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 6, 6, 64)     0           inception_4b_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 8, 8, 160)    0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 10, 10, 64)   0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_conv2 (Conv2D) (None, 3, 3, 256)    368896      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_conv2 (Conv2D) (None, 3, 3, 128)    204928      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_bn2 (BatchNorm (None, 3, 3, 256)    1024        inception_4b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_bn2 (BatchNorm (None, 3, 3, 128)    512         inception_4b_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 640)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 3, 3, 256)    0           inception_4b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 3, 3, 128)    0           inception_4b_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 3, 3, 640)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 1024)   0           activation_27[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_conv1 (Conv2D) (None, 3, 3, 96)     98400       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 3, 3, 96)     0           inception_5a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 1024)   0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 5, 5, 96)     0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_pool_conv (Conv2D) (None, 1, 1, 96)     98400       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_1x1_conv (Conv2D)  (None, 3, 3, 256)    262400      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 1, 1, 96)     0           inception_5a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 3, 3, 384)    0           inception_5a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 3, 3, 96)     0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 3, 3, 256)    0           inception_5a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 3, 3, 736)    0           activation_31[0][0]              \n",
      "                                                                 zero_padding2d_21[0][0]          \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_conv1 (Conv2D) (None, 3, 3, 96)     70752       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 3, 3, 96)     0           inception_5b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 736)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 5, 5, 96)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_pool_conv (Conv2D) (None, 1, 1, 96)     70752       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5b_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_1x1_conv (Conv2D)  (None, 3, 3, 256)    188672      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1, 1, 96)     0           inception_5b_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 3, 3, 384)    0           inception_5b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 3, 3, 96)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 3, 3, 256)    0           inception_5b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 3, 3, 736)    0           activation_35[0][0]              \n",
      "                                                                 zero_padding2d_23[0][0]          \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 736)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 736)          0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 128)          94336       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "norm_layer (Lambda)             (None, 128)          0           dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,743,280\n",
      "Trainable params: 3,733,968\n",
      "Non-trainable params: 9,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the base-cnn model\n",
    "base_model = basenet(output_shape=128)\n",
    "\n",
    "# # visualization\n",
    "# plot_model(base_model, show_shapes=True, to_file='./results/base-model.png')\n",
    "# plot_model(base_model, show_shapes=True, to_file='./results/base-model.pdf')\n",
    "\n",
    "# base-model summary\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 128)          3743280     anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Lambda)                 (None, 3, 128)       0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,743,280\n",
      "Trainable params: 3,733,968\n",
      "Non-trainable params: 9,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the triplet-network model\n",
    "triplet_model = triplet_net(base_model=base_model, input_shape=(96, 96, 3))\n",
    "\n",
    "# # visualization\n",
    "# plot_model(triplet_model, show_shapes=True, to_file='./results/triplet-model.png')\n",
    "# plot_model(triplet_model, show_shapes=True, to_file='./results/triplet-model.pdf')\n",
    "\n",
    "# base-model summary\n",
    "triplet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define learning scheduler\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\" Learning rate schedule \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 900:\n",
    "        lr *= 1e-1\n",
    "    elif epoch > 800:\n",
    "        lr *= 2e-1\n",
    "    elif epoch > 700:\n",
    "        lr *= 3e-1\n",
    "    elif epoch > 600:\n",
    "        lr *= 4e-1\n",
    "    elif epoch > 500:\n",
    "        lr *= 5e-1\n",
    "    elif epoch > 400:\n",
    "        lr *= 6e-1\n",
    "    elif epoch > 300:\n",
    "        lr *= 7e-1\n",
    "    elif epoch > 200:\n",
    "        lr *= 8e-1\n",
    "    elif epoch > 100:\n",
    "        lr *= 9e-1\n",
    "        \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoing Folder:\t ./models/margin-02-20180802-1957\n"
     ]
    }
   ],
   "source": [
    "# define optimizer\n",
    "opt = keras.optimizers.Adam(lr=lr_schedule(0))\n",
    "\n",
    "# create checkpoint folder\n",
    "path = './models/margin-02-' + time.strftime('%Y%m%d-%H%M')\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "print('Checkpoing Folder:\\t', path)    \n",
    "\n",
    "# create call backs\n",
    "checkpoint = ModelCheckpoint(filepath=path + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                             monitor='val_loss', verbose=0, save_best_only=False, \n",
    "                             save_weights_only=False, mode='auto', period=10)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# compile the model\n",
    "triplet_model.compile(optimizer=opt, loss=triplet_loss(0.2))\n",
    "\n",
    "# define training and test dataset image generator\n",
    "train_generator = train_triplet_generator(vgg2_train_df, batch_size=128)\n",
    "test_generator = test_triplet_generator(vgg2_test_df, batch_size=100, loops=10, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 124s - loss: 19.8618 - val_loss: 16.0560\n",
      "Epoch 2/1000\n",
      " - 103s - loss: 15.7596 - val_loss: 15.7850\n",
      "Epoch 3/1000\n",
      " - 103s - loss: 13.8527 - val_loss: 11.9734\n",
      "Epoch 4/1000\n",
      " - 101s - loss: 12.5798 - val_loss: 11.1762\n",
      "Epoch 5/1000\n",
      " - 101s - loss: 11.3098 - val_loss: 14.9872\n",
      "Epoch 6/1000\n",
      " - 99s - loss: 11.4714 - val_loss: 9.2701\n",
      "Epoch 7/1000\n",
      " - 99s - loss: 10.9632 - val_loss: 11.3390\n",
      "Epoch 8/1000\n",
      " - 98s - loss: 10.7864 - val_loss: 9.3514\n",
      "Epoch 9/1000\n",
      " - 99s - loss: 10.1882 - val_loss: 9.2702\n",
      "Epoch 10/1000\n",
      " - 98s - loss: 9.6797 - val_loss: 8.9340\n",
      "Epoch 11/1000\n",
      " - 97s - loss: 9.4611 - val_loss: 8.5470\n",
      "Epoch 12/1000\n",
      " - 98s - loss: 9.3595 - val_loss: 11.4402\n",
      "Epoch 13/1000\n",
      " - 98s - loss: 9.0354 - val_loss: 9.0181\n",
      "Epoch 14/1000\n",
      " - 99s - loss: 9.2023 - val_loss: 9.2022\n",
      "Epoch 15/1000\n",
      " - 97s - loss: 8.9433 - val_loss: 8.7046\n",
      "Epoch 16/1000\n",
      " - 97s - loss: 8.6497 - val_loss: 8.2774\n",
      "Epoch 17/1000\n",
      " - 98s - loss: 8.7548 - val_loss: 10.9333\n",
      "Epoch 18/1000\n",
      " - 98s - loss: 8.1278 - val_loss: 7.5328\n",
      "Epoch 19/1000\n",
      " - 98s - loss: 8.2473 - val_loss: 8.1141\n",
      "Epoch 20/1000\n",
      " - 98s - loss: 8.2000 - val_loss: 8.2895\n",
      "Epoch 21/1000\n",
      " - 98s - loss: 7.9662 - val_loss: 6.8645\n",
      "Epoch 22/1000\n",
      " - 96s - loss: 7.7695 - val_loss: 7.7668\n",
      "Epoch 23/1000\n",
      " - 98s - loss: 8.2196 - val_loss: 7.7999\n",
      "Epoch 24/1000\n",
      " - 97s - loss: 7.4322 - val_loss: 9.7295\n",
      "Epoch 25/1000\n",
      " - 97s - loss: 7.4161 - val_loss: 6.5902\n",
      "Epoch 26/1000\n",
      " - 96s - loss: 7.2508 - val_loss: 7.3416\n",
      "Epoch 27/1000\n",
      " - 97s - loss: 7.1442 - val_loss: 6.2879\n",
      "Epoch 28/1000\n",
      " - 97s - loss: 7.3017 - val_loss: 6.9110\n",
      "Epoch 29/1000\n",
      " - 96s - loss: 7.1257 - val_loss: 7.1783\n",
      "Epoch 30/1000\n",
      " - 97s - loss: 7.0805 - val_loss: 7.1089\n",
      "Epoch 31/1000\n",
      " - 97s - loss: 6.8929 - val_loss: 6.5422\n",
      "Epoch 32/1000\n",
      " - 97s - loss: 6.7495 - val_loss: 7.2335\n",
      "Epoch 33/1000\n",
      " - 97s - loss: 6.8203 - val_loss: 6.2395\n",
      "Epoch 34/1000\n",
      " - 96s - loss: 7.2218 - val_loss: 5.9908\n",
      "Epoch 35/1000\n",
      " - 96s - loss: 6.7495 - val_loss: 7.1468\n",
      "Epoch 36/1000\n",
      " - 96s - loss: 6.9399 - val_loss: 6.2732\n",
      "Epoch 37/1000\n",
      " - 96s - loss: 6.6952 - val_loss: 6.0584\n",
      "Epoch 38/1000\n",
      " - 96s - loss: 6.4280 - val_loss: 6.7012\n",
      "Epoch 39/1000\n",
      " - 96s - loss: 6.5090 - val_loss: 6.6487\n",
      "Epoch 40/1000\n",
      " - 97s - loss: 6.3345 - val_loss: 5.9670\n",
      "Epoch 41/1000\n",
      " - 96s - loss: 6.3695 - val_loss: 7.2094\n",
      "Epoch 42/1000\n",
      " - 96s - loss: 6.1448 - val_loss: 5.6650\n",
      "Epoch 43/1000\n",
      " - 96s - loss: 6.3640 - val_loss: 5.9369\n",
      "Epoch 44/1000\n",
      " - 96s - loss: 6.2714 - val_loss: 6.2570\n",
      "Epoch 45/1000\n",
      " - 97s - loss: 6.2788 - val_loss: 5.2818\n",
      "Epoch 46/1000\n",
      " - 96s - loss: 6.0386 - val_loss: 5.9629\n",
      "Epoch 47/1000\n",
      " - 96s - loss: 6.2178 - val_loss: 6.2282\n",
      "Epoch 48/1000\n",
      " - 97s - loss: 6.3471 - val_loss: 5.6800\n",
      "Epoch 49/1000\n",
      " - 96s - loss: 6.1041 - val_loss: 5.8017\n",
      "Epoch 50/1000\n",
      " - 96s - loss: 6.0367 - val_loss: 4.7908\n",
      "Epoch 51/1000\n",
      " - 97s - loss: 5.6822 - val_loss: 6.3118\n",
      "Epoch 52/1000\n",
      " - 97s - loss: 5.9396 - val_loss: 7.2391\n",
      "Epoch 53/1000\n",
      " - 97s - loss: 5.9856 - val_loss: 5.8925\n",
      "Epoch 54/1000\n",
      " - 97s - loss: 5.8476 - val_loss: 4.7908\n",
      "Epoch 55/1000\n",
      " - 96s - loss: 5.7282 - val_loss: 5.2601\n",
      "Epoch 56/1000\n",
      " - 97s - loss: 5.8211 - val_loss: 5.9019\n",
      "Epoch 57/1000\n",
      " - 96s - loss: 5.5927 - val_loss: 5.1762\n",
      "Epoch 58/1000\n",
      " - 97s - loss: 5.8381 - val_loss: 5.6791\n",
      "Epoch 59/1000\n",
      " - 97s - loss: 5.5062 - val_loss: 5.7250\n",
      "Epoch 60/1000\n",
      " - 96s - loss: 5.6234 - val_loss: 5.1016\n",
      "Epoch 61/1000\n",
      " - 97s - loss: 5.5760 - val_loss: 5.2490\n",
      "Epoch 62/1000\n",
      " - 97s - loss: 5.9099 - val_loss: 5.8785\n",
      "Epoch 63/1000\n",
      " - 97s - loss: 5.3630 - val_loss: 5.8362\n",
      "Epoch 64/1000\n",
      " - 97s - loss: 5.2131 - val_loss: 6.0384\n",
      "Epoch 65/1000\n",
      " - 97s - loss: 5.6288 - val_loss: 5.4828\n",
      "Epoch 66/1000\n",
      " - 97s - loss: 5.5633 - val_loss: 5.6577\n",
      "Epoch 67/1000\n",
      " - 96s - loss: 5.5150 - val_loss: 4.3241\n",
      "Epoch 68/1000\n",
      " - 97s - loss: 5.7903 - val_loss: 4.6907\n",
      "Epoch 69/1000\n",
      " - 97s - loss: 5.1856 - val_loss: 5.0502\n",
      "Epoch 70/1000\n",
      " - 97s - loss: 5.5532 - val_loss: 6.5471\n",
      "Epoch 71/1000\n",
      " - 97s - loss: 5.3257 - val_loss: 5.1730\n",
      "Epoch 72/1000\n",
      " - 97s - loss: 5.0833 - val_loss: 5.2854\n",
      "Epoch 73/1000\n",
      " - 97s - loss: 5.3690 - val_loss: 4.7328\n",
      "Epoch 74/1000\n",
      " - 97s - loss: 5.3812 - val_loss: 4.9837\n",
      "Epoch 75/1000\n",
      " - 97s - loss: 5.1447 - val_loss: 5.0710\n",
      "Epoch 76/1000\n",
      " - 97s - loss: 5.1167 - val_loss: 6.2845\n",
      "Epoch 77/1000\n",
      " - 97s - loss: 5.3252 - val_loss: 4.6006\n",
      "Epoch 78/1000\n",
      " - 97s - loss: 4.9853 - val_loss: 5.1241\n",
      "Epoch 79/1000\n",
      " - 97s - loss: 4.9792 - val_loss: 4.7827\n",
      "Epoch 80/1000\n",
      " - 97s - loss: 5.1617 - val_loss: 4.5462\n",
      "Epoch 81/1000\n",
      " - 97s - loss: 5.0651 - val_loss: 5.0128\n",
      "Epoch 82/1000\n",
      " - 97s - loss: 5.3535 - val_loss: 4.9392\n",
      "Epoch 83/1000\n",
      " - 97s - loss: 5.0210 - val_loss: 4.5405\n",
      "Epoch 84/1000\n",
      " - 96s - loss: 5.0307 - val_loss: 4.8218\n",
      "Epoch 85/1000\n",
      " - 97s - loss: 5.0270 - val_loss: 4.7936\n",
      "Epoch 86/1000\n",
      " - 97s - loss: 5.1336 - val_loss: 4.1888\n",
      "Epoch 87/1000\n",
      " - 97s - loss: 4.7118 - val_loss: 4.8383\n",
      "Epoch 88/1000\n",
      " - 96s - loss: 4.8594 - val_loss: 5.1470\n",
      "Epoch 89/1000\n",
      " - 96s - loss: 5.1180 - val_loss: 4.7815\n",
      "Epoch 90/1000\n",
      " - 96s - loss: 5.1045 - val_loss: 4.5085\n",
      "Epoch 91/1000\n",
      " - 96s - loss: 4.8490 - val_loss: 5.2812\n",
      "Epoch 92/1000\n",
      " - 96s - loss: 4.7913 - val_loss: 5.1695\n",
      "Epoch 93/1000\n",
      " - 96s - loss: 4.8969 - val_loss: 5.5771\n",
      "Epoch 94/1000\n",
      " - 97s - loss: 4.8431 - val_loss: 4.7420\n",
      "Epoch 95/1000\n",
      " - 97s - loss: 4.7164 - val_loss: 4.4856\n",
      "Epoch 96/1000\n",
      " - 96s - loss: 4.8600 - val_loss: 4.7014\n",
      "Epoch 97/1000\n",
      " - 97s - loss: 4.9370 - val_loss: 3.9802\n",
      "Epoch 98/1000\n",
      " - 96s - loss: 4.9202 - val_loss: 5.3001\n",
      "Epoch 99/1000\n",
      " - 96s - loss: 4.8524 - val_loss: 4.9372\n",
      "Epoch 100/1000\n",
      " - 97s - loss: 4.7297 - val_loss: 4.3553\n",
      "Epoch 101/1000\n",
      " - 97s - loss: 4.8782 - val_loss: 4.3433\n",
      "Epoch 102/1000\n",
      " - 97s - loss: 4.6884 - val_loss: 4.6041\n",
      "Epoch 103/1000\n",
      " - 97s - loss: 4.6517 - val_loss: 5.3351\n",
      "Epoch 104/1000\n",
      " - 96s - loss: 4.6736 - val_loss: 4.2755\n",
      "Epoch 105/1000\n",
      " - 96s - loss: 4.3530 - val_loss: 4.1281\n",
      "Epoch 106/1000\n",
      " - 96s - loss: 4.5463 - val_loss: 4.6478\n",
      "Epoch 107/1000\n",
      " - 97s - loss: 4.5589 - val_loss: 4.7854\n",
      "Epoch 108/1000\n",
      " - 96s - loss: 4.7832 - val_loss: 4.5538\n",
      "Epoch 109/1000\n",
      " - 97s - loss: 4.4630 - val_loss: 4.3416\n",
      "Epoch 110/1000\n",
      " - 97s - loss: 4.3542 - val_loss: 4.2928\n",
      "Epoch 111/1000\n",
      " - 97s - loss: 4.5567 - val_loss: 4.9639\n",
      "Epoch 112/1000\n",
      " - 97s - loss: 4.6205 - val_loss: 4.0652\n",
      "Epoch 113/1000\n",
      " - 97s - loss: 4.7128 - val_loss: 4.5099\n",
      "Epoch 114/1000\n",
      " - 97s - loss: 4.4570 - val_loss: 3.7107\n",
      "Epoch 115/1000\n",
      " - 97s - loss: 4.4669 - val_loss: 4.3962\n",
      "Epoch 116/1000\n",
      " - 97s - loss: 4.4753 - val_loss: 4.4294\n",
      "Epoch 118/1000\n",
      " - 97s - loss: 4.3458 - val_loss: 4.3352\n",
      "Epoch 119/1000\n",
      " - 97s - loss: 4.6484 - val_loss: 4.4480\n",
      "Epoch 120/1000\n",
      " - 97s - loss: 4.3440 - val_loss: 4.3767\n",
      "Epoch 121/1000\n",
      " - 97s - loss: 4.4125 - val_loss: 4.1891\n",
      "Epoch 122/1000\n",
      " - 97s - loss: 4.5310 - val_loss: 4.2997\n",
      "Epoch 123/1000\n",
      " - 97s - loss: 4.3708 - val_loss: 4.0855\n",
      "Epoch 124/1000\n",
      " - 97s - loss: 4.1519 - val_loss: 4.2509\n",
      "Epoch 125/1000\n",
      " - 97s - loss: 4.3491 - val_loss: 3.6499\n",
      "Epoch 126/1000\n",
      " - 97s - loss: 4.4684 - val_loss: 3.7028\n",
      "Epoch 127/1000\n",
      " - 97s - loss: 4.3763 - val_loss: 3.8937\n",
      "Epoch 128/1000\n",
      " - 98s - loss: 4.1460 - val_loss: 4.0790\n",
      "Epoch 129/1000\n",
      " - 97s - loss: 4.4435 - val_loss: 3.8590\n",
      "Epoch 130/1000\n",
      " - 97s - loss: 4.2546 - val_loss: 3.6442\n",
      "Epoch 131/1000\n",
      " - 97s - loss: 4.3752 - val_loss: 4.0233\n",
      "Epoch 132/1000\n",
      " - 96s - loss: 4.1825 - val_loss: 3.5156\n",
      "Epoch 133/1000\n",
      " - 97s - loss: 4.1218 - val_loss: 4.1198\n",
      "Epoch 134/1000\n",
      " - 97s - loss: 4.1748 - val_loss: 4.1856\n",
      "Epoch 135/1000\n",
      " - 97s - loss: 4.3171 - val_loss: 4.6312\n",
      "Epoch 136/1000\n",
      " - 97s - loss: 4.1972 - val_loss: 4.1007\n",
      "Epoch 137/1000\n",
      " - 97s - loss: 4.1999 - val_loss: 3.9700\n",
      "Epoch 138/1000\n",
      " - 97s - loss: 4.3033 - val_loss: 3.9381\n",
      "Epoch 139/1000\n",
      " - 97s - loss: 4.3395 - val_loss: 3.6811\n",
      "Epoch 140/1000\n",
      " - 98s - loss: 4.4025 - val_loss: 4.0752\n",
      "Epoch 141/1000\n",
      " - 96s - loss: 4.0492 - val_loss: 4.7066\n",
      "Epoch 142/1000\n",
      " - 98s - loss: 4.1904 - val_loss: 4.1280\n",
      "Epoch 143/1000\n",
      " - 97s - loss: 4.1301 - val_loss: 5.3663\n",
      "Epoch 144/1000\n",
      " - 96s - loss: 4.2469 - val_loss: 4.2109\n",
      "Epoch 145/1000\n",
      " - 97s - loss: 4.0381 - val_loss: 4.0703\n",
      "Epoch 146/1000\n",
      " - 98s - loss: 4.0362 - val_loss: 4.7276\n",
      "Epoch 147/1000\n",
      " - 97s - loss: 4.1065 - val_loss: 4.0665\n",
      "Epoch 148/1000\n",
      " - 97s - loss: 4.2532 - val_loss: 4.2424\n",
      "Epoch 149/1000\n",
      " - 98s - loss: 4.2549 - val_loss: 4.2134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000\n",
      " - 97s - loss: 4.0235 - val_loss: 3.5749\n",
      "Epoch 151/1000\n",
      " - 97s - loss: 3.9656 - val_loss: 3.8206\n",
      "Epoch 152/1000\n",
      " - 97s - loss: 4.1492 - val_loss: 3.9305\n",
      "Epoch 153/1000\n",
      " - 97s - loss: 4.1517 - val_loss: 3.9745\n",
      "Epoch 154/1000\n",
      " - 97s - loss: 4.2448 - val_loss: 3.8679\n",
      "Epoch 155/1000\n",
      " - 97s - loss: 3.8964 - val_loss: 3.8180\n",
      "Epoch 156/1000\n",
      " - 98s - loss: 4.2640 - val_loss: 3.8559\n",
      "Epoch 157/1000\n",
      " - 97s - loss: 4.1046 - val_loss: 3.6578\n",
      "Epoch 158/1000\n",
      " - 97s - loss: 4.3172 - val_loss: 4.1361\n",
      "Epoch 159/1000\n",
      " - 97s - loss: 4.0517 - val_loss: 3.1221\n",
      "Epoch 160/1000\n",
      " - 98s - loss: 3.8467 - val_loss: 4.2712\n",
      "Epoch 161/1000\n",
      " - 97s - loss: 3.8861 - val_loss: 3.8840\n",
      "Epoch 162/1000\n",
      " - 97s - loss: 4.2617 - val_loss: 5.4441\n",
      "Epoch 163/1000\n",
      " - 97s - loss: 3.9307 - val_loss: 4.2351\n",
      "Epoch 164/1000\n",
      " - 96s - loss: 4.0006 - val_loss: 3.8070\n",
      "Epoch 165/1000\n",
      " - 96s - loss: 4.1587 - val_loss: 4.0726\n",
      "Epoch 166/1000\n",
      " - 96s - loss: 3.9013 - val_loss: 3.9945\n",
      "Epoch 167/1000\n",
      " - 97s - loss: 3.9724 - val_loss: 4.3452\n",
      "Epoch 168/1000\n",
      " - 97s - loss: 3.9567 - val_loss: 3.7098\n",
      "Epoch 169/1000\n",
      " - 97s - loss: 4.1507 - val_loss: 3.9563\n",
      "Epoch 170/1000\n",
      " - 96s - loss: 4.0928 - val_loss: 4.2060\n",
      "Epoch 171/1000\n",
      " - 97s - loss: 3.8755 - val_loss: 3.9491\n",
      "Epoch 172/1000\n",
      " - 96s - loss: 4.0933 - val_loss: 4.1225\n",
      "Epoch 173/1000\n",
      " - 97s - loss: 3.9789 - val_loss: 3.6829\n",
      "Epoch 174/1000\n",
      " - 96s - loss: 3.8534 - val_loss: 4.4015\n",
      "Epoch 175/1000\n",
      " - 97s - loss: 3.9315 - val_loss: 3.8237\n",
      "Epoch 176/1000\n",
      " - 97s - loss: 3.8063 - val_loss: 3.5719\n",
      "Epoch 177/1000\n",
      " - 97s - loss: 3.7890 - val_loss: 3.6301\n",
      "Epoch 178/1000\n",
      " - 97s - loss: 3.6918 - val_loss: 4.5382\n",
      "Epoch 179/1000\n",
      " - 96s - loss: 3.7825 - val_loss: 4.0451\n",
      "Epoch 180/1000\n",
      " - 96s - loss: 3.8197 - val_loss: 3.8524\n",
      "Epoch 181/1000\n",
      " - 97s - loss: 3.8036 - val_loss: 4.0006\n",
      "Epoch 182/1000\n",
      " - 97s - loss: 3.7851 - val_loss: 4.0002\n",
      "Epoch 183/1000\n",
      " - 97s - loss: 3.8956 - val_loss: 3.8003\n",
      "Epoch 184/1000\n",
      " - 98s - loss: 3.8347 - val_loss: 3.4992\n",
      "Epoch 185/1000\n",
      " - 97s - loss: 3.8800 - val_loss: 3.6693\n",
      "Epoch 186/1000\n",
      " - 96s - loss: 3.6341 - val_loss: 4.5784\n",
      "Epoch 187/1000\n",
      " - 98s - loss: 3.5821 - val_loss: 3.4687\n",
      "Epoch 188/1000\n",
      " - 97s - loss: 3.6076 - val_loss: 4.1504\n",
      "Epoch 189/1000\n",
      " - 97s - loss: 3.5523 - val_loss: 3.2536\n",
      "Epoch 190/1000\n",
      " - 97s - loss: 3.8691 - val_loss: 3.1427\n",
      "Epoch 191/1000\n",
      " - 97s - loss: 3.8075 - val_loss: 3.5748\n",
      "Epoch 192/1000\n",
      " - 97s - loss: 3.9131 - val_loss: 3.0686\n",
      "Epoch 193/1000\n",
      " - 97s - loss: 3.7230 - val_loss: 3.8148\n",
      "Epoch 194/1000\n",
      " - 98s - loss: 3.6465 - val_loss: 3.3882\n",
      "Epoch 195/1000\n",
      " - 97s - loss: 3.6413 - val_loss: 3.4293\n",
      "Epoch 196/1000\n",
      " - 97s - loss: 3.9451 - val_loss: 3.6127\n",
      "Epoch 197/1000\n",
      " - 98s - loss: 3.6115 - val_loss: 3.6250\n",
      "Epoch 198/1000\n",
      " - 97s - loss: 3.8522 - val_loss: 3.3202\n",
      "Epoch 199/1000\n",
      " - 97s - loss: 3.5798 - val_loss: 3.2502\n",
      "Epoch 200/1000\n",
      " - 97s - loss: 3.5833 - val_loss: 3.6105\n",
      "Epoch 201/1000\n",
      " - 98s - loss: 3.8390 - val_loss: 3.6185\n",
      "Epoch 202/1000\n",
      " - 97s - loss: 3.5520 - val_loss: 3.2093\n",
      "Epoch 203/1000\n",
      " - 97s - loss: 3.5666 - val_loss: 3.5043\n",
      "Epoch 204/1000\n",
      " - 97s - loss: 3.8161 - val_loss: 3.5558\n",
      "Epoch 205/1000\n",
      " - 96s - loss: 3.7118 - val_loss: 3.2052\n",
      "Epoch 206/1000\n",
      " - 97s - loss: 3.7341 - val_loss: 3.2063\n",
      "Epoch 207/1000\n",
      " - 97s - loss: 3.6741 - val_loss: 3.6205\n",
      "Epoch 208/1000\n",
      " - 97s - loss: 3.9671 - val_loss: 3.6006\n",
      "Epoch 209/1000\n",
      " - 96s - loss: 3.6993 - val_loss: 3.5661\n",
      "Epoch 210/1000\n",
      " - 96s - loss: 3.6663 - val_loss: 3.2473\n",
      "Epoch 211/1000\n",
      " - 97s - loss: 3.7554 - val_loss: 3.5549\n",
      "Epoch 212/1000\n",
      " - 97s - loss: 3.5532 - val_loss: 3.9016\n",
      "Epoch 213/1000\n",
      " - 97s - loss: 3.5226 - val_loss: 3.7380\n",
      "Epoch 214/1000\n",
      " - 97s - loss: 3.7166 - val_loss: 3.2190\n",
      "Epoch 215/1000\n",
      " - 97s - loss: 3.1692 - val_loss: 2.9558\n",
      "Epoch 216/1000\n",
      " - 97s - loss: 3.4631 - val_loss: 3.7729\n",
      "Epoch 217/1000\n",
      " - 97s - loss: 3.7209 - val_loss: 3.4596\n",
      "Epoch 218/1000\n",
      " - 97s - loss: 3.4863 - val_loss: 2.9940\n",
      "Epoch 219/1000\n",
      " - 97s - loss: 3.5332 - val_loss: 3.9893\n",
      "Epoch 220/1000\n",
      " - 97s - loss: 3.3185 - val_loss: 3.1791\n",
      "Epoch 221/1000\n",
      " - 97s - loss: 3.3465 - val_loss: 2.7004\n",
      "Epoch 222/1000\n",
      " - 97s - loss: 3.4754 - val_loss: 3.5876\n",
      "Epoch 223/1000\n",
      " - 97s - loss: 3.7126 - val_loss: 3.1256\n",
      "Epoch 224/1000\n",
      " - 96s - loss: 3.5509 - val_loss: 3.2840\n",
      "Epoch 225/1000\n",
      " - 96s - loss: 3.6009 - val_loss: 3.2475\n",
      "Epoch 226/1000\n",
      " - 97s - loss: 3.5829 - val_loss: 3.2370\n",
      "Epoch 227/1000\n",
      " - 97s - loss: 3.8332 - val_loss: 3.3328\n",
      "Epoch 228/1000\n",
      " - 97s - loss: 3.6567 - val_loss: 3.2849\n",
      "Epoch 229/1000\n",
      " - 97s - loss: 3.6522 - val_loss: 3.9622\n",
      "Epoch 230/1000\n",
      " - 97s - loss: 3.5310 - val_loss: 3.2213\n",
      "Epoch 231/1000\n",
      " - 97s - loss: 3.3692 - val_loss: 3.1780\n",
      "Epoch 232/1000\n",
      " - 97s - loss: 3.1304 - val_loss: 3.2691\n",
      "Epoch 233/1000\n",
      " - 96s - loss: 3.3867 - val_loss: 3.2223\n",
      "Epoch 234/1000\n",
      " - 97s - loss: 3.5745 - val_loss: 3.3207\n",
      "Epoch 235/1000\n",
      " - 97s - loss: 3.6533 - val_loss: 3.2655\n",
      "Epoch 236/1000\n",
      " - 97s - loss: 3.6922 - val_loss: 3.0951\n",
      "Epoch 237/1000\n",
      " - 98s - loss: 3.6357 - val_loss: 3.4449\n",
      "Epoch 238/1000\n",
      " - 97s - loss: 3.4581 - val_loss: 3.6839\n",
      "Epoch 239/1000\n",
      " - 97s - loss: 3.6418 - val_loss: 3.1675\n",
      "Epoch 240/1000\n",
      " - 97s - loss: 3.4580 - val_loss: 3.4038\n",
      "Epoch 241/1000\n",
      " - 97s - loss: 3.4442 - val_loss: 3.2270\n",
      "Epoch 242/1000\n",
      " - 96s - loss: 3.2804 - val_loss: 3.1224\n",
      "Epoch 243/1000\n",
      " - 97s - loss: 3.4377 - val_loss: 3.3926\n",
      "Epoch 244/1000\n",
      " - 97s - loss: 2.9751 - val_loss: 3.0211\n",
      "Epoch 245/1000\n",
      " - 97s - loss: 3.3614 - val_loss: 3.2524\n",
      "Epoch 246/1000\n",
      " - 97s - loss: 3.4302 - val_loss: 3.1111\n",
      "Epoch 247/1000\n",
      " - 96s - loss: 3.5881 - val_loss: 3.4794\n",
      "Epoch 248/1000\n",
      " - 96s - loss: 3.4882 - val_loss: 4.0533\n",
      "Epoch 249/1000\n",
      " - 97s - loss: 3.5177 - val_loss: 3.2576\n",
      "Epoch 250/1000\n",
      " - 96s - loss: 3.4513 - val_loss: 3.2442\n",
      "Epoch 251/1000\n",
      " - 97s - loss: 3.2981 - val_loss: 3.2311\n",
      "Epoch 252/1000\n",
      " - 97s - loss: 3.4563 - val_loss: 3.6907\n",
      "Epoch 253/1000\n",
      " - 96s - loss: 3.5123 - val_loss: 2.9571\n",
      "Epoch 254/1000\n",
      " - 97s - loss: 3.5052 - val_loss: 3.2603\n",
      "Epoch 255/1000\n",
      " - 98s - loss: 3.2497 - val_loss: 3.3758\n",
      "Epoch 256/1000\n",
      " - 97s - loss: 3.2095 - val_loss: 3.4262\n",
      "Epoch 257/1000\n",
      " - 97s - loss: 3.3439 - val_loss: 3.2805\n",
      "Epoch 258/1000\n",
      " - 97s - loss: 3.3502 - val_loss: 2.7189\n",
      "Epoch 259/1000\n",
      " - 97s - loss: 3.3623 - val_loss: 3.0869\n",
      "Epoch 260/1000\n",
      " - 96s - loss: 3.3014 - val_loss: 3.2163\n",
      "Epoch 261/1000\n",
      " - 97s - loss: 3.3965 - val_loss: 3.2847\n",
      "Epoch 262/1000\n",
      " - 97s - loss: 3.1551 - val_loss: 3.3313\n",
      "Epoch 263/1000\n",
      " - 96s - loss: 3.1169 - val_loss: 2.8636\n",
      "Epoch 264/1000\n",
      " - 97s - loss: 3.4325 - val_loss: 2.7480\n",
      "Epoch 265/1000\n",
      " - 97s - loss: 3.5039 - val_loss: 3.0553\n",
      "Epoch 266/1000\n",
      " - 97s - loss: 3.0668 - val_loss: 3.0784\n",
      "Epoch 267/1000\n",
      " - 97s - loss: 3.5423 - val_loss: 3.1118\n",
      "Epoch 268/1000\n",
      " - 97s - loss: 3.0251 - val_loss: 3.1902\n",
      "Epoch 269/1000\n",
      " - 97s - loss: 3.2909 - val_loss: 3.1188\n",
      "Epoch 270/1000\n",
      " - 96s - loss: 3.1763 - val_loss: 3.0940\n",
      "Epoch 271/1000\n",
      " - 97s - loss: 3.3602 - val_loss: 3.2892\n",
      "Epoch 272/1000\n",
      " - 97s - loss: 3.3532 - val_loss: 2.9178\n",
      "Epoch 273/1000\n",
      " - 96s - loss: 3.3349 - val_loss: 3.5005\n",
      "Epoch 274/1000\n",
      " - 97s - loss: 3.1751 - val_loss: 3.5904\n",
      "Epoch 275/1000\n",
      " - 97s - loss: 3.4225 - val_loss: 3.1098\n",
      "Epoch 276/1000\n",
      " - 97s - loss: 3.1563 - val_loss: 2.8320\n",
      "Epoch 277/1000\n",
      " - 97s - loss: 3.3140 - val_loss: 3.1215\n",
      "Epoch 278/1000\n",
      " - 97s - loss: 3.2149 - val_loss: 3.3854\n",
      "Epoch 279/1000\n",
      " - 97s - loss: 3.0954 - val_loss: 3.2128\n",
      "Epoch 280/1000\n",
      " - 97s - loss: 3.2736 - val_loss: 3.6546\n",
      "Epoch 281/1000\n",
      " - 97s - loss: 3.2520 - val_loss: 3.0275\n",
      "Epoch 282/1000\n",
      " - 98s - loss: 3.2409 - val_loss: 3.5494\n",
      "Epoch 283/1000\n",
      " - 97s - loss: 3.2030 - val_loss: 2.8820\n",
      "Epoch 284/1000\n",
      " - 96s - loss: 3.0940 - val_loss: 3.2670\n",
      "Epoch 285/1000\n",
      " - 96s - loss: 3.1095 - val_loss: 3.4092\n",
      "Epoch 286/1000\n",
      " - 96s - loss: 3.3079 - val_loss: 3.5864\n",
      "Epoch 287/1000\n",
      " - 96s - loss: 3.0949 - val_loss: 3.1967\n",
      "Epoch 288/1000\n",
      " - 96s - loss: 3.5628 - val_loss: 2.8158\n",
      "Epoch 289/1000\n",
      " - 97s - loss: 3.2029 - val_loss: 2.7606\n",
      "Epoch 290/1000\n",
      " - 97s - loss: 3.2883 - val_loss: 2.9113\n",
      "Epoch 291/1000\n",
      " - 96s - loss: 3.4219 - val_loss: 3.0972\n",
      "Epoch 292/1000\n",
      " - 97s - loss: 3.1752 - val_loss: 3.4815\n",
      "Epoch 293/1000\n",
      " - 97s - loss: 3.1857 - val_loss: 3.4173\n",
      "Epoch 294/1000\n",
      " - 97s - loss: 3.1833 - val_loss: 3.3506\n",
      "Epoch 295/1000\n",
      " - 97s - loss: 3.2135 - val_loss: 3.2226\n",
      "Epoch 296/1000\n",
      " - 97s - loss: 3.1956 - val_loss: 3.1621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000\n",
      " - 96s - loss: 3.1751 - val_loss: 3.0189\n",
      "Epoch 298/1000\n",
      " - 97s - loss: 3.2943 - val_loss: 3.4614\n",
      "Epoch 299/1000\n",
      " - 96s - loss: 3.1072 - val_loss: 2.9129\n",
      "Epoch 300/1000\n",
      " - 97s - loss: 3.1068 - val_loss: 3.2035\n",
      "Epoch 301/1000\n",
      " - 97s - loss: 3.3792 - val_loss: 3.6233\n",
      "Epoch 302/1000\n",
      " - 96s - loss: 3.2269 - val_loss: 2.9287\n",
      "Epoch 303/1000\n",
      " - 97s - loss: 3.0321 - val_loss: 2.6331\n",
      "Epoch 304/1000\n",
      " - 97s - loss: 2.9846 - val_loss: 3.0140\n",
      "Epoch 305/1000\n",
      " - 96s - loss: 2.9683 - val_loss: 2.8838\n",
      "Epoch 306/1000\n",
      " - 97s - loss: 3.2077 - val_loss: 2.9607\n",
      "Epoch 307/1000\n",
      " - 97s - loss: 3.1046 - val_loss: 2.8735\n",
      "Epoch 308/1000\n",
      " - 97s - loss: 2.8119 - val_loss: 3.2389\n",
      "Epoch 309/1000\n",
      " - 97s - loss: 3.2817 - val_loss: 3.2411\n",
      "Epoch 310/1000\n",
      " - 97s - loss: 2.9674 - val_loss: 2.9042\n",
      "Epoch 311/1000\n",
      " - 96s - loss: 3.0164 - val_loss: 3.0615\n",
      "Epoch 312/1000\n",
      " - 97s - loss: 3.1276 - val_loss: 2.9987\n",
      "Epoch 313/1000\n",
      " - 97s - loss: 3.0740 - val_loss: 2.8912\n",
      "Epoch 314/1000\n",
      " - 96s - loss: 3.1756 - val_loss: 2.5236\n",
      "Epoch 315/1000\n",
      " - 97s - loss: 3.0154 - val_loss: 3.7309\n",
      "Epoch 316/1000\n",
      " - 97s - loss: 3.2248 - val_loss: 2.8087\n",
      "Epoch 317/1000\n",
      " - 97s - loss: 2.9133 - val_loss: 3.2143\n",
      "Epoch 318/1000\n",
      " - 97s - loss: 3.1850 - val_loss: 3.1022\n",
      "Epoch 319/1000\n",
      " - 97s - loss: 3.1859 - val_loss: 2.8300\n",
      "Epoch 320/1000\n",
      " - 97s - loss: 3.0484 - val_loss: 2.8145\n",
      "Epoch 321/1000\n",
      " - 98s - loss: 3.0340 - val_loss: 2.7506\n",
      "Epoch 322/1000\n",
      " - 97s - loss: 2.8420 - val_loss: 2.9698\n",
      "Epoch 323/1000\n",
      " - 97s - loss: 3.1122 - val_loss: 2.9762\n",
      "Epoch 324/1000\n",
      " - 98s - loss: 3.1577 - val_loss: 2.8435\n",
      "Epoch 325/1000\n",
      " - 96s - loss: 2.9997 - val_loss: 2.9576\n",
      "Epoch 326/1000\n",
      " - 97s - loss: 2.9797 - val_loss: 2.8140\n",
      "Epoch 327/1000\n",
      " - 98s - loss: 3.4375 - val_loss: 2.6465\n",
      "Epoch 328/1000\n",
      " - 96s - loss: 2.9842 - val_loss: 3.4516\n",
      "Epoch 329/1000\n",
      " - 97s - loss: 3.0364 - val_loss: 2.9933\n",
      "Epoch 330/1000\n",
      " - 97s - loss: 3.0260 - val_loss: 2.6900\n",
      "Epoch 331/1000\n",
      " - 96s - loss: 3.0187 - val_loss: 3.4583\n",
      "Epoch 332/1000\n",
      " - 97s - loss: 2.9846 - val_loss: 3.1660\n",
      "Epoch 333/1000\n",
      " - 97s - loss: 3.0474 - val_loss: 3.0019\n",
      "Epoch 334/1000\n",
      " - 97s - loss: 2.9197 - val_loss: 2.9363\n",
      "Epoch 335/1000\n",
      " - 97s - loss: 2.9453 - val_loss: 2.9446\n",
      "Epoch 336/1000\n",
      " - 97s - loss: 2.9485 - val_loss: 2.9214\n",
      "Epoch 337/1000\n",
      " - 96s - loss: 3.0166 - val_loss: 2.6746\n",
      "Epoch 338/1000\n",
      " - 97s - loss: 2.9030 - val_loss: 2.7878\n",
      "Epoch 339/1000\n",
      " - 97s - loss: 3.0484 - val_loss: 2.6131\n",
      "Epoch 340/1000\n",
      " - 96s - loss: 3.1673 - val_loss: 2.9641\n",
      "Epoch 341/1000\n",
      " - 96s - loss: 2.9855 - val_loss: 4.2886\n",
      "Epoch 342/1000\n",
      " - 98s - loss: 2.8703 - val_loss: 3.0277\n",
      "Epoch 343/1000\n",
      " - 97s - loss: 2.8853 - val_loss: 3.2262\n",
      "Epoch 344/1000\n",
      " - 96s - loss: 2.9616 - val_loss: 2.7293\n",
      "Epoch 345/1000\n",
      " - 98s - loss: 3.0686 - val_loss: 2.8330\n",
      "Epoch 346/1000\n",
      " - 97s - loss: 2.8898 - val_loss: 2.9624\n",
      "Epoch 347/1000\n",
      " - 97s - loss: 2.6754 - val_loss: 2.7307\n",
      "Epoch 348/1000\n",
      " - 98s - loss: 2.8550 - val_loss: 2.6839\n",
      "Epoch 349/1000\n",
      " - 97s - loss: 2.8910 - val_loss: 2.8068\n",
      "Epoch 350/1000\n",
      " - 97s - loss: 3.2265 - val_loss: 2.9501\n",
      "Epoch 351/1000\n",
      " - 97s - loss: 2.9943 - val_loss: 3.1251\n",
      "Epoch 352/1000\n",
      " - 97s - loss: 2.9379 - val_loss: 2.6614\n",
      "Epoch 353/1000\n",
      " - 97s - loss: 2.9210 - val_loss: 3.3352\n",
      "Epoch 354/1000\n",
      " - 97s - loss: 2.9338 - val_loss: 2.7846\n",
      "Epoch 355/1000\n",
      " - 96s - loss: 3.0672 - val_loss: 2.8002\n",
      "Epoch 356/1000\n",
      " - 97s - loss: 3.0951 - val_loss: 3.3999\n",
      "Epoch 357/1000\n",
      " - 97s - loss: 2.8371 - val_loss: 2.6788\n",
      "Epoch 358/1000\n",
      " - 97s - loss: 2.8748 - val_loss: 2.6665\n",
      "Epoch 359/1000\n",
      " - 98s - loss: 2.7720 - val_loss: 2.7825\n",
      "Epoch 360/1000\n",
      " - 98s - loss: 2.7196 - val_loss: 3.1464\n",
      "Epoch 361/1000\n",
      " - 97s - loss: 2.9293 - val_loss: 2.7335\n",
      "Epoch 362/1000\n",
      " - 97s - loss: 2.9467 - val_loss: 2.5943\n",
      "Epoch 363/1000\n",
      " - 98s - loss: 2.9860 - val_loss: 2.9586\n",
      "Epoch 364/1000\n",
      " - 97s - loss: 2.9327 - val_loss: 2.9178\n",
      "Epoch 365/1000\n",
      " - 97s - loss: 3.0598 - val_loss: 3.4997\n",
      "Epoch 366/1000\n",
      " - 97s - loss: 2.8218 - val_loss: 2.9415\n",
      "Epoch 367/1000\n",
      " - 97s - loss: 2.8968 - val_loss: 2.9405\n",
      "Epoch 368/1000\n",
      " - 97s - loss: 2.9637 - val_loss: 2.7386\n",
      "Epoch 369/1000\n",
      " - 98s - loss: 2.8300 - val_loss: 2.7743\n",
      "Epoch 370/1000\n",
      " - 97s - loss: 2.7485 - val_loss: 2.8615\n",
      "Epoch 371/1000\n",
      " - 97s - loss: 3.1146 - val_loss: 2.8419\n",
      "Epoch 372/1000\n",
      " - 97s - loss: 2.9423 - val_loss: 3.0993\n",
      "Epoch 373/1000\n",
      " - 97s - loss: 2.9122 - val_loss: 2.8324\n",
      "Epoch 374/1000\n",
      " - 97s - loss: 2.7162 - val_loss: 2.8076\n",
      "Epoch 375/1000\n",
      " - 96s - loss: 3.0068 - val_loss: 2.7650\n",
      "Epoch 376/1000\n",
      " - 97s - loss: 2.8600 - val_loss: 2.8472\n",
      "Epoch 377/1000\n",
      " - 97s - loss: 2.9924 - val_loss: 2.9503\n",
      "Epoch 378/1000\n",
      " - 96s - loss: 2.7285 - val_loss: 2.9626\n",
      "Epoch 379/1000\n",
      " - 97s - loss: 2.9986 - val_loss: 2.8779\n",
      "Epoch 380/1000\n",
      " - 97s - loss: 2.9694 - val_loss: 3.1725\n",
      "Epoch 381/1000\n",
      " - 96s - loss: 2.7758 - val_loss: 3.3543\n",
      "Epoch 382/1000\n",
      " - 97s - loss: 2.8345 - val_loss: 2.6677\n",
      "Epoch 383/1000\n",
      " - 97s - loss: 2.7521 - val_loss: 2.7262\n",
      "Epoch 384/1000\n",
      " - 97s - loss: 2.8770 - val_loss: 2.8901\n",
      "Epoch 385/1000\n",
      " - 96s - loss: 3.1024 - val_loss: 3.1813\n",
      "Epoch 386/1000\n",
      " - 97s - loss: 2.6205 - val_loss: 2.4650\n",
      "Epoch 387/1000\n",
      " - 97s - loss: 3.0496 - val_loss: 2.7132\n",
      "Epoch 388/1000\n",
      " - 96s - loss: 2.9384 - val_loss: 3.1984\n",
      "Epoch 389/1000\n",
      " - 98s - loss: 2.7273 - val_loss: 2.8508\n",
      "Epoch 390/1000\n",
      " - 97s - loss: 2.6104 - val_loss: 2.6198\n",
      "Epoch 391/1000\n",
      " - 96s - loss: 2.7783 - val_loss: 2.3720\n",
      "Epoch 392/1000\n",
      " - 98s - loss: 3.0308 - val_loss: 2.7657\n",
      "Epoch 393/1000\n",
      " - 97s - loss: 2.9157 - val_loss: 2.6636\n",
      "Epoch 394/1000\n",
      " - 96s - loss: 2.9127 - val_loss: 2.9344\n",
      "Epoch 395/1000\n",
      " - 97s - loss: 2.8902 - val_loss: 2.5412\n",
      "Epoch 396/1000\n",
      " - 97s - loss: 2.8174 - val_loss: 2.7705\n",
      "Epoch 397/1000\n",
      " - 97s - loss: 2.8140 - val_loss: 2.7207\n",
      "Epoch 398/1000\n",
      " - 98s - loss: 2.8729 - val_loss: 2.6597\n",
      "Epoch 399/1000\n",
      " - 97s - loss: 2.6989 - val_loss: 2.7537\n",
      "Epoch 400/1000\n",
      " - 97s - loss: 2.9397 - val_loss: 2.4902\n",
      "Epoch 401/1000\n",
      " - 97s - loss: 2.9402 - val_loss: 2.4440\n",
      "Epoch 402/1000\n",
      " - 97s - loss: 2.9943 - val_loss: 2.6363\n",
      "Epoch 403/1000\n",
      " - 97s - loss: 2.8282 - val_loss: 2.7308\n",
      "Epoch 404/1000\n",
      " - 97s - loss: 2.6600 - val_loss: 2.9190\n",
      "Epoch 405/1000\n",
      " - 97s - loss: 2.6784 - val_loss: 2.7374\n",
      "Epoch 406/1000\n",
      " - 96s - loss: 2.6304 - val_loss: 3.0249\n",
      "Epoch 407/1000\n",
      " - 97s - loss: 2.6671 - val_loss: 2.6501\n",
      "Epoch 408/1000\n",
      " - 96s - loss: 2.9291 - val_loss: 2.4104\n",
      "Epoch 409/1000\n",
      " - 96s - loss: 2.5649 - val_loss: 2.3499\n",
      "Epoch 410/1000\n",
      " - 96s - loss: 2.9420 - val_loss: 2.4791\n",
      "Epoch 411/1000\n",
      " - 97s - loss: 2.6742 - val_loss: 2.4252\n",
      "Epoch 412/1000\n",
      " - 97s - loss: 2.5375 - val_loss: 2.6085\n",
      "Epoch 413/1000\n",
      " - 96s - loss: 2.5927 - val_loss: 2.6780\n",
      "Epoch 414/1000\n",
      " - 97s - loss: 2.7024 - val_loss: 2.6545\n",
      "Epoch 415/1000\n",
      " - 97s - loss: 2.7404 - val_loss: 2.6251\n",
      "Epoch 416/1000\n",
      " - 97s - loss: 2.7690 - val_loss: 2.4775\n",
      "Epoch 417/1000\n",
      " - 96s - loss: 2.6856 - val_loss: 2.5715\n",
      "Epoch 418/1000\n",
      " - 96s - loss: 2.8746 - val_loss: 2.6474\n",
      "Epoch 419/1000\n",
      " - 97s - loss: 2.7031 - val_loss: 2.7480\n",
      "Epoch 420/1000\n",
      " - 97s - loss: 2.8107 - val_loss: 2.4921\n",
      "Epoch 421/1000\n",
      " - 96s - loss: 2.6581 - val_loss: 2.6377\n",
      "Epoch 422/1000\n",
      " - 97s - loss: 2.6250 - val_loss: 2.8749\n",
      "Epoch 423/1000\n",
      " - 97s - loss: 2.6965 - val_loss: 2.8210\n",
      "Epoch 424/1000\n",
      " - 96s - loss: 2.7196 - val_loss: 2.4369\n",
      "Epoch 425/1000\n",
      " - 96s - loss: 2.7478 - val_loss: 2.7443\n",
      "Epoch 426/1000\n",
      " - 97s - loss: 2.5596 - val_loss: 2.6302\n",
      "Epoch 427/1000\n",
      " - 97s - loss: 2.7442 - val_loss: 2.8878\n",
      "Epoch 428/1000\n",
      " - 96s - loss: 2.8137 - val_loss: 2.2249\n",
      "Epoch 429/1000\n",
      " - 97s - loss: 2.5302 - val_loss: 2.4017\n",
      "Epoch 430/1000\n",
      " - 97s - loss: 2.6319 - val_loss: 2.5336\n",
      "Epoch 431/1000\n",
      " - 97s - loss: 2.5739 - val_loss: 2.5450\n",
      "Epoch 432/1000\n",
      " - 98s - loss: 2.6036 - val_loss: 2.1661\n",
      "Epoch 433/1000\n",
      " - 96s - loss: 2.5241 - val_loss: 2.9164\n",
      "Epoch 434/1000\n",
      " - 96s - loss: 2.6409 - val_loss: 2.9527\n",
      "Epoch 435/1000\n",
      " - 97s - loss: 2.8134 - val_loss: 3.0337\n",
      "Epoch 436/1000\n",
      " - 97s - loss: 2.7991 - val_loss: 2.4698\n",
      "Epoch 437/1000\n",
      " - 96s - loss: 2.7453 - val_loss: 2.4961\n",
      "Epoch 438/1000\n",
      " - 96s - loss: 2.9178 - val_loss: 2.8676\n",
      "Epoch 439/1000\n",
      " - 97s - loss: 2.8122 - val_loss: 2.8229\n",
      "Epoch 440/1000\n",
      " - 96s - loss: 2.5086 - val_loss: 2.7150\n",
      "Epoch 441/1000\n",
      " - 96s - loss: 2.5675 - val_loss: 2.4127\n",
      "Epoch 442/1000\n",
      " - 97s - loss: 2.7708 - val_loss: 2.7367\n",
      "Epoch 443/1000\n",
      " - 96s - loss: 2.7700 - val_loss: 2.8464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000\n",
      " - 96s - loss: 2.7264 - val_loss: 2.7899\n",
      "Epoch 445/1000\n",
      " - 97s - loss: 2.5117 - val_loss: 2.4468\n",
      "Epoch 446/1000\n",
      " - 97s - loss: 2.7977 - val_loss: 2.7279\n",
      "Epoch 447/1000\n",
      " - 96s - loss: 2.5905 - val_loss: 2.4988\n",
      "Epoch 448/1000\n",
      " - 97s - loss: 2.5486 - val_loss: 2.4787\n",
      "Epoch 449/1000\n",
      " - 96s - loss: 2.6984 - val_loss: 3.0227\n",
      "Epoch 450/1000\n",
      " - 96s - loss: 2.6030 - val_loss: 2.6643\n",
      "Epoch 451/1000\n",
      " - 97s - loss: 2.6061 - val_loss: 2.3306\n",
      "Epoch 452/1000\n",
      " - 96s - loss: 2.5116 - val_loss: 2.5476\n",
      "Epoch 453/1000\n",
      " - 96s - loss: 2.4897 - val_loss: 2.4803\n",
      "Epoch 454/1000\n",
      " - 97s - loss: 2.6602 - val_loss: 2.5918\n",
      "Epoch 455/1000\n",
      " - 97s - loss: 2.7026 - val_loss: 2.7668\n",
      "Epoch 456/1000\n",
      " - 96s - loss: 2.5506 - val_loss: 2.6215\n",
      "Epoch 457/1000\n",
      " - 97s - loss: 2.5672 - val_loss: 2.5946\n",
      "Epoch 458/1000\n",
      " - 97s - loss: 2.5630 - val_loss: 2.7725\n",
      "Epoch 459/1000\n",
      " - 96s - loss: 2.8826 - val_loss: 2.3704\n",
      "Epoch 460/1000\n",
      " - 97s - loss: 2.6885 - val_loss: 2.3733\n",
      "Epoch 461/1000\n",
      " - 96s - loss: 2.4642 - val_loss: 2.5588\n",
      "Epoch 462/1000\n",
      " - 96s - loss: 2.5379 - val_loss: 2.9078\n",
      "Epoch 463/1000\n",
      " - 96s - loss: 2.7535 - val_loss: 2.6026\n",
      "Epoch 464/1000\n",
      " - 96s - loss: 2.6266 - val_loss: 2.7861\n",
      "Epoch 465/1000\n",
      " - 96s - loss: 2.8127 - val_loss: 2.5015\n",
      "Epoch 466/1000\n",
      " - 96s - loss: 2.6682 - val_loss: 2.6757\n",
      "Epoch 467/1000\n",
      " - 96s - loss: 2.5563 - val_loss: 2.3521\n",
      "Epoch 468/1000\n",
      " - 96s - loss: 2.5871 - val_loss: 2.2604\n",
      "Epoch 469/1000\n",
      " - 96s - loss: 2.3517 - val_loss: 2.5965\n",
      "Epoch 470/1000\n",
      " - 97s - loss: 2.5989 - val_loss: 2.9484\n",
      "Epoch 471/1000\n",
      " - 97s - loss: 2.6071 - val_loss: 2.7140\n",
      "Epoch 472/1000\n",
      " - 96s - loss: 2.6532 - val_loss: 2.5194\n",
      "Epoch 473/1000\n",
      " - 97s - loss: 2.6536 - val_loss: 2.2454\n",
      "Epoch 474/1000\n",
      " - 97s - loss: 2.6350 - val_loss: 2.2325\n",
      "Epoch 475/1000\n",
      " - 96s - loss: 2.4173 - val_loss: 2.9645\n",
      "Epoch 476/1000\n",
      " - 96s - loss: 2.6475 - val_loss: 2.5450\n",
      "Epoch 477/1000\n",
      " - 96s - loss: 2.5687 - val_loss: 2.4887\n",
      "Epoch 478/1000\n",
      " - 96s - loss: 2.5534 - val_loss: 2.7468\n",
      "Epoch 479/1000\n",
      " - 96s - loss: 2.7232 - val_loss: 2.4102\n",
      "Epoch 480/1000\n",
      " - 96s - loss: 2.4773 - val_loss: 2.5948\n",
      "Epoch 481/1000\n",
      " - 96s - loss: 2.6242 - val_loss: 2.4401\n",
      "Epoch 482/1000\n",
      " - 96s - loss: 2.4601 - val_loss: 2.5865\n",
      "Epoch 483/1000\n",
      " - 96s - loss: 2.9283 - val_loss: 2.3598\n",
      "Epoch 484/1000\n",
      " - 96s - loss: 2.4769 - val_loss: 2.5740\n",
      "Epoch 485/1000\n",
      " - 96s - loss: 2.7143 - val_loss: 2.9556\n",
      "Epoch 486/1000\n",
      " - 97s - loss: 2.6124 - val_loss: 3.0896\n",
      "Epoch 487/1000\n",
      " - 96s - loss: 2.8337 - val_loss: 2.2531\n",
      "Epoch 488/1000\n",
      " - 96s - loss: 2.6208 - val_loss: 2.9852\n",
      "Epoch 489/1000\n",
      " - 97s - loss: 2.7198 - val_loss: 2.4613\n",
      "Epoch 490/1000\n",
      " - 97s - loss: 2.6735 - val_loss: 2.7819\n",
      "Epoch 491/1000\n",
      " - 97s - loss: 2.5811 - val_loss: 2.5883\n",
      "Epoch 492/1000\n",
      " - 97s - loss: 2.5741 - val_loss: 2.9047\n",
      "Epoch 493/1000\n",
      " - 97s - loss: 2.6344 - val_loss: 2.6217\n",
      "Epoch 494/1000\n",
      " - 97s - loss: 2.6220 - val_loss: 2.6733\n",
      "Epoch 495/1000\n",
      " - 97s - loss: 2.6271 - val_loss: 2.5180\n",
      "Epoch 496/1000\n",
      " - 97s - loss: 2.5878 - val_loss: 2.9663\n",
      "Epoch 497/1000\n",
      " - 97s - loss: 2.5702 - val_loss: 2.6587\n",
      "Epoch 498/1000\n",
      " - 97s - loss: 2.6043 - val_loss: 2.5940\n",
      "Epoch 499/1000\n",
      " - 96s - loss: 2.8379 - val_loss: 2.6692\n",
      "Epoch 500/1000\n",
      " - 96s - loss: 2.7059 - val_loss: 2.5406\n",
      "Epoch 501/1000\n",
      " - 97s - loss: 2.6046 - val_loss: 2.6570\n",
      "Epoch 502/1000\n",
      " - 97s - loss: 2.4416 - val_loss: 2.8350\n",
      "Epoch 503/1000\n",
      " - 97s - loss: 2.6613 - val_loss: 2.7809\n",
      "Epoch 504/1000\n",
      " - 97s - loss: 2.3540 - val_loss: 2.5114\n",
      "Epoch 505/1000\n",
      " - 97s - loss: 2.5820 - val_loss: 2.2351\n",
      "Epoch 506/1000\n",
      " - 97s - loss: 2.5120 - val_loss: 2.6099\n",
      "Epoch 507/1000\n",
      " - 98s - loss: 2.5129 - val_loss: 2.5148\n",
      "Epoch 508/1000\n",
      " - 96s - loss: 2.3201 - val_loss: 2.6004\n",
      "Epoch 509/1000\n",
      " - 97s - loss: 2.4443 - val_loss: 2.7398\n",
      "Epoch 510/1000\n",
      " - 97s - loss: 2.4165 - val_loss: 2.6400\n",
      "Epoch 511/1000\n",
      " - 97s - loss: 2.5546 - val_loss: 2.5001\n",
      "Epoch 512/1000\n",
      " - 97s - loss: 2.4366 - val_loss: 2.2897\n",
      "Epoch 513/1000\n",
      " - 97s - loss: 2.4902 - val_loss: 2.4816\n",
      "Epoch 514/1000\n",
      " - 97s - loss: 2.4842 - val_loss: 2.4891\n",
      "Epoch 515/1000\n",
      " - 97s - loss: 2.4521 - val_loss: 2.7716\n",
      "Epoch 516/1000\n",
      " - 97s - loss: 2.2689 - val_loss: 2.2806\n",
      "Epoch 517/1000\n",
      " - 97s - loss: 2.4686 - val_loss: 2.3642\n",
      "Epoch 518/1000\n",
      " - 98s - loss: 2.5382 - val_loss: 2.5604\n",
      "Epoch 519/1000\n",
      " - 97s - loss: 2.5566 - val_loss: 2.8320\n",
      "Epoch 520/1000\n",
      " - 96s - loss: 2.5282 - val_loss: 2.4477\n",
      "Epoch 521/1000\n",
      " - 97s - loss: 2.4933 - val_loss: 2.4657\n",
      "Epoch 522/1000\n",
      " - 97s - loss: 2.3782 - val_loss: 2.6800\n",
      "Epoch 523/1000\n",
      " - 97s - loss: 2.6608 - val_loss: 2.4411\n",
      "Epoch 524/1000\n",
      " - 97s - loss: 2.4289 - val_loss: 2.4367\n",
      "Epoch 525/1000\n",
      " - 97s - loss: 2.5294 - val_loss: 2.3195\n",
      "Epoch 526/1000\n",
      " - 97s - loss: 2.4507 - val_loss: 2.7489\n",
      "Epoch 527/1000\n",
      " - 97s - loss: 2.4612 - val_loss: 2.4064\n",
      "Epoch 528/1000\n",
      " - 97s - loss: 2.4600 - val_loss: 2.6678\n",
      "Epoch 529/1000\n",
      " - 97s - loss: 2.5766 - val_loss: 2.7328\n",
      "Epoch 530/1000\n",
      " - 97s - loss: 2.4923 - val_loss: 2.5245\n",
      "Epoch 531/1000\n",
      " - 97s - loss: 2.4375 - val_loss: 2.4128\n",
      "Epoch 532/1000\n",
      " - 96s - loss: 2.3170 - val_loss: 2.3954\n",
      "Epoch 533/1000\n",
      " - 97s - loss: 2.4321 - val_loss: 2.5114\n",
      "Epoch 534/1000\n",
      " - 97s - loss: 2.3572 - val_loss: 2.4962\n",
      "Epoch 535/1000\n",
      " - 97s - loss: 2.4348 - val_loss: 2.6234\n",
      "Epoch 536/1000\n",
      " - 97s - loss: 2.5459 - val_loss: 2.3817\n",
      "Epoch 537/1000\n",
      " - 97s - loss: 2.4937 - val_loss: 2.6264\n",
      "Epoch 538/1000\n",
      " - 97s - loss: 2.4902 - val_loss: 2.2910\n",
      "Epoch 539/1000\n",
      " - 97s - loss: 2.1796 - val_loss: 2.1071\n",
      "Epoch 540/1000\n",
      " - 97s - loss: 2.5255 - val_loss: 2.2500\n",
      "Epoch 541/1000\n",
      " - 97s - loss: 2.3572 - val_loss: 2.2434\n",
      "Epoch 542/1000\n",
      " - 97s - loss: 2.4937 - val_loss: 2.8062\n",
      "Epoch 543/1000\n",
      " - 96s - loss: 2.4895 - val_loss: 2.4488\n",
      "Epoch 544/1000\n",
      " - 97s - loss: 2.2459 - val_loss: 2.2445\n",
      "Epoch 545/1000\n",
      " - 97s - loss: 2.4994 - val_loss: 2.5325\n",
      "Epoch 546/1000\n",
      " - 97s - loss: 2.4055 - val_loss: 2.3950\n",
      "Epoch 547/1000\n",
      " - 97s - loss: 2.6130 - val_loss: 2.6826\n",
      "Epoch 548/1000\n",
      " - 96s - loss: 2.6139 - val_loss: 2.7087\n",
      "Epoch 549/1000\n",
      " - 97s - loss: 2.4939 - val_loss: 2.5260\n",
      "Epoch 550/1000\n",
      " - 97s - loss: 2.3821 - val_loss: 2.4628\n",
      "Epoch 551/1000\n",
      " - 97s - loss: 2.2143 - val_loss: 2.3411\n",
      "Epoch 552/1000\n",
      " - 97s - loss: 2.5048 - val_loss: 2.4878\n",
      "Epoch 553/1000\n",
      " - 97s - loss: 2.4660 - val_loss: 2.5951\n",
      "Epoch 554/1000\n",
      " - 97s - loss: 2.4271 - val_loss: 2.3130\n",
      "Epoch 555/1000\n",
      " - 97s - loss: 2.3610 - val_loss: 2.0621\n",
      "Epoch 556/1000\n",
      " - 97s - loss: 2.3683 - val_loss: 2.1060\n",
      "Epoch 557/1000\n",
      " - 97s - loss: 2.2089 - val_loss: 2.1266\n",
      "Epoch 558/1000\n",
      " - 97s - loss: 2.2725 - val_loss: 2.3005\n",
      "Epoch 559/1000\n",
      " - 97s - loss: 2.4780 - val_loss: 2.4397\n",
      "Epoch 560/1000\n",
      " - 97s - loss: 2.4505 - val_loss: 2.3357\n",
      "Epoch 561/1000\n",
      " - 97s - loss: 2.5984 - val_loss: 2.3739\n",
      "Epoch 562/1000\n",
      " - 97s - loss: 2.4423 - val_loss: 1.9548\n",
      "Epoch 563/1000\n",
      " - 96s - loss: 2.2557 - val_loss: 2.3617\n",
      "Epoch 564/1000\n",
      " - 96s - loss: 2.4417 - val_loss: 2.9250\n",
      "Epoch 565/1000\n",
      " - 97s - loss: 2.4326 - val_loss: 2.1944\n",
      "Epoch 566/1000\n",
      " - 96s - loss: 2.3885 - val_loss: 2.4276\n",
      "Epoch 567/1000\n",
      " - 97s - loss: 2.3067 - val_loss: 2.2559\n",
      "Epoch 568/1000\n",
      " - 97s - loss: 2.3138 - val_loss: 2.2766\n",
      "Epoch 569/1000\n",
      " - 96s - loss: 2.4282 - val_loss: 2.5383\n",
      "Epoch 570/1000\n",
      " - 97s - loss: 2.5146 - val_loss: 2.7115\n",
      "Epoch 571/1000\n",
      " - 96s - loss: 2.3729 - val_loss: 2.4497\n",
      "Epoch 572/1000\n",
      " - 97s - loss: 2.2958 - val_loss: 2.2281\n",
      "Epoch 573/1000\n",
      " - 97s - loss: 2.4506 - val_loss: 2.6226\n",
      "Epoch 574/1000\n",
      " - 97s - loss: 2.2764 - val_loss: 2.5474\n",
      "Epoch 575/1000\n",
      " - 97s - loss: 2.3862 - val_loss: 2.0080\n",
      "Epoch 576/1000\n",
      " - 97s - loss: 2.3901 - val_loss: 2.7607\n",
      "Epoch 577/1000\n",
      " - 97s - loss: 2.1848 - val_loss: 2.2863\n",
      "Epoch 578/1000\n",
      " - 97s - loss: 2.6403 - val_loss: 2.1302\n",
      "Epoch 579/1000\n",
      " - 97s - loss: 2.4080 - val_loss: 2.5156\n",
      "Epoch 580/1000\n",
      " - 97s - loss: 2.3611 - val_loss: 2.2008\n",
      "Epoch 581/1000\n",
      " - 97s - loss: 2.2603 - val_loss: 2.6438\n",
      "Epoch 582/1000\n",
      " - 96s - loss: 2.3836 - val_loss: 2.3590\n",
      "Epoch 583/1000\n",
      " - 97s - loss: 2.4124 - val_loss: 2.3759\n",
      "Epoch 584/1000\n",
      " - 97s - loss: 2.3829 - val_loss: 2.1600\n",
      "Epoch 585/1000\n",
      " - 97s - loss: 2.4501 - val_loss: 2.3110\n",
      "Epoch 586/1000\n",
      " - 97s - loss: 2.2761 - val_loss: 2.1802\n",
      "Epoch 587/1000\n",
      " - 97s - loss: 2.3096 - val_loss: 2.1281\n",
      "Epoch 588/1000\n",
      " - 96s - loss: 2.3198 - val_loss: 2.3854\n",
      "Epoch 589/1000\n",
      " - 98s - loss: 2.3283 - val_loss: 2.7944\n",
      "Epoch 590/1000\n",
      " - 97s - loss: 2.3254 - val_loss: 2.3677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591/1000\n",
      " - 98s - loss: 2.5005 - val_loss: 2.5768\n",
      "Epoch 592/1000\n",
      " - 97s - loss: 2.2229 - val_loss: 2.3830\n",
      "Epoch 593/1000\n",
      " - 96s - loss: 2.1827 - val_loss: 2.4794\n",
      "Epoch 594/1000\n",
      " - 97s - loss: 2.3863 - val_loss: 2.2561\n",
      "Epoch 595/1000\n",
      " - 97s - loss: 2.4192 - val_loss: 2.2243\n",
      "Epoch 596/1000\n",
      " - 97s - loss: 2.3185 - val_loss: 2.3708\n",
      "Epoch 597/1000\n",
      " - 97s - loss: 2.2682 - val_loss: 2.1815\n",
      "Epoch 598/1000\n",
      " - 97s - loss: 2.3515 - val_loss: 2.5902\n",
      "Epoch 599/1000\n",
      " - 96s - loss: 2.5047 - val_loss: 2.4676\n",
      "Epoch 600/1000\n",
      " - 97s - loss: 2.2255 - val_loss: 2.4701\n",
      "Epoch 601/1000\n",
      " - 97s - loss: 2.4561 - val_loss: 2.4520\n",
      "Epoch 602/1000\n",
      " - 97s - loss: 2.2485 - val_loss: 2.4795\n",
      "Epoch 603/1000\n",
      " - 98s - loss: 2.5005 - val_loss: 2.2453\n",
      "Epoch 604/1000\n",
      " - 96s - loss: 2.2249 - val_loss: 2.1909\n",
      "Epoch 605/1000\n",
      " - 96s - loss: 2.1535 - val_loss: 2.3669\n",
      "Epoch 606/1000\n",
      " - 97s - loss: 2.3190 - val_loss: 2.3948\n",
      "Epoch 607/1000\n",
      " - 97s - loss: 2.4042 - val_loss: 2.2730\n",
      "Epoch 608/1000\n",
      " - 97s - loss: 2.0727 - val_loss: 2.1529\n",
      "Epoch 609/1000\n",
      " - 97s - loss: 2.3062 - val_loss: 2.1273\n",
      "Epoch 610/1000\n",
      " - 96s - loss: 2.1356 - val_loss: 2.2525\n",
      "Epoch 611/1000\n",
      " - 96s - loss: 2.3631 - val_loss: 2.4923\n",
      "Epoch 612/1000\n",
      " - 98s - loss: 2.3546 - val_loss: 2.2120\n",
      "Epoch 613/1000\n",
      " - 96s - loss: 2.2054 - val_loss: 2.2370\n",
      "Epoch 614/1000\n",
      " - 96s - loss: 2.2986 - val_loss: 2.0705\n",
      "Epoch 615/1000\n",
      " - 97s - loss: 2.1126 - val_loss: 2.3813\n",
      "Epoch 616/1000\n",
      " - 96s - loss: 1.9454 - val_loss: 2.5679\n",
      "Epoch 617/1000\n",
      " - 97s - loss: 2.2362 - val_loss: 1.9837\n",
      "Epoch 618/1000\n",
      " - 97s - loss: 2.2736 - val_loss: 2.1990\n",
      "Epoch 619/1000\n",
      " - 97s - loss: 2.1843 - val_loss: 3.0270\n",
      "Epoch 620/1000\n",
      " - 97s - loss: 2.2878 - val_loss: 2.0440\n",
      "Epoch 621/1000\n",
      " - 97s - loss: 2.3664 - val_loss: 2.3701\n",
      "Epoch 622/1000\n",
      " - 96s - loss: 2.1909 - val_loss: 2.2756\n",
      "Epoch 623/1000\n",
      " - 97s - loss: 2.3065 - val_loss: 2.2050\n",
      "Epoch 624/1000\n",
      " - 97s - loss: 2.2554 - val_loss: 1.9486\n",
      "Epoch 625/1000\n",
      " - 96s - loss: 2.2156 - val_loss: 2.1108\n",
      "Epoch 626/1000\n",
      " - 97s - loss: 2.3093 - val_loss: 2.4224\n",
      "Epoch 627/1000\n",
      " - 96s - loss: 2.2356 - val_loss: 2.2237\n",
      "Epoch 628/1000\n",
      " - 96s - loss: 2.2573 - val_loss: 1.8932\n",
      "Epoch 629/1000\n",
      " - 96s - loss: 2.2947 - val_loss: 2.2085\n",
      "Epoch 630/1000\n",
      " - 97s - loss: 2.2917 - val_loss: 2.3224\n",
      "Epoch 631/1000\n",
      " - 97s - loss: 2.2693 - val_loss: 2.0822\n",
      "Epoch 632/1000\n",
      " - 97s - loss: 2.2121 - val_loss: 2.0984\n",
      "Epoch 633/1000\n",
      " - 97s - loss: 2.1994 - val_loss: 2.1915\n",
      "Epoch 634/1000\n",
      " - 96s - loss: 2.3165 - val_loss: 2.2326\n",
      "Epoch 635/1000\n",
      " - 97s - loss: 2.1784 - val_loss: 2.5838\n",
      "Epoch 636/1000\n",
      " - 97s - loss: 2.3855 - val_loss: 2.3113\n",
      "Epoch 637/1000\n",
      " - 97s - loss: 2.0750 - val_loss: 2.4297\n",
      "Epoch 638/1000\n",
      " - 97s - loss: 2.3473 - val_loss: 2.3046\n",
      "Epoch 639/1000\n",
      " - 96s - loss: 1.9882 - val_loss: 2.1649\n",
      "Epoch 640/1000\n",
      " - 96s - loss: 2.2854 - val_loss: 2.2091\n",
      "Epoch 641/1000\n",
      " - 96s - loss: 2.2435 - val_loss: 1.9680\n",
      "Epoch 642/1000\n",
      " - 96s - loss: 2.3111 - val_loss: 2.6252\n",
      "Epoch 643/1000\n",
      " - 97s - loss: 2.1766 - val_loss: 2.3393\n",
      "Epoch 644/1000\n",
      " - 97s - loss: 2.4088 - val_loss: 1.9732\n",
      "Epoch 645/1000\n",
      " - 96s - loss: 2.2464 - val_loss: 1.9397\n",
      "Epoch 646/1000\n",
      " - 96s - loss: 2.1911 - val_loss: 2.3532\n",
      "Epoch 647/1000\n",
      " - 96s - loss: 2.4317 - val_loss: 2.0470\n",
      "Epoch 648/1000\n",
      " - 97s - loss: 2.1409 - val_loss: 2.2620\n",
      "Epoch 649/1000\n",
      " - 96s - loss: 2.2441 - val_loss: 2.3883\n",
      "Epoch 650/1000\n",
      " - 97s - loss: 2.2111 - val_loss: 2.2361\n",
      "Epoch 651/1000\n",
      " - 96s - loss: 2.0510 - val_loss: 2.0816\n",
      "Epoch 652/1000\n",
      " - 96s - loss: 2.3516 - val_loss: 2.1394\n",
      "Epoch 653/1000\n",
      " - 96s - loss: 2.3415 - val_loss: 2.2573\n",
      "Epoch 654/1000\n",
      " - 96s - loss: 2.1944 - val_loss: 2.4512\n",
      "Epoch 655/1000\n",
      " - 96s - loss: 2.1459 - val_loss: 1.8931\n",
      "Epoch 656/1000\n",
      " - 96s - loss: 2.3206 - val_loss: 2.3046\n",
      "Epoch 657/1000\n",
      " - 96s - loss: 2.4237 - val_loss: 2.0357\n",
      "Epoch 658/1000\n",
      " - 96s - loss: 2.2439 - val_loss: 2.1330\n",
      "Epoch 659/1000\n",
      " - 96s - loss: 2.1978 - val_loss: 2.4975\n",
      "Epoch 660/1000\n",
      " - 97s - loss: 2.2652 - val_loss: 2.1236\n",
      "Epoch 661/1000\n",
      " - 97s - loss: 2.1701 - val_loss: 2.3149\n",
      "Epoch 662/1000\n",
      " - 96s - loss: 2.2241 - val_loss: 2.4579\n",
      "Epoch 663/1000\n",
      " - 96s - loss: 2.3075 - val_loss: 2.3873\n",
      "Epoch 664/1000\n",
      " - 97s - loss: 2.2970 - val_loss: 2.2533\n",
      "Epoch 665/1000\n",
      " - 96s - loss: 2.1099 - val_loss: 2.4240\n",
      "Epoch 666/1000\n",
      " - 96s - loss: 2.2726 - val_loss: 2.3329\n",
      "Epoch 667/1000\n",
      " - 97s - loss: 1.9928 - val_loss: 2.1671\n",
      "Epoch 668/1000\n",
      " - 96s - loss: 1.9785 - val_loss: 2.0751\n",
      "Epoch 669/1000\n",
      " - 96s - loss: 2.0550 - val_loss: 2.5511\n",
      "Epoch 670/1000\n",
      " - 97s - loss: 2.3167 - val_loss: 2.3219\n",
      "Epoch 671/1000\n",
      " - 96s - loss: 2.1866 - val_loss: 2.2147\n",
      "Epoch 672/1000\n",
      " - 97s - loss: 2.1889 - val_loss: 2.6745\n",
      "Epoch 673/1000\n",
      " - 97s - loss: 2.3353 - val_loss: 2.2964\n",
      "Epoch 674/1000\n",
      " - 97s - loss: 2.1790 - val_loss: 2.2345\n",
      "Epoch 675/1000\n",
      " - 97s - loss: 2.1434 - val_loss: 2.1882\n",
      "Epoch 677/1000\n",
      " - 97s - loss: 2.2336 - val_loss: 2.5621\n",
      "Epoch 678/1000\n",
      " - 96s - loss: 2.2982 - val_loss: 2.0906\n",
      "Epoch 679/1000\n",
      " - 97s - loss: 2.1005 - val_loss: 1.9595\n",
      "Epoch 680/1000\n",
      " - 97s - loss: 2.0327 - val_loss: 2.0121\n",
      "Epoch 681/1000\n",
      " - 97s - loss: 2.3946 - val_loss: 2.1508\n",
      "Epoch 682/1000\n",
      " - 97s - loss: 2.2522 - val_loss: 2.5291\n",
      "Epoch 683/1000\n",
      " - 96s - loss: 2.1676 - val_loss: 2.2294\n",
      "Epoch 684/1000\n",
      " - 97s - loss: 2.2053 - val_loss: 2.3140\n",
      "Epoch 685/1000\n",
      " - 97s - loss: 2.0247 - val_loss: 2.2260\n",
      "Epoch 686/1000\n",
      " - 96s - loss: 1.9377 - val_loss: 2.0108\n",
      "Epoch 687/1000\n",
      " - 97s - loss: 2.2402 - val_loss: 2.2236\n",
      "Epoch 688/1000\n",
      " - 98s - loss: 2.2738 - val_loss: 2.0934\n",
      "Epoch 689/1000\n",
      " - 97s - loss: 2.3220 - val_loss: 2.1727\n",
      "Epoch 690/1000\n",
      " - 97s - loss: 2.1194 - val_loss: 2.1077\n",
      "Epoch 691/1000\n",
      " - 97s - loss: 2.1143 - val_loss: 1.9565\n",
      "Epoch 692/1000\n",
      " - 96s - loss: 2.3105 - val_loss: 2.0170\n",
      "Epoch 693/1000\n",
      " - 97s - loss: 2.3230 - val_loss: 1.7553\n",
      "Epoch 694/1000\n",
      " - 97s - loss: 2.1827 - val_loss: 2.0174\n",
      "Epoch 695/1000\n",
      " - 97s - loss: 2.2239 - val_loss: 2.3450\n",
      "Epoch 696/1000\n",
      " - 97s - loss: 2.0865 - val_loss: 2.1119\n",
      "Epoch 697/1000\n",
      " - 97s - loss: 2.2593 - val_loss: 2.5897\n",
      "Epoch 698/1000\n",
      " - 97s - loss: 2.2855 - val_loss: 2.0855\n",
      "Epoch 699/1000\n",
      " - 96s - loss: 2.1422 - val_loss: 2.4807\n",
      "Epoch 700/1000\n",
      " - 96s - loss: 2.0796 - val_loss: 2.1175\n",
      "Epoch 701/1000\n",
      " - 97s - loss: 2.1420 - val_loss: 2.3958\n",
      "Epoch 702/1000\n",
      " - 97s - loss: 2.0527 - val_loss: 2.2549\n",
      "Epoch 703/1000\n",
      " - 96s - loss: 2.0132 - val_loss: 2.1471\n",
      "Epoch 704/1000\n",
      " - 97s - loss: 2.1004 - val_loss: 2.2091\n",
      "Epoch 705/1000\n",
      " - 96s - loss: 2.2563 - val_loss: 2.4083\n",
      "Epoch 706/1000\n",
      " - 96s - loss: 2.1029 - val_loss: 2.0286\n",
      "Epoch 707/1000\n",
      " - 96s - loss: 1.9100 - val_loss: 2.3535\n",
      "Epoch 708/1000\n",
      " - 96s - loss: 1.9558 - val_loss: 2.2731\n",
      "Epoch 709/1000\n",
      " - 96s - loss: 2.0627 - val_loss: 2.1241\n",
      "Epoch 710/1000\n",
      " - 97s - loss: 1.9493 - val_loss: 1.9876\n",
      "Epoch 711/1000\n",
      " - 96s - loss: 2.0042 - val_loss: 1.9468\n",
      "Epoch 712/1000\n",
      " - 96s - loss: 2.0435 - val_loss: 2.2733\n",
      "Epoch 713/1000\n",
      " - 96s - loss: 2.2327 - val_loss: 2.2223\n",
      "Epoch 714/1000\n",
      " - 96s - loss: 2.0591 - val_loss: 2.0045\n",
      "Epoch 715/1000\n",
      " - 96s - loss: 1.9856 - val_loss: 2.4159\n",
      "Epoch 716/1000\n",
      " - 96s - loss: 2.2016 - val_loss: 2.1651\n",
      "Epoch 717/1000\n",
      " - 97s - loss: 2.2933 - val_loss: 2.0388\n",
      "Epoch 718/1000\n",
      " - 96s - loss: 2.0129 - val_loss: 2.3850\n",
      "Epoch 719/1000\n",
      " - 96s - loss: 2.0462 - val_loss: 1.9215\n",
      "Epoch 720/1000\n",
      " - 96s - loss: 2.0431 - val_loss: 2.4317\n",
      "Epoch 721/1000\n",
      " - 97s - loss: 2.0560 - val_loss: 2.4757\n",
      "Epoch 722/1000\n",
      " - 96s - loss: 1.9762 - val_loss: 2.2012\n",
      "Epoch 723/1000\n",
      " - 96s - loss: 1.9541 - val_loss: 2.0925\n",
      "Epoch 724/1000\n",
      " - 97s - loss: 2.0805 - val_loss: 2.1764\n",
      "Epoch 725/1000\n",
      " - 96s - loss: 1.9965 - val_loss: 1.9811\n",
      "Epoch 726/1000\n",
      " - 97s - loss: 2.1160 - val_loss: 2.4802\n",
      "Epoch 727/1000\n",
      " - 96s - loss: 2.0226 - val_loss: 1.7172\n",
      "Epoch 728/1000\n",
      " - 96s - loss: 1.9460 - val_loss: 1.9421\n",
      "Epoch 729/1000\n",
      " - 96s - loss: 2.0999 - val_loss: 2.1893\n",
      "Epoch 730/1000\n",
      " - 96s - loss: 2.1023 - val_loss: 2.0368\n",
      "Epoch 731/1000\n",
      " - 96s - loss: 2.0545 - val_loss: 1.7208\n",
      "Epoch 732/1000\n",
      " - 96s - loss: 2.0356 - val_loss: 2.2250\n",
      "Epoch 733/1000\n",
      " - 97s - loss: 2.0538 - val_loss: 2.3439\n",
      "Epoch 734/1000\n",
      " - 96s - loss: 2.0029 - val_loss: 1.8948\n",
      "Epoch 735/1000\n",
      " - 96s - loss: 1.8973 - val_loss: 1.9202\n",
      "Epoch 736/1000\n",
      " - 97s - loss: 2.2208 - val_loss: 2.3857\n",
      "Epoch 737/1000\n",
      " - 96s - loss: 2.0852 - val_loss: 2.4594\n",
      "Epoch 738/1000\n",
      " - 96s - loss: 2.0699 - val_loss: 2.1804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 739/1000\n",
      " - 97s - loss: 2.1799 - val_loss: 2.0166\n",
      "Epoch 740/1000\n",
      " - 97s - loss: 1.9717 - val_loss: 2.1199\n",
      "Epoch 741/1000\n",
      " - 96s - loss: 1.9890 - val_loss: 1.8678\n",
      "Epoch 742/1000\n",
      " - 97s - loss: 2.0101 - val_loss: 2.2165\n",
      "Epoch 743/1000\n",
      " - 96s - loss: 1.9989 - val_loss: 2.0118\n",
      "Epoch 744/1000\n",
      " - 97s - loss: 2.0794 - val_loss: 2.6013\n",
      "Epoch 745/1000\n",
      " - 96s - loss: 2.1421 - val_loss: 2.0459\n",
      "Epoch 746/1000\n",
      " - 96s - loss: 2.0990 - val_loss: 1.6234\n",
      "Epoch 747/1000\n",
      " - 97s - loss: 2.0284 - val_loss: 2.0411\n",
      "Epoch 748/1000\n",
      " - 97s - loss: 2.1939 - val_loss: 2.2451\n",
      "Epoch 749/1000\n",
      " - 96s - loss: 2.0697 - val_loss: 2.0353\n",
      "Epoch 750/1000\n",
      " - 96s - loss: 1.9243 - val_loss: 1.9645\n",
      "Epoch 751/1000\n",
      " - 97s - loss: 2.1739 - val_loss: 2.0477\n",
      "Epoch 752/1000\n",
      " - 96s - loss: 2.1159 - val_loss: 1.9775\n",
      "Epoch 753/1000\n",
      " - 96s - loss: 2.1970 - val_loss: 1.9564\n",
      "Epoch 754/1000\n",
      " - 97s - loss: 2.1951 - val_loss: 2.1071\n",
      "Epoch 755/1000\n",
      " - 96s - loss: 1.8080 - val_loss: 1.7625\n",
      "Epoch 756/1000\n",
      " - 96s - loss: 2.1790 - val_loss: 1.7191\n",
      "Epoch 757/1000\n",
      " - 97s - loss: 2.2503 - val_loss: 2.0680\n",
      "Epoch 758/1000\n",
      " - 97s - loss: 1.9387 - val_loss: 2.0087\n",
      "Epoch 759/1000\n",
      " - 97s - loss: 1.9393 - val_loss: 2.1804\n",
      "Epoch 760/1000\n",
      " - 97s - loss: 2.1603 - val_loss: 2.3091\n",
      "Epoch 761/1000\n",
      " - 96s - loss: 1.9766 - val_loss: 1.9232\n",
      "Epoch 762/1000\n",
      " - 97s - loss: 2.1202 - val_loss: 1.8179\n",
      "Epoch 763/1000\n",
      " - 97s - loss: 2.1420 - val_loss: 2.0981\n",
      "Epoch 764/1000\n",
      " - 96s - loss: 2.1026 - val_loss: 2.1592\n",
      "Epoch 765/1000\n",
      " - 97s - loss: 2.1745 - val_loss: 1.9855\n",
      "Epoch 766/1000\n",
      " - 97s - loss: 2.1181 - val_loss: 1.8414\n",
      "Epoch 767/1000\n",
      " - 97s - loss: 1.9727 - val_loss: 1.8900\n",
      "Epoch 768/1000\n",
      " - 97s - loss: 1.9855 - val_loss: 2.1256\n",
      "Epoch 769/1000\n",
      " - 96s - loss: 2.2446 - val_loss: 2.2732\n",
      "Epoch 770/1000\n",
      " - 96s - loss: 2.0605 - val_loss: 1.8637\n",
      "Epoch 771/1000\n",
      " - 96s - loss: 1.9571 - val_loss: 2.4228\n",
      "Epoch 772/1000\n",
      " - 96s - loss: 1.9572 - val_loss: 2.1149\n",
      "Epoch 773/1000\n",
      " - 97s - loss: 1.9834 - val_loss: 1.9358\n",
      "Epoch 774/1000\n",
      " - 96s - loss: 1.9570 - val_loss: 2.4215\n",
      "Epoch 775/1000\n",
      " - 96s - loss: 2.1761 - val_loss: 2.5685\n",
      "Epoch 776/1000\n",
      " - 96s - loss: 2.0703 - val_loss: 2.4186\n",
      "Epoch 777/1000\n",
      " - 96s - loss: 2.0237 - val_loss: 2.0079\n",
      "Epoch 778/1000\n",
      " - 96s - loss: 1.8550 - val_loss: 1.8318\n",
      "Epoch 779/1000\n",
      " - 97s - loss: 1.9527 - val_loss: 1.8266\n",
      "Epoch 780/1000\n",
      " - 96s - loss: 1.9677 - val_loss: 2.3401\n",
      "Epoch 781/1000\n",
      " - 97s - loss: 1.9828 - val_loss: 2.0774\n",
      "Epoch 782/1000\n",
      " - 96s - loss: 2.1088 - val_loss: 2.0960\n",
      "Epoch 783/1000\n",
      " - 96s - loss: 1.9110 - val_loss: 2.1676\n",
      "Epoch 784/1000\n",
      " - 96s - loss: 2.1378 - val_loss: 2.1431\n",
      "Epoch 785/1000\n",
      " - 96s - loss: 1.9932 - val_loss: 2.0567\n",
      "Epoch 786/1000\n",
      " - 96s - loss: 2.1526 - val_loss: 2.0696\n",
      "Epoch 787/1000\n",
      " - 96s - loss: 1.8827 - val_loss: 2.2029\n",
      "Epoch 788/1000\n",
      " - 96s - loss: 2.0244 - val_loss: 2.0557\n",
      "Epoch 789/1000\n",
      " - 96s - loss: 1.9925 - val_loss: 2.1121\n",
      "Epoch 790/1000\n",
      " - 96s - loss: 1.9812 - val_loss: 2.3084\n",
      "Epoch 791/1000\n",
      " - 96s - loss: 2.0838 - val_loss: 2.1997\n",
      "Epoch 792/1000\n",
      " - 96s - loss: 1.9231 - val_loss: 1.8137\n",
      "Epoch 793/1000\n",
      " - 96s - loss: 2.1076 - val_loss: 2.4088\n",
      "Epoch 794/1000\n",
      " - 96s - loss: 1.9499 - val_loss: 2.0185\n",
      "Epoch 795/1000\n",
      " - 96s - loss: 2.0819 - val_loss: 2.3534\n",
      "Epoch 796/1000\n",
      " - 96s - loss: 2.0772 - val_loss: 1.8755\n",
      "Epoch 797/1000\n",
      " - 96s - loss: 1.8371 - val_loss: 1.9436\n",
      "Epoch 798/1000\n",
      " - 96s - loss: 1.9626 - val_loss: 2.1528\n",
      "Epoch 799/1000\n",
      " - 97s - loss: 2.0252 - val_loss: 2.4683\n",
      "Epoch 800/1000\n",
      " - 96s - loss: 2.0199 - val_loss: 1.8728\n",
      "Epoch 801/1000\n",
      " - 97s - loss: 1.9152 - val_loss: 2.1029\n",
      "Epoch 802/1000\n",
      " - 96s - loss: 2.0958 - val_loss: 1.8916\n",
      "Epoch 803/1000\n",
      " - 97s - loss: 2.0075 - val_loss: 2.1419\n",
      "Epoch 804/1000\n",
      " - 96s - loss: 1.9796 - val_loss: 2.0335\n",
      "Epoch 805/1000\n",
      " - 96s - loss: 2.0076 - val_loss: 1.9111\n",
      "Epoch 806/1000\n",
      " - 96s - loss: 1.9475 - val_loss: 1.9117\n",
      "Epoch 807/1000\n",
      " - 96s - loss: 1.9127 - val_loss: 1.8916\n",
      "Epoch 808/1000\n",
      " - 96s - loss: 1.9357 - val_loss: 2.1273\n",
      "Epoch 809/1000\n",
      " - 96s - loss: 1.9648 - val_loss: 2.0714\n",
      "Epoch 810/1000\n",
      " - 97s - loss: 1.9383 - val_loss: 1.4502\n",
      "Epoch 811/1000\n",
      " - 96s - loss: 1.9928 - val_loss: 2.0042\n",
      "Epoch 812/1000\n",
      " - 96s - loss: 1.8362 - val_loss: 1.7439\n",
      "Epoch 813/1000\n",
      " - 97s - loss: 1.8241 - val_loss: 2.1941\n",
      "Epoch 814/1000\n",
      " - 96s - loss: 2.0338 - val_loss: 2.1163\n",
      "Epoch 815/1000\n",
      " - 96s - loss: 1.8861 - val_loss: 1.7676\n",
      "Epoch 816/1000\n",
      " - 96s - loss: 2.0791 - val_loss: 2.0391\n",
      "Epoch 817/1000\n",
      " - 96s - loss: 1.9646 - val_loss: 1.9970\n",
      "Epoch 818/1000\n",
      " - 97s - loss: 1.8491 - val_loss: 1.9158\n",
      "Epoch 819/1000\n",
      " - 96s - loss: 1.9016 - val_loss: 2.1250\n",
      "Epoch 820/1000\n",
      " - 97s - loss: 1.9114 - val_loss: 1.9149\n",
      "Epoch 821/1000\n",
      " - 97s - loss: 2.0404 - val_loss: 2.0145\n",
      "Epoch 822/1000\n",
      " - 97s - loss: 1.8441 - val_loss: 2.1224\n",
      "Epoch 823/1000\n",
      " - 96s - loss: 1.8452 - val_loss: 2.2018\n",
      "Epoch 824/1000\n",
      " - 96s - loss: 1.9144 - val_loss: 1.7622\n",
      "Epoch 825/1000\n",
      " - 97s - loss: 1.8952 - val_loss: 2.1120\n",
      "Epoch 826/1000\n",
      " - 97s - loss: 1.9681 - val_loss: 2.0051\n",
      "Epoch 827/1000\n",
      " - 97s - loss: 1.7858 - val_loss: 2.1272\n",
      "Epoch 828/1000\n",
      " - 96s - loss: 1.6951 - val_loss: 2.4095\n",
      "Epoch 829/1000\n",
      " - 96s - loss: 1.9343 - val_loss: 1.8211\n",
      "Epoch 830/1000\n",
      " - 97s - loss: 1.8272 - val_loss: 2.1212\n",
      "Epoch 831/1000\n",
      " - 97s - loss: 1.7765 - val_loss: 2.0814\n",
      "Epoch 832/1000\n",
      " - 96s - loss: 1.9482 - val_loss: 2.1049\n",
      "Epoch 833/1000\n",
      " - 97s - loss: 1.8979 - val_loss: 2.3974\n",
      "Epoch 834/1000\n",
      " - 97s - loss: 1.9977 - val_loss: 2.1750\n",
      "Epoch 835/1000\n",
      " - 96s - loss: 1.8086 - val_loss: 1.7672\n",
      "Epoch 836/1000\n",
      " - 96s - loss: 2.0031 - val_loss: 2.2183\n",
      "Epoch 837/1000\n",
      " - 96s - loss: 1.9754 - val_loss: 2.0554\n",
      "Epoch 838/1000\n",
      " - 97s - loss: 1.8380 - val_loss: 1.7790\n",
      "Epoch 839/1000\n",
      " - 97s - loss: 1.9532 - val_loss: 2.0349\n",
      "Epoch 840/1000\n",
      " - 97s - loss: 1.9021 - val_loss: 2.0878\n",
      "Epoch 841/1000\n",
      " - 96s - loss: 1.8862 - val_loss: 1.9867\n",
      "Epoch 842/1000\n",
      " - 97s - loss: 1.9261 - val_loss: 1.8497\n",
      "Epoch 843/1000\n",
      " - 96s - loss: 1.7324 - val_loss: 1.9340\n",
      "Epoch 844/1000\n",
      " - 97s - loss: 1.7400 - val_loss: 2.3352\n",
      "Epoch 845/1000\n",
      " - 97s - loss: 1.7770 - val_loss: 2.0638\n",
      "Epoch 846/1000\n",
      " - 96s - loss: 1.9301 - val_loss: 2.1442\n",
      "Epoch 847/1000\n",
      " - 97s - loss: 1.9488 - val_loss: 2.0146\n",
      "Epoch 848/1000\n",
      " - 97s - loss: 1.9779 - val_loss: 2.2707\n",
      "Epoch 849/1000\n",
      " - 97s - loss: 1.9139 - val_loss: 2.1289\n",
      "Epoch 850/1000\n",
      " - 97s - loss: 2.0375 - val_loss: 1.9050\n",
      "Epoch 851/1000\n",
      " - 96s - loss: 1.9002 - val_loss: 1.9606\n",
      "Epoch 852/1000\n",
      " - 97s - loss: 1.9518 - val_loss: 2.2059\n",
      "Epoch 853/1000\n",
      " - 97s - loss: 2.0055 - val_loss: 2.0092\n",
      "Epoch 854/1000\n",
      " - 97s - loss: 1.8392 - val_loss: 2.1817\n",
      "Epoch 855/1000\n",
      " - 96s - loss: 2.0157 - val_loss: 2.1285\n",
      "Epoch 856/1000\n",
      " - 97s - loss: 1.8795 - val_loss: 2.3497\n",
      "Epoch 857/1000\n",
      " - 97s - loss: 1.8867 - val_loss: 1.9349\n",
      "Epoch 858/1000\n",
      " - 97s - loss: 1.8063 - val_loss: 1.9926\n",
      "Epoch 859/1000\n",
      " - 97s - loss: 1.6413 - val_loss: 1.9544\n",
      "Epoch 860/1000\n",
      " - 97s - loss: 1.8875 - val_loss: 2.0654\n",
      "Epoch 861/1000\n",
      " - 97s - loss: 1.8303 - val_loss: 2.1257\n",
      "Epoch 862/1000\n",
      " - 97s - loss: 1.7716 - val_loss: 2.1993\n",
      "Epoch 863/1000\n",
      " - 97s - loss: 1.9565 - val_loss: 1.9922\n",
      "Epoch 864/1000\n",
      " - 97s - loss: 1.7920 - val_loss: 2.0928\n",
      "Epoch 865/1000\n",
      " - 97s - loss: 1.7654 - val_loss: 1.9999\n",
      "Epoch 866/1000\n",
      " - 96s - loss: 1.9098 - val_loss: 1.9190\n",
      "Epoch 867/1000\n",
      " - 96s - loss: 1.9789 - val_loss: 1.9725\n",
      "Epoch 868/1000\n",
      " - 97s - loss: 1.8906 - val_loss: 1.9532\n",
      "Epoch 869/1000\n",
      " - 97s - loss: 2.0398 - val_loss: 2.0725\n",
      "Epoch 870/1000\n",
      " - 96s - loss: 1.7925 - val_loss: 1.9117\n",
      "Epoch 871/1000\n",
      " - 97s - loss: 1.9256 - val_loss: 1.7435\n",
      "Epoch 872/1000\n",
      " - 97s - loss: 1.9879 - val_loss: 1.8748\n",
      "Epoch 873/1000\n",
      " - 96s - loss: 1.9905 - val_loss: 1.8577\n",
      "Epoch 874/1000\n",
      " - 97s - loss: 1.8401 - val_loss: 1.9441\n",
      "Epoch 875/1000\n",
      " - 97s - loss: 1.8514 - val_loss: 1.8645\n",
      "Epoch 876/1000\n",
      " - 96s - loss: 1.9590 - val_loss: 1.8597\n",
      "Epoch 877/1000\n",
      " - 97s - loss: 1.9157 - val_loss: 1.7885\n",
      "Epoch 878/1000\n",
      " - 96s - loss: 2.0193 - val_loss: 2.0711\n",
      "Epoch 879/1000\n",
      " - 97s - loss: 1.8916 - val_loss: 1.9930\n",
      "Epoch 880/1000\n",
      " - 97s - loss: 1.9195 - val_loss: 1.8306\n",
      "Epoch 881/1000\n",
      " - 97s - loss: 1.8659 - val_loss: 1.9217\n",
      "Epoch 882/1000\n",
      " - 97s - loss: 1.8625 - val_loss: 1.9003\n",
      "Epoch 883/1000\n",
      " - 97s - loss: 1.9599 - val_loss: 2.1776\n",
      "Epoch 884/1000\n",
      " - 96s - loss: 1.8980 - val_loss: 1.8945\n",
      "Epoch 885/1000\n",
      " - 97s - loss: 1.7568 - val_loss: 1.8685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/1000\n",
      " - 97s - loss: 1.8766 - val_loss: 1.9958\n",
      "Epoch 887/1000\n",
      " - 96s - loss: 1.9698 - val_loss: 1.9037\n",
      "Epoch 888/1000\n",
      " - 96s - loss: 1.7953 - val_loss: 1.8132\n",
      "Epoch 889/1000\n",
      " - 96s - loss: 1.7248 - val_loss: 1.8033\n",
      "Epoch 890/1000\n",
      " - 97s - loss: 2.0756 - val_loss: 2.1140\n",
      "Epoch 891/1000\n",
      " - 96s - loss: 1.8104 - val_loss: 1.9747\n",
      "Epoch 892/1000\n",
      " - 96s - loss: 2.0869 - val_loss: 1.7119\n",
      "Epoch 893/1000\n",
      " - 96s - loss: 1.8414 - val_loss: 1.9998\n",
      "Epoch 894/1000\n",
      " - 97s - loss: 1.7823 - val_loss: 2.4170\n",
      "Epoch 895/1000\n",
      " - 96s - loss: 2.0205 - val_loss: 1.9288\n",
      "Epoch 896/1000\n",
      " - 97s - loss: 2.0142 - val_loss: 1.5733\n",
      "Epoch 897/1000\n",
      " - 97s - loss: 1.7487 - val_loss: 2.0061\n",
      "Epoch 898/1000\n",
      " - 97s - loss: 1.7684 - val_loss: 1.8874\n",
      "Epoch 899/1000\n",
      " - 97s - loss: 1.9091 - val_loss: 2.2918\n",
      "Epoch 900/1000\n",
      " - 97s - loss: 1.8982 - val_loss: 1.6151\n",
      "Epoch 901/1000\n",
      " - 97s - loss: 2.0857 - val_loss: 1.8129\n",
      "Epoch 902/1000\n",
      " - 97s - loss: 1.8986 - val_loss: 2.4114\n",
      "Epoch 903/1000\n",
      " - 97s - loss: 1.7636 - val_loss: 1.6346\n",
      "Epoch 904/1000\n",
      " - 97s - loss: 1.7675 - val_loss: 1.8387\n",
      "Epoch 905/1000\n",
      " - 97s - loss: 1.6389 - val_loss: 1.8560\n",
      "Epoch 906/1000\n",
      " - 97s - loss: 1.7133 - val_loss: 1.6707\n",
      "Epoch 907/1000\n",
      " - 97s - loss: 1.7305 - val_loss: 2.0577\n",
      "Epoch 908/1000\n",
      " - 97s - loss: 1.8165 - val_loss: 2.0544\n",
      "Epoch 909/1000\n",
      " - 97s - loss: 1.8322 - val_loss: 1.8714\n",
      "Epoch 910/1000\n",
      " - 97s - loss: 1.7807 - val_loss: 2.0584\n",
      "Epoch 911/1000\n",
      " - 97s - loss: 1.8595 - val_loss: 2.2701\n",
      "Epoch 912/1000\n",
      " - 97s - loss: 1.8240 - val_loss: 1.7172\n",
      "Epoch 913/1000\n",
      " - 97s - loss: 2.0037 - val_loss: 1.9723\n",
      "Epoch 914/1000\n",
      " - 97s - loss: 1.7025 - val_loss: 2.1499\n",
      "Epoch 915/1000\n",
      " - 97s - loss: 1.8325 - val_loss: 1.9987\n",
      "Epoch 916/1000\n",
      " - 97s - loss: 1.8763 - val_loss: 2.2202\n",
      "Epoch 917/1000\n",
      " - 96s - loss: 1.6352 - val_loss: 1.7029\n",
      "Epoch 918/1000\n",
      " - 98s - loss: 1.8708 - val_loss: 1.8673\n",
      "Epoch 919/1000\n",
      " - 97s - loss: 1.7147 - val_loss: 1.8597\n",
      "Epoch 920/1000\n",
      " - 96s - loss: 1.7264 - val_loss: 1.9407\n",
      "Epoch 921/1000\n",
      " - 97s - loss: 1.7571 - val_loss: 1.8314\n",
      "Epoch 922/1000\n",
      " - 97s - loss: 1.7557 - val_loss: 1.7983\n",
      "Epoch 923/1000\n",
      " - 96s - loss: 1.7816 - val_loss: 1.9349\n",
      "Epoch 924/1000\n",
      " - 97s - loss: 1.6181 - val_loss: 1.9163\n",
      "Epoch 925/1000\n",
      " - 97s - loss: 1.8104 - val_loss: 2.0922\n",
      "Epoch 926/1000\n",
      " - 96s - loss: 2.0451 - val_loss: 1.7434\n",
      "Epoch 927/1000\n",
      " - 97s - loss: 1.7398 - val_loss: 2.1112\n",
      "Epoch 928/1000\n",
      " - 97s - loss: 1.8319 - val_loss: 1.8229\n",
      "Epoch 929/1000\n",
      " - 97s - loss: 1.7733 - val_loss: 1.8658\n",
      "Epoch 930/1000\n",
      " - 97s - loss: 1.7121 - val_loss: 1.9577\n",
      "Epoch 931/1000\n",
      " - 97s - loss: 1.8060 - val_loss: 1.8162\n",
      "Epoch 932/1000\n",
      " - 96s - loss: 1.8444 - val_loss: 2.0711\n",
      "Epoch 933/1000\n",
      " - 98s - loss: 1.9305 - val_loss: 2.0253\n",
      "Epoch 934/1000\n",
      " - 97s - loss: 1.8939 - val_loss: 1.8646\n",
      "Epoch 935/1000\n",
      " - 97s - loss: 1.8523 - val_loss: 1.7784\n",
      "Epoch 936/1000\n",
      " - 97s - loss: 1.6720 - val_loss: 1.9149\n",
      "Epoch 937/1000\n",
      " - 97s - loss: 1.9246 - val_loss: 2.0094\n",
      "Epoch 938/1000\n",
      " - 97s - loss: 1.7627 - val_loss: 2.1700\n",
      "Epoch 939/1000\n",
      " - 97s - loss: 1.7091 - val_loss: 1.8368\n",
      "Epoch 940/1000\n",
      " - 96s - loss: 1.9468 - val_loss: 2.0520\n",
      "Epoch 941/1000\n",
      " - 97s - loss: 1.7379 - val_loss: 1.9081\n",
      "Epoch 942/1000\n",
      " - 97s - loss: 1.6386 - val_loss: 1.9743\n",
      "Epoch 943/1000\n",
      " - 97s - loss: 1.9790 - val_loss: 2.0304\n",
      "Epoch 944/1000\n",
      " - 97s - loss: 1.6721 - val_loss: 1.9772\n",
      "Epoch 945/1000\n",
      " - 97s - loss: 1.8407 - val_loss: 1.7767\n",
      "Epoch 946/1000\n",
      " - 97s - loss: 1.8156 - val_loss: 1.8930\n",
      "Epoch 947/1000\n",
      " - 97s - loss: 1.8379 - val_loss: 2.1130\n",
      "Epoch 948/1000\n",
      " - 97s - loss: 1.8550 - val_loss: 2.0929\n",
      "Epoch 949/1000\n",
      " - 97s - loss: 1.6689 - val_loss: 1.6026\n",
      "Epoch 950/1000\n",
      " - 97s - loss: 1.7265 - val_loss: 2.0726\n",
      "Epoch 951/1000\n",
      " - 97s - loss: 1.8599 - val_loss: 1.7603\n",
      "Epoch 952/1000\n",
      " - 98s - loss: 1.9965 - val_loss: 1.8190\n",
      "Epoch 953/1000\n",
      " - 97s - loss: 1.7831 - val_loss: 1.9257\n",
      "Epoch 954/1000\n",
      " - 97s - loss: 1.9273 - val_loss: 1.7880\n",
      "Epoch 955/1000\n",
      " - 97s - loss: 1.6479 - val_loss: 1.9379\n",
      "Epoch 956/1000\n",
      " - 97s - loss: 1.8169 - val_loss: 1.8603\n",
      "Epoch 957/1000\n",
      " - 97s - loss: 1.6981 - val_loss: 1.7149\n",
      "Epoch 958/1000\n",
      " - 98s - loss: 1.7666 - val_loss: 1.7472\n",
      "Epoch 959/1000\n",
      " - 97s - loss: 1.7067 - val_loss: 2.0026\n",
      "Epoch 960/1000\n",
      " - 97s - loss: 1.7647 - val_loss: 2.0443\n",
      "Epoch 961/1000\n",
      " - 98s - loss: 1.7238 - val_loss: 1.7313\n",
      "Epoch 962/1000\n",
      " - 97s - loss: 1.7638 - val_loss: 2.0521\n",
      "Epoch 963/1000\n",
      " - 97s - loss: 1.6951 - val_loss: 1.8636\n",
      "Epoch 964/1000\n",
      " - 98s - loss: 1.8444 - val_loss: 1.9546\n",
      "Epoch 965/1000\n",
      " - 97s - loss: 1.8043 - val_loss: 1.6591\n",
      "Epoch 966/1000\n",
      " - 97s - loss: 1.6329 - val_loss: 1.8267\n",
      "Epoch 967/1000\n",
      " - 97s - loss: 1.8581 - val_loss: 1.9309\n",
      "Epoch 968/1000\n",
      " - 97s - loss: 1.9534 - val_loss: 1.7485\n",
      "Epoch 969/1000\n",
      " - 97s - loss: 1.6158 - val_loss: 1.6601\n",
      "Epoch 970/1000\n",
      " - 97s - loss: 1.8954 - val_loss: 1.9071\n",
      "Epoch 973/1000\n",
      " - 98s - loss: 1.8230 - val_loss: 1.8929\n",
      "Epoch 974/1000\n",
      " - 98s - loss: 1.8087 - val_loss: 1.8090\n",
      "Epoch 975/1000\n",
      " - 97s - loss: 1.6118 - val_loss: 1.8340\n",
      "Epoch 976/1000\n",
      " - 97s - loss: 1.6945 - val_loss: 2.1805\n",
      "Epoch 977/1000\n",
      " - 97s - loss: 1.8428 - val_loss: 1.7999\n",
      "Epoch 978/1000\n",
      " - 96s - loss: 1.7875 - val_loss: 2.1593\n",
      "Epoch 979/1000\n",
      " - 97s - loss: 1.8388 - val_loss: 1.8492\n",
      "Epoch 980/1000\n",
      " - 97s - loss: 1.8195 - val_loss: 1.9475\n",
      "Epoch 981/1000\n",
      " - 96s - loss: 1.7463 - val_loss: 1.8264\n",
      "Epoch 982/1000\n",
      " - 97s - loss: 1.7801 - val_loss: 1.7556\n",
      "Epoch 983/1000\n",
      " - 97s - loss: 1.7085 - val_loss: 2.2370\n",
      "Epoch 984/1000\n",
      " - 96s - loss: 1.7052 - val_loss: 1.8581\n",
      "Epoch 985/1000\n",
      " - 97s - loss: 1.7830 - val_loss: 1.8120\n",
      "Epoch 986/1000\n",
      " - 96s - loss: 1.9872 - val_loss: 1.8742\n",
      "Epoch 987/1000\n",
      " - 96s - loss: 1.7058 - val_loss: 1.7846\n",
      "Epoch 988/1000\n",
      " - 97s - loss: 1.6694 - val_loss: 1.6159\n",
      "Epoch 989/1000\n",
      " - 97s - loss: 1.7624 - val_loss: 1.9173\n",
      "Epoch 990/1000\n",
      " - 97s - loss: 1.9290 - val_loss: 1.9855\n",
      "Epoch 991/1000\n",
      " - 97s - loss: 1.7364 - val_loss: 1.7882\n",
      "Epoch 992/1000\n",
      " - 97s - loss: 1.8049 - val_loss: 2.0365\n",
      "Epoch 993/1000\n",
      " - 97s - loss: 1.7753 - val_loss: 1.5044\n",
      "Epoch 994/1000\n",
      " - 98s - loss: 1.6871 - val_loss: 1.6568\n",
      "Epoch 995/1000\n",
      " - 97s - loss: 1.9719 - val_loss: 1.7158\n",
      "Epoch 996/1000\n",
      " - 97s - loss: 1.7872 - val_loss: 1.8912\n",
      "Epoch 997/1000\n",
      " - 98s - loss: 1.6029 - val_loss: 1.9597\n",
      "Epoch 998/1000\n",
      " - 96s - loss: 1.7232 - val_loss: 1.8723\n",
      "Epoch 999/1000\n",
      " - 96s - loss: 1.6267 - val_loss: 1.7282\n",
      "Epoch 1000/1000\n",
      " - 96s - loss: 1.6819 - val_loss: 2.0374\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = triplet_model.fit_generator(train_generator, steps_per_epoch=67, epochs=1000, \n",
    "                                      validation_data=test_generator, validation_steps=50, \n",
    "                                      verbose=2, callbacks=callbacks)\n",
    "\n",
    "base_model.save(path + '/facenet-model.h5')\n",
    "pickle.dump(history.history, open(path + '/facenet-history.p', 'wb'))\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training process\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.plot(train_loss, label='Training Loss')\n",
    "ax.plot(val_loss, label='Validation Loss')\n",
    "ax.set_title('Loss vs. Epochs', fontsize=16)\n",
    "ax.set_xlabel('Epochs', fontsize=14)\n",
    "ax.set_ylabel('Loss', fontsize=14)\n",
    "ax.legend(fontsize=14)\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
