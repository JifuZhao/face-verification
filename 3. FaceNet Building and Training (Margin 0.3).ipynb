{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, time, random, keras, pickle, gc\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from face_verification.facenet import basenet\n",
    "from face_verification.facenet import triplet_net\n",
    "from face_verification.facenet import triplet_loss\n",
    "from face_verification.facenet import train_triplet_generator\n",
    "from face_verification.facenet import test_triplet_generator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t# person = 8631\t # images = 2113881\n",
      "Test:\t# person =  500\t # images =  116568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0054_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0029_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0202_02.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0037_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n000002</td>\n",
       "      <td>./images/vgg2_face/train/n000002/0046_01.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                                          path\n",
       "0  n000002  ./images/vgg2_face/train/n000002/0054_01.jpg\n",
       "1  n000002  ./images/vgg2_face/train/n000002/0029_01.jpg\n",
       "2  n000002  ./images/vgg2_face/train/n000002/0202_02.jpg\n",
       "3  n000002  ./images/vgg2_face/train/n000002/0037_01.jpg\n",
       "4  n000002  ./images/vgg2_face/train/n000002/0046_01.jpg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg2_train = pd.read_csv('./images/vgg2_train_path.csv')\n",
    "vgg2_test = pd.read_csv('./images/vgg2_test_path.csv')\n",
    "\n",
    "print('Train:\\t# person ={0:5d}\\t # images ={1:8d}'.format(len(vgg2_train['name'].unique()), \n",
    "                                                           len(vgg2_train)))\n",
    "print('Test:\\t# person ={0:5d}\\t # images ={1:8d}'.format(len(vgg2_test['name'].unique()),\n",
    "                                                          len(vgg2_test)))\n",
    "\n",
    "vgg2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process the train and test dataframe\n",
    "def path_to_list(df):\n",
    "    \"\"\" function to merge df into the name and path list format \"\"\"\n",
    "    paths = list(df['path'].values)\n",
    "    count = len(paths)\n",
    "    \n",
    "    return pd.Series([count, paths], index=['count', 'paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "      <th>paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n000002</td>\n",
       "      <td>198</td>\n",
       "      <td>[./images/vgg2_face/train/n000002/0054_01.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n000003</td>\n",
       "      <td>143</td>\n",
       "      <td>[./images/vgg2_face/train/n000003/0054_01.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n000004</td>\n",
       "      <td>334</td>\n",
       "      <td>[./images/vgg2_face/train/n000004/0054_01.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n000005</td>\n",
       "      <td>67</td>\n",
       "      <td>[./images/vgg2_face/train/n000005/0430_02.jpg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n000006</td>\n",
       "      <td>374</td>\n",
       "      <td>[./images/vgg2_face/train/n000006/0154_01.jpg,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  count                                              paths\n",
       "0  n000002    198  [./images/vgg2_face/train/n000002/0054_01.jpg,...\n",
       "1  n000003    143  [./images/vgg2_face/train/n000003/0054_01.jpg,...\n",
       "2  n000004    334  [./images/vgg2_face/train/n000004/0054_01.jpg,...\n",
       "3  n000005     67  [./images/vgg2_face/train/n000005/0430_02.jpg,...\n",
       "4  n000006    374  [./images/vgg2_face/train/n000006/0154_01.jpg,..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg2_train_df = vgg2_train.groupby('name').apply(path_to_list).reset_index()\n",
    "vgg2_test_df = vgg2_test.groupby('name').apply(path_to_list).reset_index()\n",
    "\n",
    "vgg2_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Triplet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproduciable purpose\n",
    "seed = 42\n",
    "K.clear_session()\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3148: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 102, 102, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 48, 48, 64)   9472        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 48, 48, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 48, 64)   0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 50, 50, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 24, 24, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lrn_1 (Lambda)                  (None, 24, 24, 64)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 24, 24, 64)   4160        lrn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 24, 24, 64)   256         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 24, 24, 64)   0           bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 26, 26, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 24, 24, 192)  110784      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 24, 24, 192)  768         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 24, 192)  0           bn3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lrn_2 (Lambda)                  (None, 24, 24, 192)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 26, 26, 192)  0           lrn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 192)  0           zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_conv1 (Conv2D) (None, 12, 12, 96)   18528       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_conv1 (Conv2D) (None, 12, 12, 16)   3088        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_bn1 (BatchNorm (None, 12, 12, 16)   64          inception_3a_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 12, 96)   0           inception_3a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 12, 12, 16)   0           inception_3a_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 192)    0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 14, 14, 96)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 16, 16, 16)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_pool_conv (Conv2D) (None, 5, 5, 32)     6176        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_conv2 (Conv2D) (None, 12, 12, 32)   12832       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_pool_bn (BatchNorm (None, 5, 5, 32)     128         inception_3a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_1x1_conv (Conv2D)  (None, 12, 12, 64)   12352       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_bn2 (BatchNorm (None, 12, 12, 32)   128         inception_3a_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5, 5, 32)     0           inception_3a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 12, 12, 128)  0           inception_3a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 12, 12, 32)   0           inception_3a_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 12, 12, 32)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 12, 12, 64)   0           inception_3a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 zero_padding2d_7[0][0]           \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_conv1 (Conv2D) (None, 12, 12, 96)   24672       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_conv1 (Conv2D) (None, 12, 12, 32)   8224        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3b_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 12, 12, 96)   0           inception_3b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 12, 12, 32)   0           inception_3b_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 4, 4, 256)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 14, 14, 96)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 16, 16, 32)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_pool_conv (Conv2D) (None, 4, 4, 64)     16448       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_conv2 (Conv2D) (None, 12, 12, 64)   51264       zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_pool_bn (BatchNorm (None, 4, 4, 64)     256         inception_3b_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_1x1_conv (Conv2D)  (None, 12, 12, 64)   16448       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_bn2 (BatchNorm (None, 12, 12, 64)   256         inception_3b_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 64)     0           inception_3b_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 12, 12, 128)  0           inception_3b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 12, 12, 64)   0           inception_3b_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 12, 12, 64)   0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 12, 12, 64)   0           inception_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 12, 12, 320)  0           activation_11[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "                                                                 zero_padding2d_10[0][0]          \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_conv1 (Conv2D) (None, 12, 12, 128)  41088       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_conv1 (Conv2D) (None, 12, 12, 32)   10272       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_bn1 (BatchNorm (None, 12, 12, 128)  512         inception_3c_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3c_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 12, 12, 128)  0           inception_3c_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 12, 12, 32)   0           inception_3c_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 14, 14, 128)  0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 16, 16, 32)   0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_conv2 (Conv2D) (None, 6, 6, 256)    295168      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_bn2 (BatchNorm (None, 6, 6, 256)    1024        inception_3c_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_3c_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 320)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 6, 6, 256)    0           inception_3c_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 6, 6, 64)     0           inception_3c_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 6, 6, 320)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 6, 6, 640)    0           activation_17[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "                                                                 zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_conv1 (Conv2D) (None, 6, 6, 96)     61536       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_conv1 (Conv2D) (None, 6, 6, 32)     20512       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_bn1 (BatchNorm (None, 6, 6, 96)     384         inception_4a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_bn1 (BatchNorm (None, 6, 6, 32)     128         inception_4a_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 6, 6, 96)     0           inception_4a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 6, 6, 32)     0           inception_4a_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 2, 2, 640)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 8, 8, 96)     0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 10, 10, 32)   0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_pool_conv (Conv2D) (None, 2, 2, 128)    82048       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_conv2 (Conv2D) (None, 6, 6, 192)    166080      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_pool_bn (BatchNorm (None, 2, 2, 128)    512         inception_4a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_1x1_conv (Conv2D)  (None, 6, 6, 256)    164096      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_bn2 (BatchNorm (None, 6, 6, 192)    768         inception_4a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_4a_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 2, 128)    0           inception_4a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_1x1_bn (BatchNorma (None, 6, 6, 256)    1024        inception_4a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 6, 6, 192)    0           inception_4a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 6, 6, 64)     0           inception_4a_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 6, 6, 128)    0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 6, 6, 256)    0           inception_4a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 6, 6, 640)    0           activation_21[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "                                                                 zero_padding2d_16[0][0]          \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_conv1 (Conv2D) (None, 6, 6, 160)    102560      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_conv1 (Conv2D) (None, 6, 6, 64)     41024       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_bn1 (BatchNorm (None, 6, 6, 160)    640         inception_4b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_bn1 (BatchNorm (None, 6, 6, 64)     256         inception_4b_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 6, 6, 160)    0           inception_4b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 6, 6, 64)     0           inception_4b_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 8, 8, 160)    0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 10, 10, 64)   0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_conv2 (Conv2D) (None, 3, 3, 256)    368896      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_conv2 (Conv2D) (None, 3, 3, 128)    204928      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_3x3_bn2 (BatchNorm (None, 3, 3, 256)    1024        inception_4b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b_5x5_bn2 (BatchNorm (None, 3, 3, 128)    512         inception_4b_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 640)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 3, 3, 256)    0           inception_4b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 3, 3, 128)    0           inception_4b_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 3, 3, 640)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 1024)   0           activation_27[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_conv1 (Conv2D) (None, 3, 3, 96)     98400       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 3, 3, 96)     0           inception_5a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 1024)   0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 5, 5, 96)     0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_pool_conv (Conv2D) (None, 1, 1, 96)     98400       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_1x1_conv (Conv2D)  (None, 3, 3, 256)    262400      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 1, 1, 96)     0           inception_5a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 3, 3, 384)    0           inception_5a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 3, 3, 96)     0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 3, 3, 256)    0           inception_5a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 3, 3, 736)    0           activation_31[0][0]              \n",
      "                                                                 zero_padding2d_21[0][0]          \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_conv1 (Conv2D) (None, 3, 3, 96)     70752       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 3, 3, 96)     0           inception_5b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 736)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 5, 5, 96)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_pool_conv (Conv2D) (None, 1, 1, 96)     70752       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5b_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_1x1_conv (Conv2D)  (None, 3, 3, 256)    188672      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1, 1, 96)     0           inception_5b_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 3, 3, 384)    0           inception_5b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 3, 3, 96)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 3, 3, 256)    0           inception_5b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 3, 3, 736)    0           activation_35[0][0]              \n",
      "                                                                 zero_padding2d_23[0][0]          \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 736)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 736)          0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 128)          94336       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "norm_layer (Lambda)             (None, 128)          0           dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,743,280\n",
      "Trainable params: 3,733,968\n",
      "Non-trainable params: 9,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the base-cnn model\n",
    "base_model = basenet(output_shape=128)\n",
    "\n",
    "# # visualization\n",
    "# plot_model(base_model, show_shapes=True, to_file='./results/base-model.png')\n",
    "# plot_model(base_model, show_shapes=True, to_file='./results/base-model.pdf')\n",
    "\n",
    "# base-model summary\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 128)          3743280     anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Lambda)                 (None, 3, 128)       0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,743,280\n",
      "Trainable params: 3,733,968\n",
      "Non-trainable params: 9,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the triplet-network model\n",
    "triplet_model = triplet_net(base_model=base_model, input_shape=(96, 96, 3))\n",
    "\n",
    "# # visualization\n",
    "# plot_model(triplet_model, show_shapes=True, to_file='./results/triplet-model.png')\n",
    "# plot_model(triplet_model, show_shapes=True, to_file='./results/triplet-model.pdf')\n",
    "\n",
    "# base-model summary\n",
    "triplet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define learning scheduler\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\" Learning rate schedule \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 900:\n",
    "        lr *= 1e-1\n",
    "    elif epoch > 800:\n",
    "        lr *= 2e-1\n",
    "    elif epoch > 700:\n",
    "        lr *= 3e-1\n",
    "    elif epoch > 600:\n",
    "        lr *= 4e-1\n",
    "    elif epoch > 500:\n",
    "        lr *= 5e-1\n",
    "    elif epoch > 400:\n",
    "        lr *= 6e-1\n",
    "    elif epoch > 300:\n",
    "        lr *= 7e-1\n",
    "    elif epoch > 200:\n",
    "        lr *= 8e-1\n",
    "    elif epoch > 100:\n",
    "        lr *= 9e-1\n",
    "        \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoing Folder:\t ./models/margin-03-20180803-2300\n"
     ]
    }
   ],
   "source": [
    "# define optimizer\n",
    "opt = keras.optimizers.Adam(lr=lr_schedule(0))\n",
    "\n",
    "# create checkpoint folder\n",
    "path = './models/margin-03-' + time.strftime('%Y%m%d-%H%M')\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "print('Checkpoing Folder:\\t', path)    \n",
    "\n",
    "# create call backs\n",
    "checkpoint = ModelCheckpoint(filepath=path + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                             monitor='val_loss', verbose=0, save_best_only=False, \n",
    "                             save_weights_only=False, mode='auto', period=10)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# compile the model\n",
    "triplet_model.compile(optimizer=opt, loss=triplet_loss(0.3))\n",
    "\n",
    "# define training and test dataset image generator\n",
    "train_generator = train_triplet_generator(vgg2_train_df, batch_size=128)\n",
    "test_generator = test_triplet_generator(vgg2_test_df, batch_size=100, loops=10, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 122s - loss: 30.6457 - val_loss: 25.1297\n",
      "Epoch 2/1000\n",
      " - 103s - loss: 25.1003 - val_loss: 24.6764\n",
      "Epoch 3/1000\n",
      " - 103s - loss: 21.7025 - val_loss: 19.6537\n",
      "Epoch 4/1000\n",
      " - 102s - loss: 19.2078 - val_loss: 18.9591\n",
      "Epoch 5/1000\n",
      " - 102s - loss: 17.5455 - val_loss: 19.6766\n",
      "Epoch 6/1000\n",
      " - 101s - loss: 16.8191 - val_loss: 16.6270\n",
      "Epoch 7/1000\n",
      " - 100s - loss: 16.3869 - val_loss: 14.2820\n",
      "Epoch 8/1000\n",
      " - 101s - loss: 15.9597 - val_loss: 13.4394\n",
      "Epoch 9/1000\n",
      " - 100s - loss: 15.5696 - val_loss: 12.7228\n",
      "Epoch 10/1000\n",
      " - 99s - loss: 14.6158 - val_loss: 12.4634\n",
      "Epoch 11/1000\n",
      " - 99s - loss: 13.9540 - val_loss: 12.3264\n",
      "Epoch 12/1000\n",
      " - 97s - loss: 14.2147 - val_loss: 16.1694\n",
      "Epoch 13/1000\n",
      " - 99s - loss: 13.5905 - val_loss: 13.3892\n",
      "Epoch 14/1000\n",
      " - 98s - loss: 13.5956 - val_loss: 15.7988\n",
      "Epoch 15/1000\n",
      " - 99s - loss: 13.5916 - val_loss: 13.9660\n",
      "Epoch 16/1000\n",
      " - 98s - loss: 13.0864 - val_loss: 12.2670\n",
      "Epoch 17/1000\n",
      " - 98s - loss: 13.1190 - val_loss: 18.7369\n",
      "Epoch 18/1000\n",
      " - 98s - loss: 12.2959 - val_loss: 11.1549\n",
      "Epoch 19/1000\n",
      " - 98s - loss: 12.6612 - val_loss: 12.2382\n",
      "Epoch 20/1000\n",
      " - 99s - loss: 12.4168 - val_loss: 11.5091\n",
      "Epoch 21/1000\n",
      " - 98s - loss: 12.0242 - val_loss: 11.7270\n",
      "Epoch 22/1000\n",
      " - 98s - loss: 12.1632 - val_loss: 14.2591\n",
      "Epoch 23/1000\n",
      " - 97s - loss: 12.4976 - val_loss: 12.1077\n",
      "Epoch 24/1000\n",
      " - 97s - loss: 11.8537 - val_loss: 12.7558\n",
      "Epoch 25/1000\n",
      " - 98s - loss: 11.5640 - val_loss: 13.4203\n",
      "Epoch 26/1000\n",
      " - 97s - loss: 11.1251 - val_loss: 10.0445\n",
      "Epoch 27/1000\n",
      " - 97s - loss: 11.0603 - val_loss: 10.6149\n",
      "Epoch 28/1000\n",
      " - 97s - loss: 11.4032 - val_loss: 11.5314\n",
      "Epoch 29/1000\n",
      " - 97s - loss: 11.0974 - val_loss: 10.0336\n",
      "Epoch 30/1000\n",
      " - 98s - loss: 10.7667 - val_loss: 11.4569\n",
      "Epoch 31/1000\n",
      " - 97s - loss: 10.5327 - val_loss: 9.9938\n",
      "Epoch 32/1000\n",
      " - 97s - loss: 10.1774 - val_loss: 10.1663\n",
      "Epoch 33/1000\n",
      " - 97s - loss: 10.6922 - val_loss: 10.6397\n",
      "Epoch 34/1000\n",
      " - 97s - loss: 10.9420 - val_loss: 10.8378\n",
      "Epoch 35/1000\n",
      " - 98s - loss: 10.3274 - val_loss: 10.4738\n",
      "Epoch 36/1000\n",
      " - 97s - loss: 10.6565 - val_loss: 9.9940\n",
      "Epoch 37/1000\n",
      " - 97s - loss: 10.1558 - val_loss: 9.4339\n",
      "Epoch 38/1000\n",
      " - 97s - loss: 9.8003 - val_loss: 10.4029\n",
      "Epoch 39/1000\n",
      " - 97s - loss: 9.6994 - val_loss: 9.5534\n",
      "Epoch 40/1000\n",
      " - 97s - loss: 9.3612 - val_loss: 9.8736\n",
      "Epoch 41/1000\n",
      " - 96s - loss: 9.9566 - val_loss: 8.1427\n",
      "Epoch 42/1000\n",
      " - 97s - loss: 9.3263 - val_loss: 10.0649\n",
      "Epoch 43/1000\n",
      " - 97s - loss: 9.8267 - val_loss: 8.7267\n",
      "Epoch 44/1000\n",
      " - 98s - loss: 9.5793 - val_loss: 9.2787\n",
      "Epoch 45/1000\n",
      " - 97s - loss: 9.5748 - val_loss: 8.1644\n",
      "Epoch 46/1000\n",
      " - 97s - loss: 9.3839 - val_loss: 8.1780\n",
      "Epoch 47/1000\n",
      " - 97s - loss: 9.4864 - val_loss: 10.3273\n",
      "Epoch 48/1000\n",
      " - 97s - loss: 9.5753 - val_loss: 8.0735\n",
      "Epoch 49/1000\n",
      " - 97s - loss: 9.5130 - val_loss: 8.1973\n",
      "Epoch 50/1000\n",
      " - 97s - loss: 9.1692 - val_loss: 8.1814\n",
      "Epoch 51/1000\n",
      " - 97s - loss: 8.9506 - val_loss: 8.8179\n",
      "Epoch 52/1000\n",
      " - 97s - loss: 9.2718 - val_loss: 9.3877\n",
      "Epoch 53/1000\n",
      " - 97s - loss: 9.1162 - val_loss: 8.5674\n",
      "Epoch 54/1000\n",
      " - 97s - loss: 8.8856 - val_loss: 8.3267\n",
      "Epoch 55/1000\n",
      " - 97s - loss: 9.0233 - val_loss: 7.4365\n",
      "Epoch 56/1000\n",
      " - 97s - loss: 8.9392 - val_loss: 10.2299\n",
      "Epoch 57/1000\n",
      " - 97s - loss: 8.6524 - val_loss: 9.5896\n",
      "Epoch 58/1000\n",
      " - 97s - loss: 8.9836 - val_loss: 9.0699\n",
      "Epoch 59/1000\n",
      " - 97s - loss: 8.6115 - val_loss: 8.5959\n",
      "Epoch 60/1000\n",
      " - 97s - loss: 8.7667 - val_loss: 7.1711\n",
      "Epoch 61/1000\n",
      " - 97s - loss: 8.6400 - val_loss: 8.0844\n",
      "Epoch 62/1000\n",
      " - 97s - loss: 9.0915 - val_loss: 8.3117\n",
      "Epoch 63/1000\n",
      " - 97s - loss: 8.1448 - val_loss: 8.0872\n",
      "Epoch 64/1000\n",
      " - 96s - loss: 8.3072 - val_loss: 8.9222\n",
      "Epoch 65/1000\n",
      " - 97s - loss: 8.2975 - val_loss: 9.4587\n",
      "Epoch 66/1000\n",
      " - 97s - loss: 8.5098 - val_loss: 8.4050\n",
      "Epoch 67/1000\n",
      " - 97s - loss: 8.5274 - val_loss: 7.8411\n",
      "Epoch 68/1000\n",
      " - 97s - loss: 8.5762 - val_loss: 8.6901\n",
      "Epoch 69/1000\n",
      " - 97s - loss: 8.2581 - val_loss: 7.6369\n",
      "Epoch 70/1000\n",
      " - 97s - loss: 8.3160 - val_loss: 7.4268\n",
      "Epoch 71/1000\n",
      " - 97s - loss: 8.2317 - val_loss: 8.7305\n",
      "Epoch 72/1000\n",
      " - 97s - loss: 7.7715 - val_loss: 7.3883\n",
      "Epoch 73/1000\n",
      " - 97s - loss: 8.1401 - val_loss: 6.7879\n",
      "Epoch 74/1000\n",
      " - 97s - loss: 8.0105 - val_loss: 7.9907\n",
      "Epoch 75/1000\n",
      " - 96s - loss: 8.0700 - val_loss: 7.9100\n",
      "Epoch 76/1000\n",
      " - 97s - loss: 7.7399 - val_loss: 8.7383\n",
      "Epoch 77/1000\n",
      " - 96s - loss: 8.1868 - val_loss: 8.8022\n",
      "Epoch 78/1000\n",
      " - 97s - loss: 7.5772 - val_loss: 7.7326\n",
      "Epoch 79/1000\n",
      " - 97s - loss: 7.7421 - val_loss: 6.8840\n",
      "Epoch 80/1000\n",
      " - 98s - loss: 7.8486 - val_loss: 7.4842\n",
      "Epoch 81/1000\n",
      " - 97s - loss: 7.9557 - val_loss: 7.1856\n",
      "Epoch 82/1000\n",
      " - 97s - loss: 8.0649 - val_loss: 7.8458\n",
      "Epoch 83/1000\n",
      " - 97s - loss: 7.4317 - val_loss: 7.3382\n",
      "Epoch 84/1000\n",
      " - 97s - loss: 7.5309 - val_loss: 7.4105\n",
      "Epoch 85/1000\n",
      " - 97s - loss: 7.9631 - val_loss: 6.9300\n",
      "Epoch 86/1000\n",
      " - 97s - loss: 7.7144 - val_loss: 7.3324\n",
      "Epoch 87/1000\n",
      " - 97s - loss: 7.2509 - val_loss: 6.5248\n",
      "Epoch 88/1000\n",
      " - 97s - loss: 7.3667 - val_loss: 7.5439\n",
      "Epoch 89/1000\n",
      " - 97s - loss: 7.3828 - val_loss: 7.4412\n",
      "Epoch 90/1000\n",
      " - 97s - loss: 7.6061 - val_loss: 7.8445\n",
      "Epoch 91/1000\n",
      " - 98s - loss: 7.1553 - val_loss: 8.2708\n",
      "Epoch 92/1000\n",
      " - 96s - loss: 7.3988 - val_loss: 7.4937\n",
      "Epoch 93/1000\n",
      " - 97s - loss: 7.6264 - val_loss: 8.9165\n",
      "Epoch 94/1000\n",
      " - 97s - loss: 7.3747 - val_loss: 7.5448\n",
      "Epoch 95/1000\n",
      " - 97s - loss: 7.3436 - val_loss: 6.3283\n",
      "Epoch 96/1000\n",
      " - 97s - loss: 7.3967 - val_loss: 8.5519\n",
      "Epoch 97/1000\n",
      " - 97s - loss: 7.5834 - val_loss: 6.4560\n",
      "Epoch 98/1000\n",
      " - 97s - loss: 7.5018 - val_loss: 7.4451\n",
      "Epoch 99/1000\n",
      " - 97s - loss: 7.3272 - val_loss: 7.6686\n",
      "Epoch 100/1000\n",
      " - 97s - loss: 7.3731 - val_loss: 6.3617\n",
      "Epoch 101/1000\n",
      " - 97s - loss: 7.5901 - val_loss: 6.6971\n",
      "Epoch 102/1000\n",
      " - 97s - loss: 7.0648 - val_loss: 7.4863\n",
      "Epoch 103/1000\n",
      " - 97s - loss: 7.1685 - val_loss: 7.2722\n",
      "Epoch 104/1000\n",
      " - 97s - loss: 7.1872 - val_loss: 9.3558\n",
      "Epoch 105/1000\n",
      " - 97s - loss: 6.8188 - val_loss: 6.6997\n",
      "Epoch 106/1000\n",
      " - 98s - loss: 7.1622 - val_loss: 6.8821\n",
      "Epoch 107/1000\n",
      " - 97s - loss: 6.9294 - val_loss: 6.6457\n",
      "Epoch 108/1000\n",
      " - 97s - loss: 7.4106 - val_loss: 7.3854\n",
      "Epoch 109/1000\n",
      " - 97s - loss: 6.7862 - val_loss: 6.6702\n",
      "Epoch 110/1000\n",
      " - 98s - loss: 6.4907 - val_loss: 6.4964\n",
      "Epoch 111/1000\n",
      " - 97s - loss: 6.9810 - val_loss: 6.8521\n",
      "Epoch 112/1000\n",
      " - 97s - loss: 6.5716 - val_loss: 5.9483\n",
      "Epoch 113/1000\n",
      " - 97s - loss: 6.9652 - val_loss: 7.0534\n",
      "Epoch 114/1000\n",
      " - 97s - loss: 6.7364 - val_loss: 5.9050\n",
      "Epoch 115/1000\n",
      " - 98s - loss: 6.6168 - val_loss: 7.1848\n",
      "Epoch 116/1000\n",
      " - 97s - loss: 6.8441 - val_loss: 6.6982\n",
      "Epoch 117/1000\n",
      " - 97s - loss: 6.8528 - val_loss: 6.8196\n",
      "Epoch 118/1000\n",
      " - 97s - loss: 6.5619 - val_loss: 6.2151\n",
      "Epoch 119/1000\n",
      " - 97s - loss: 6.9968 - val_loss: 6.0659\n",
      "Epoch 120/1000\n",
      " - 97s - loss: 6.5520 - val_loss: 5.9461\n",
      "Epoch 121/1000\n",
      " - 97s - loss: 6.6266 - val_loss: 6.0820\n",
      "Epoch 122/1000\n",
      " - 97s - loss: 7.0368 - val_loss: 6.9637\n",
      "Epoch 123/1000\n",
      " - 97s - loss: 6.6906 - val_loss: 6.1563\n",
      "Epoch 124/1000\n",
      " - 97s - loss: 6.6206 - val_loss: 6.6403\n",
      "Epoch 125/1000\n",
      " - 97s - loss: 6.6795 - val_loss: 5.5442\n",
      "Epoch 126/1000\n",
      " - 98s - loss: 6.7501 - val_loss: 5.5567\n",
      "Epoch 127/1000\n",
      " - 97s - loss: 6.7854 - val_loss: 6.5170\n",
      "Epoch 128/1000\n",
      " - 98s - loss: 6.0751 - val_loss: 6.0620\n",
      "Epoch 129/1000\n",
      " - 97s - loss: 6.8255 - val_loss: 6.6323\n",
      "Epoch 130/1000\n",
      " - 96s - loss: 6.2928 - val_loss: 6.1690\n",
      "Epoch 131/1000\n",
      " - 98s - loss: 6.7688 - val_loss: 5.8719\n",
      "Epoch 132/1000\n",
      " - 97s - loss: 6.5896 - val_loss: 5.9825\n",
      "Epoch 133/1000\n",
      " - 98s - loss: 6.5331 - val_loss: 5.8487\n",
      "Epoch 134/1000\n",
      " - 97s - loss: 6.3255 - val_loss: 6.2487\n",
      "Epoch 135/1000\n",
      " - 97s - loss: 6.2892 - val_loss: 6.3151\n",
      "Epoch 136/1000\n",
      " - 97s - loss: 6.1828 - val_loss: 7.1731\n",
      "Epoch 137/1000\n",
      " - 97s - loss: 6.3625 - val_loss: 6.5400\n",
      "Epoch 138/1000\n",
      " - 97s - loss: 6.6533 - val_loss: 5.9727\n",
      "Epoch 139/1000\n",
      " - 96s - loss: 6.4127 - val_loss: 6.2153\n",
      "Epoch 140/1000\n",
      " - 97s - loss: 6.5811 - val_loss: 6.2878\n",
      "Epoch 141/1000\n",
      " - 97s - loss: 5.9997 - val_loss: 6.1953\n",
      "Epoch 142/1000\n",
      " - 97s - loss: 6.2643 - val_loss: 5.9399\n",
      "Epoch 143/1000\n",
      " - 97s - loss: 6.3774 - val_loss: 6.4663\n",
      "Epoch 144/1000\n",
      " - 97s - loss: 5.8797 - val_loss: 6.7319\n",
      "Epoch 145/1000\n",
      " - 98s - loss: 6.0147 - val_loss: 5.9430\n",
      "Epoch 146/1000\n",
      " - 97s - loss: 5.8979 - val_loss: 7.2769\n",
      "Epoch 147/1000\n",
      " - 97s - loss: 6.1578 - val_loss: 6.1275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000\n",
      " - 97s - loss: 6.1202 - val_loss: 5.8253\n",
      "Epoch 149/1000\n",
      " - 97s - loss: 6.4117 - val_loss: 6.5228\n",
      "Epoch 150/1000\n",
      " - 97s - loss: 6.0763 - val_loss: 5.5635\n",
      "Epoch 151/1000\n",
      " - 97s - loss: 6.0372 - val_loss: 6.1399\n",
      "Epoch 152/1000\n",
      " - 97s - loss: 6.2094 - val_loss: 5.5881\n",
      "Epoch 153/1000\n",
      " - 97s - loss: 6.2235 - val_loss: 6.2271\n",
      "Epoch 154/1000\n",
      " - 97s - loss: 6.1805 - val_loss: 5.7250\n",
      "Epoch 155/1000\n",
      " - 97s - loss: 5.8282 - val_loss: 5.7999\n",
      "Epoch 156/1000\n",
      " - 97s - loss: 6.3759 - val_loss: 5.9101\n",
      "Epoch 157/1000\n",
      " - 97s - loss: 6.3251 - val_loss: 5.7086\n",
      "Epoch 158/1000\n",
      " - 98s - loss: 6.2153 - val_loss: 5.9464\n",
      "Epoch 159/1000\n",
      " - 97s - loss: 6.0356 - val_loss: 5.2483\n",
      "Epoch 160/1000\n",
      " - 97s - loss: 5.9372 - val_loss: 6.8701\n",
      "Epoch 161/1000\n",
      " - 97s - loss: 5.8611 - val_loss: 5.6653\n",
      "Epoch 162/1000\n",
      " - 97s - loss: 6.0937 - val_loss: 7.5819\n",
      "Epoch 163/1000\n",
      " - 97s - loss: 5.7425 - val_loss: 5.8776\n",
      "Epoch 164/1000\n",
      " - 97s - loss: 5.9241 - val_loss: 5.6964\n",
      "Epoch 165/1000\n",
      " - 97s - loss: 6.1830 - val_loss: 6.0690\n",
      "Epoch 166/1000\n",
      " - 97s - loss: 5.8006 - val_loss: 5.4762\n",
      "Epoch 167/1000\n",
      " - 97s - loss: 5.7743 - val_loss: 5.7563\n",
      "Epoch 168/1000\n",
      " - 97s - loss: 5.7420 - val_loss: 5.1598\n",
      "Epoch 169/1000\n",
      " - 97s - loss: 6.2989 - val_loss: 5.7716\n",
      "Epoch 170/1000\n",
      " - 97s - loss: 5.7848 - val_loss: 6.4975\n",
      "Epoch 171/1000\n",
      " - 97s - loss: 5.9149 - val_loss: 5.5041\n",
      "Epoch 172/1000\n",
      " - 97s - loss: 6.0715 - val_loss: 5.8369\n",
      "Epoch 173/1000\n",
      " - 97s - loss: 6.0364 - val_loss: 6.2924\n",
      "Epoch 174/1000\n",
      " - 97s - loss: 5.8104 - val_loss: 6.0019\n",
      "Epoch 175/1000\n",
      " - 98s - loss: 6.0620 - val_loss: 5.1513\n",
      "Epoch 176/1000\n",
      " - 97s - loss: 5.7816 - val_loss: 6.5061\n",
      "Epoch 177/1000\n",
      " - 97s - loss: 5.6903 - val_loss: 6.5560\n",
      "Epoch 178/1000\n",
      " - 96s - loss: 5.5798 - val_loss: 5.8589\n",
      "Epoch 179/1000\n",
      " - 96s - loss: 5.7399 - val_loss: 5.8458\n",
      "Epoch 180/1000\n",
      " - 97s - loss: 5.8900 - val_loss: 5.4441\n",
      "Epoch 181/1000\n",
      " - 97s - loss: 5.6310 - val_loss: 5.7606\n",
      "Epoch 182/1000\n",
      " - 97s - loss: 5.6132 - val_loss: 5.8261\n",
      "Epoch 183/1000\n",
      " - 97s - loss: 5.9060 - val_loss: 5.6220\n",
      "Epoch 184/1000\n",
      " - 97s - loss: 5.8434 - val_loss: 4.8734\n",
      "Epoch 185/1000\n",
      " - 97s - loss: 6.0688 - val_loss: 5.5796\n",
      "Epoch 186/1000\n",
      " - 98s - loss: 5.2476 - val_loss: 5.6219\n",
      "Epoch 187/1000\n",
      " - 97s - loss: 5.0169 - val_loss: 5.3230\n",
      "Epoch 188/1000\n",
      " - 97s - loss: 5.6034 - val_loss: 6.0001\n",
      "Epoch 189/1000\n",
      " - 97s - loss: 5.5122 - val_loss: 7.2076\n",
      "Epoch 190/1000\n",
      " - 97s - loss: 5.7104 - val_loss: 5.0744\n",
      "Epoch 191/1000\n",
      " - 97s - loss: 5.6696 - val_loss: 4.8735\n",
      "Epoch 192/1000\n",
      " - 97s - loss: 5.7014 - val_loss: 6.0510\n",
      "Epoch 193/1000\n",
      " - 97s - loss: 5.7081 - val_loss: 5.8294\n",
      "Epoch 194/1000\n",
      " - 97s - loss: 5.6580 - val_loss: 5.7987\n",
      "Epoch 195/1000\n",
      " - 97s - loss: 5.4301 - val_loss: 5.1408\n",
      "Epoch 196/1000\n",
      " - 97s - loss: 5.7234 - val_loss: 5.9684\n",
      "Epoch 197/1000\n",
      " - 97s - loss: 5.6154 - val_loss: 6.0477\n",
      "Epoch 198/1000\n",
      " - 97s - loss: 5.8815 - val_loss: 5.3059\n",
      "Epoch 199/1000\n",
      " - 96s - loss: 5.4188 - val_loss: 5.8416\n",
      "Epoch 200/1000\n",
      " - 97s - loss: 5.5179 - val_loss: 5.1245\n",
      "Epoch 201/1000\n",
      " - 97s - loss: 5.5332 - val_loss: 5.5978\n",
      "Epoch 202/1000\n",
      " - 96s - loss: 5.3620 - val_loss: 5.1717\n",
      "Epoch 203/1000\n",
      " - 97s - loss: 5.1427 - val_loss: 4.7475\n",
      "Epoch 204/1000\n",
      " - 97s - loss: 5.5742 - val_loss: 5.6674\n",
      "Epoch 205/1000\n",
      " - 96s - loss: 5.3444 - val_loss: 4.8334\n",
      "Epoch 206/1000\n",
      " - 96s - loss: 5.6087 - val_loss: 4.9701\n",
      "Epoch 207/1000\n",
      " - 97s - loss: 5.3073 - val_loss: 5.5811\n",
      "Epoch 208/1000\n",
      " - 97s - loss: 5.9394 - val_loss: 5.2819\n",
      "Epoch 209/1000\n",
      " - 97s - loss: 5.5365 - val_loss: 4.5880\n",
      "Epoch 210/1000\n",
      " - 97s - loss: 5.5224 - val_loss: 5.4238\n",
      "Epoch 211/1000\n",
      " - 97s - loss: 5.5384 - val_loss: 5.1837\n",
      "Epoch 212/1000\n",
      " - 97s - loss: 5.5059 - val_loss: 5.1381\n",
      "Epoch 213/1000\n",
      " - 97s - loss: 5.4429 - val_loss: 5.5466\n",
      "Epoch 214/1000\n",
      " - 97s - loss: 5.3311 - val_loss: 4.5690\n",
      "Epoch 215/1000\n",
      " - 98s - loss: 4.8953 - val_loss: 4.6765\n",
      "Epoch 216/1000\n",
      " - 97s - loss: 5.1604 - val_loss: 5.3229\n",
      "Epoch 217/1000\n",
      " - 97s - loss: 5.8858 - val_loss: 5.0777\n",
      "Epoch 218/1000\n",
      " - 97s - loss: 5.2338 - val_loss: 5.4989\n",
      "Epoch 219/1000\n",
      " - 97s - loss: 5.2737 - val_loss: 5.6331\n",
      "Epoch 220/1000\n",
      " - 97s - loss: 4.9106 - val_loss: 5.4279\n",
      "Epoch 221/1000\n",
      " - 97s - loss: 5.0038 - val_loss: 4.7441\n",
      "Epoch 222/1000\n",
      " - 97s - loss: 5.2033 - val_loss: 5.2754\n",
      "Epoch 223/1000\n",
      " - 97s - loss: 5.4414 - val_loss: 5.1165\n",
      "Epoch 224/1000\n",
      " - 97s - loss: 5.3883 - val_loss: 5.0643\n",
      "Epoch 225/1000\n",
      " - 97s - loss: 5.3835 - val_loss: 5.6757\n",
      "Epoch 226/1000\n",
      " - 98s - loss: 5.2601 - val_loss: 5.2114\n",
      "Epoch 227/1000\n",
      " - 97s - loss: 5.8040 - val_loss: 5.2381\n",
      "Epoch 228/1000\n",
      " - 98s - loss: 5.3588 - val_loss: 5.1971\n",
      "Epoch 229/1000\n",
      " - 97s - loss: 5.3545 - val_loss: 5.3890\n",
      "Epoch 230/1000\n",
      " - 97s - loss: 5.2298 - val_loss: 6.0018\n",
      "Epoch 231/1000\n",
      " - 97s - loss: 4.9454 - val_loss: 4.2004\n",
      "Epoch 232/1000\n",
      " - 97s - loss: 4.7429 - val_loss: 5.0360\n",
      "Epoch 233/1000\n",
      " - 97s - loss: 4.9353 - val_loss: 4.9796\n",
      "Epoch 234/1000\n",
      " - 98s - loss: 5.3905 - val_loss: 5.3579\n",
      "Epoch 235/1000\n",
      " - 97s - loss: 5.5906 - val_loss: 4.9947\n",
      "Epoch 236/1000\n",
      " - 97s - loss: 5.3115 - val_loss: 4.5571\n",
      "Epoch 237/1000\n",
      " - 98s - loss: 5.3931 - val_loss: 5.1900\n",
      "Epoch 238/1000\n",
      " - 97s - loss: 5.2174 - val_loss: 4.6746\n",
      "Epoch 239/1000\n",
      " - 98s - loss: 5.2472 - val_loss: 5.8409\n",
      "Epoch 240/1000\n",
      " - 97s - loss: 5.0901 - val_loss: 4.9200\n",
      "Epoch 241/1000\n",
      " - 98s - loss: 5.0698 - val_loss: 4.7981\n",
      "Epoch 242/1000\n",
      " - 97s - loss: 4.9925 - val_loss: 4.5608\n",
      "Epoch 243/1000\n",
      " - 98s - loss: 4.8043 - val_loss: 5.5290\n",
      "Epoch 244/1000\n",
      " - 97s - loss: 4.4932 - val_loss: 5.0175\n",
      "Epoch 245/1000\n",
      " - 97s - loss: 5.0389 - val_loss: 4.9671\n",
      "Epoch 246/1000\n",
      " - 98s - loss: 5.3488 - val_loss: 4.7529\n",
      "Epoch 247/1000\n",
      " - 97s - loss: 5.4597 - val_loss: 4.9173\n",
      "Epoch 248/1000\n",
      " - 98s - loss: 5.2591 - val_loss: 5.5003\n",
      "Epoch 249/1000\n",
      " - 97s - loss: 5.0970 - val_loss: 5.2433\n",
      "Epoch 250/1000\n",
      " - 98s - loss: 5.3002 - val_loss: 5.3481\n",
      "Epoch 251/1000\n",
      " - 98s - loss: 4.9021 - val_loss: 4.9701\n",
      "Epoch 252/1000\n",
      " - 98s - loss: 5.0392 - val_loss: 5.5776\n",
      "Epoch 253/1000\n",
      " - 97s - loss: 5.1282 - val_loss: 4.3534\n",
      "Epoch 254/1000\n",
      " - 98s - loss: 5.2510 - val_loss: 5.6631\n",
      "Epoch 255/1000\n",
      " - 97s - loss: 5.0100 - val_loss: 5.1907\n",
      "Epoch 256/1000\n",
      " - 98s - loss: 4.9355 - val_loss: 4.8006\n",
      "Epoch 257/1000\n",
      " - 97s - loss: 5.0844 - val_loss: 4.7942\n",
      "Epoch 258/1000\n",
      " - 97s - loss: 5.0892 - val_loss: 4.4023\n",
      "Epoch 259/1000\n",
      " - 97s - loss: 5.1044 - val_loss: 5.1869\n",
      "Epoch 260/1000\n",
      " - 97s - loss: 5.0882 - val_loss: 5.4597\n",
      "Epoch 261/1000\n",
      " - 97s - loss: 4.9711 - val_loss: 5.0151\n",
      "Epoch 262/1000\n",
      " - 97s - loss: 4.8933 - val_loss: 5.1320\n",
      "Epoch 263/1000\n",
      " - 97s - loss: 4.6686 - val_loss: 4.4408\n",
      "Epoch 264/1000\n",
      " - 97s - loss: 4.9811 - val_loss: 4.8756\n",
      "Epoch 265/1000\n",
      " - 97s - loss: 5.1519 - val_loss: 4.5090\n",
      "Epoch 266/1000\n",
      " - 97s - loss: 4.7824 - val_loss: 5.2962\n",
      "Epoch 267/1000\n",
      " - 97s - loss: 5.3806 - val_loss: 4.8400\n",
      "Epoch 268/1000\n",
      " - 97s - loss: 4.6882 - val_loss: 4.5276\n",
      "Epoch 269/1000\n",
      " - 97s - loss: 5.0302 - val_loss: 4.6846\n",
      "Epoch 270/1000\n",
      " - 97s - loss: 4.8598 - val_loss: 4.5751\n",
      "Epoch 271/1000\n",
      " - 97s - loss: 5.0769 - val_loss: 4.4388\n",
      "Epoch 272/1000\n",
      " - 97s - loss: 4.9726 - val_loss: 4.6560\n",
      "Epoch 273/1000\n",
      " - 97s - loss: 4.8684 - val_loss: 5.5737\n",
      "Epoch 274/1000\n",
      " - 97s - loss: 4.8189 - val_loss: 4.9981\n",
      "Epoch 275/1000\n",
      " - 97s - loss: 4.8084 - val_loss: 5.5322\n",
      "Epoch 276/1000\n",
      " - 98s - loss: 4.9319 - val_loss: 4.4685\n",
      "Epoch 277/1000\n",
      " - 97s - loss: 4.9027 - val_loss: 4.7850\n",
      "Epoch 278/1000\n",
      " - 98s - loss: 4.8785 - val_loss: 5.2762\n",
      "Epoch 279/1000\n",
      " - 97s - loss: 4.6572 - val_loss: 4.0330\n",
      "Epoch 280/1000\n",
      " - 98s - loss: 4.9287 - val_loss: 5.2186\n",
      "Epoch 281/1000\n",
      " - 97s - loss: 4.9545 - val_loss: 4.2929\n",
      "Epoch 282/1000\n",
      " - 96s - loss: 4.6954 - val_loss: 5.0128\n",
      "Epoch 283/1000\n",
      " - 97s - loss: 4.8589 - val_loss: 4.4273\n",
      "Epoch 284/1000\n",
      " - 97s - loss: 4.7657 - val_loss: 4.7808\n",
      "Epoch 285/1000\n",
      " - 98s - loss: 4.6161 - val_loss: 5.5287\n",
      "Epoch 286/1000\n",
      " - 97s - loss: 4.9085 - val_loss: 5.0438\n",
      "Epoch 287/1000\n",
      " - 97s - loss: 4.6299 - val_loss: 5.0045\n",
      "Epoch 288/1000\n",
      " - 97s - loss: 5.3124 - val_loss: 4.5894\n",
      "Epoch 289/1000\n",
      " - 97s - loss: 4.7681 - val_loss: 4.1870\n",
      "Epoch 290/1000\n",
      " - 97s - loss: 4.8641 - val_loss: 4.3980\n",
      "Epoch 291/1000\n",
      " - 97s - loss: 5.1156 - val_loss: 4.8316\n",
      "Epoch 292/1000\n",
      " - 97s - loss: 4.6451 - val_loss: 5.1457\n",
      "Epoch 293/1000\n",
      " - 97s - loss: 4.6310 - val_loss: 5.3789\n",
      "Epoch 294/1000\n",
      " - 98s - loss: 4.9011 - val_loss: 5.2198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/1000\n",
      " - 98s - loss: 4.7713 - val_loss: 4.5265\n",
      "Epoch 296/1000\n",
      " - 97s - loss: 4.8245 - val_loss: 5.4290\n",
      "Epoch 297/1000\n",
      " - 97s - loss: 4.6915 - val_loss: 4.7643\n",
      "Epoch 298/1000\n",
      " - 98s - loss: 4.9619 - val_loss: 5.5007\n",
      "Epoch 299/1000\n",
      " - 97s - loss: 4.6575 - val_loss: 4.3696\n",
      "Epoch 300/1000\n",
      " - 98s - loss: 4.7811 - val_loss: 4.5335\n",
      "Epoch 301/1000\n",
      " - 97s - loss: 4.9579 - val_loss: 4.9088\n",
      "Epoch 302/1000\n",
      " - 98s - loss: 5.0166 - val_loss: 4.3562\n",
      "Epoch 303/1000\n",
      " - 96s - loss: 4.5407 - val_loss: 3.9590\n",
      "Epoch 304/1000\n",
      " - 98s - loss: 4.2818 - val_loss: 4.4662\n",
      "Epoch 305/1000\n",
      " - 97s - loss: 4.5087 - val_loss: 4.6805\n",
      "Epoch 306/1000\n",
      " - 97s - loss: 4.6942 - val_loss: 4.6947\n",
      "Epoch 307/1000\n",
      " - 97s - loss: 4.5964 - val_loss: 4.3089\n",
      "Epoch 308/1000\n",
      " - 98s - loss: 4.5832 - val_loss: 4.8190\n",
      "Epoch 309/1000\n",
      " - 98s - loss: 5.0521 - val_loss: 4.9623\n",
      "Epoch 310/1000\n",
      " - 97s - loss: 4.4894 - val_loss: 4.4791\n",
      "Epoch 311/1000\n",
      " - 97s - loss: 4.5576 - val_loss: 4.7638\n",
      "Epoch 312/1000\n",
      " - 97s - loss: 4.8272 - val_loss: 4.2890\n",
      "Epoch 313/1000\n",
      " - 97s - loss: 4.5598 - val_loss: 4.4486\n",
      "Epoch 314/1000\n",
      " - 97s - loss: 4.8729 - val_loss: 3.8776\n",
      "Epoch 315/1000\n",
      " - 98s - loss: 4.3941 - val_loss: 4.7014\n",
      "Epoch 316/1000\n",
      " - 97s - loss: 4.8972 - val_loss: 4.6080\n",
      "Epoch 317/1000\n",
      " - 97s - loss: 4.5867 - val_loss: 4.3002\n",
      "Epoch 318/1000\n",
      " - 97s - loss: 4.6064 - val_loss: 4.4001\n",
      "Epoch 319/1000\n",
      " - 97s - loss: 4.5626 - val_loss: 4.1168\n",
      "Epoch 320/1000\n",
      " - 97s - loss: 4.5407 - val_loss: 4.1728\n",
      "Epoch 321/1000\n",
      " - 96s - loss: 4.6107 - val_loss: 4.0630\n",
      "Epoch 322/1000\n",
      " - 97s - loss: 4.1192 - val_loss: 4.5384\n",
      "Epoch 323/1000\n",
      " - 97s - loss: 4.4927 - val_loss: 4.2363\n",
      "Epoch 324/1000\n",
      " - 97s - loss: 4.4658 - val_loss: 4.0318\n",
      "Epoch 325/1000\n",
      " - 97s - loss: 4.6079 - val_loss: 4.3978\n",
      "Epoch 326/1000\n",
      " - 97s - loss: 4.7564 - val_loss: 4.4524\n",
      "Epoch 327/1000\n",
      " - 97s - loss: 4.9022 - val_loss: 4.1891\n",
      "Epoch 328/1000\n",
      " - 97s - loss: 4.4820 - val_loss: 5.1893\n",
      "Epoch 329/1000\n",
      " - 97s - loss: 4.4253 - val_loss: 4.7359\n",
      "Epoch 330/1000\n",
      " - 98s - loss: 4.5155 - val_loss: 4.2431\n",
      "Epoch 331/1000\n",
      " - 98s - loss: 4.5841 - val_loss: 4.3511\n",
      "Epoch 332/1000\n",
      " - 97s - loss: 4.3830 - val_loss: 4.7263\n",
      "Epoch 333/1000\n",
      " - 97s - loss: 4.5819 - val_loss: 4.7344\n",
      "Epoch 334/1000\n",
      " - 97s - loss: 4.3237 - val_loss: 4.5620\n",
      "Epoch 335/1000\n",
      " - 97s - loss: 4.3268 - val_loss: 4.0471\n",
      "Epoch 336/1000\n",
      " - 97s - loss: 4.2874 - val_loss: 4.4713\n",
      "Epoch 337/1000\n",
      " - 97s - loss: 4.4853 - val_loss: 4.2277\n",
      "Epoch 338/1000\n",
      " - 97s - loss: 4.4503 - val_loss: 3.7915\n",
      "Epoch 339/1000\n",
      " - 97s - loss: 4.4242 - val_loss: 4.5535\n",
      "Epoch 340/1000\n",
      " - 97s - loss: 4.8626 - val_loss: 4.8644\n",
      "Epoch 341/1000\n",
      " - 97s - loss: 4.3413 - val_loss: 5.9184\n",
      "Epoch 342/1000\n",
      " - 97s - loss: 4.4034 - val_loss: 5.8195\n",
      "Epoch 343/1000\n",
      " - 97s - loss: 4.5280 - val_loss: 4.4639\n",
      "Epoch 344/1000\n",
      " - 97s - loss: 4.5063 - val_loss: 4.3186\n",
      "Epoch 345/1000\n",
      " - 96s - loss: 4.5583 - val_loss: 4.2219\n",
      "Epoch 346/1000\n",
      " - 97s - loss: 4.5064 - val_loss: 5.0007\n",
      "Epoch 347/1000\n",
      " - 97s - loss: 4.2516 - val_loss: 4.5402\n",
      "Epoch 348/1000\n",
      " - 97s - loss: 4.4125 - val_loss: 3.6737\n",
      "Epoch 349/1000\n",
      " - 97s - loss: 4.5399 - val_loss: 4.1537\n",
      "Epoch 350/1000\n",
      " - 97s - loss: 4.7844 - val_loss: 4.0208\n",
      "Epoch 351/1000\n",
      " - 97s - loss: 4.3759 - val_loss: 4.2924\n",
      "Epoch 352/1000\n",
      " - 97s - loss: 4.3261 - val_loss: 4.0981\n",
      "Epoch 353/1000\n",
      " - 97s - loss: 4.4886 - val_loss: 4.9474\n",
      "Epoch 354/1000\n",
      " - 97s - loss: 4.3621 - val_loss: 4.8075\n",
      "Epoch 355/1000\n",
      " - 97s - loss: 4.6041 - val_loss: 4.1588\n",
      "Epoch 356/1000\n",
      " - 96s - loss: 4.5179 - val_loss: 4.7159\n",
      "Epoch 357/1000\n",
      " - 97s - loss: 4.3272 - val_loss: 4.2287\n",
      "Epoch 358/1000\n",
      " - 97s - loss: 4.0800 - val_loss: 4.1429\n",
      "Epoch 359/1000\n",
      " - 97s - loss: 4.1454 - val_loss: 3.8312\n",
      "Epoch 360/1000\n",
      " - 97s - loss: 4.1433 - val_loss: 4.4119\n",
      "Epoch 361/1000\n",
      " - 97s - loss: 4.3238 - val_loss: 4.1930\n",
      "Epoch 362/1000\n",
      " - 97s - loss: 4.1611 - val_loss: 3.7016\n",
      "Epoch 363/1000\n",
      " - 97s - loss: 4.4166 - val_loss: 4.4139\n",
      "Epoch 364/1000\n",
      " - 97s - loss: 4.3745 - val_loss: 4.2704\n",
      "Epoch 365/1000\n",
      " - 97s - loss: 4.7074 - val_loss: 4.7963\n",
      "Epoch 366/1000\n",
      " - 97s - loss: 4.0350 - val_loss: 4.5662\n",
      "Epoch 367/1000\n",
      " - 97s - loss: 4.3354 - val_loss: 4.5389\n",
      "Epoch 368/1000\n",
      " - 98s - loss: 4.3642 - val_loss: 4.2629\n",
      "Epoch 369/1000\n",
      " - 97s - loss: 4.2690 - val_loss: 4.0656\n",
      "Epoch 370/1000\n",
      " - 97s - loss: 4.3622 - val_loss: 4.3039\n",
      "Epoch 371/1000\n",
      " - 97s - loss: 4.5626 - val_loss: 5.3552\n",
      "Epoch 372/1000\n",
      " - 97s - loss: 4.3542 - val_loss: 4.3071\n",
      "Epoch 373/1000\n",
      " - 97s - loss: 4.5606 - val_loss: 4.3103\n",
      "Epoch 374/1000\n",
      " - 97s - loss: 4.1566 - val_loss: 4.1092\n",
      "Epoch 375/1000\n",
      " - 96s - loss: 4.4395 - val_loss: 4.2726\n",
      "Epoch 376/1000\n",
      " - 97s - loss: 4.4130 - val_loss: 4.4619\n",
      "Epoch 377/1000\n",
      " - 97s - loss: 4.4598 - val_loss: 4.5599\n",
      "Epoch 378/1000\n",
      " - 97s - loss: 4.3500 - val_loss: 4.2873\n",
      "Epoch 379/1000\n",
      " - 97s - loss: 4.2542 - val_loss: 4.3384\n",
      "Epoch 380/1000\n",
      " - 98s - loss: 4.4192 - val_loss: 4.4694\n",
      "Epoch 381/1000\n",
      " - 97s - loss: 4.1045 - val_loss: 4.7632\n",
      "Epoch 382/1000\n",
      " - 97s - loss: 4.4844 - val_loss: 4.1706\n",
      "Epoch 383/1000\n",
      " - 97s - loss: 4.2325 - val_loss: 4.0090\n",
      "Epoch 384/1000\n",
      " - 97s - loss: 4.2682 - val_loss: 4.8285\n",
      "Epoch 385/1000\n",
      " - 97s - loss: 4.5194 - val_loss: 4.7924\n",
      "Epoch 386/1000\n",
      " - 97s - loss: 4.1473 - val_loss: 3.6355\n",
      "Epoch 387/1000\n",
      " - 97s - loss: 4.4091 - val_loss: 3.9419\n",
      "Epoch 388/1000\n",
      " - 97s - loss: 4.2783 - val_loss: 4.7877\n",
      "Epoch 389/1000\n",
      " - 97s - loss: 3.9341 - val_loss: 4.4860\n",
      "Epoch 390/1000\n",
      " - 97s - loss: 3.8420 - val_loss: 3.9846\n",
      "Epoch 391/1000\n",
      " - 97s - loss: 4.3244 - val_loss: 3.6033\n",
      "Epoch 392/1000\n",
      " - 97s - loss: 4.5098 - val_loss: 3.9987\n",
      "Epoch 393/1000\n",
      " - 97s - loss: 4.4243 - val_loss: 4.0434\n",
      "Epoch 394/1000\n",
      " - 97s - loss: 4.2851 - val_loss: 4.3355\n",
      "Epoch 395/1000\n",
      " - 98s - loss: 4.3512 - val_loss: 3.6967\n",
      "Epoch 396/1000\n",
      " - 97s - loss: 4.2861 - val_loss: 4.2388\n",
      "Epoch 397/1000\n",
      " - 97s - loss: 4.1378 - val_loss: 4.1187\n",
      "Epoch 398/1000\n",
      " - 97s - loss: 4.3662 - val_loss: 4.5550\n",
      "Epoch 399/1000\n",
      " - 97s - loss: 3.9968 - val_loss: 5.2229\n",
      "Epoch 400/1000\n",
      " - 97s - loss: 4.3729 - val_loss: 4.0934\n",
      "Epoch 401/1000\n",
      " - 97s - loss: 4.3492 - val_loss: 3.8130\n",
      "Epoch 402/1000\n",
      " - 97s - loss: 4.6560 - val_loss: 4.0608\n",
      "Epoch 403/1000\n",
      " - 98s - loss: 4.2580 - val_loss: 4.6117\n",
      "Epoch 404/1000\n",
      " - 97s - loss: 4.2055 - val_loss: 4.1428\n",
      "Epoch 405/1000\n",
      " - 97s - loss: 3.9392 - val_loss: 3.9537\n",
      "Epoch 406/1000\n",
      " - 97s - loss: 3.9369 - val_loss: 4.4343\n",
      "Epoch 407/1000\n",
      " - 98s - loss: 3.9474 - val_loss: 4.0092\n",
      "Epoch 408/1000\n",
      " - 96s - loss: 4.4590 - val_loss: 3.5873\n",
      "Epoch 409/1000\n",
      " - 97s - loss: 4.0477 - val_loss: 3.5990\n",
      "Epoch 410/1000\n",
      " - 97s - loss: 4.4010 - val_loss: 3.9568\n",
      "Epoch 411/1000\n",
      " - 97s - loss: 3.7106 - val_loss: 3.8211\n",
      "Epoch 412/1000\n",
      " - 97s - loss: 3.6754 - val_loss: 4.3693\n",
      "Epoch 413/1000\n",
      " - 97s - loss: 3.8331 - val_loss: 4.2754\n",
      "Epoch 414/1000\n",
      " - 97s - loss: 4.1735 - val_loss: 4.0567\n",
      "Epoch 415/1000\n",
      " - 98s - loss: 4.2138 - val_loss: 3.7825\n",
      "Epoch 416/1000\n",
      " - 97s - loss: 3.8904 - val_loss: 4.0799\n",
      "Epoch 417/1000\n",
      " - 97s - loss: 4.0904 - val_loss: 3.8583\n",
      "Epoch 418/1000\n",
      " - 97s - loss: 4.1276 - val_loss: 3.9870\n",
      "Epoch 419/1000\n",
      " - 97s - loss: 3.9821 - val_loss: 4.1048\n",
      "Epoch 420/1000\n",
      " - 98s - loss: 4.1945 - val_loss: 3.8637\n",
      "Epoch 421/1000\n",
      " - 97s - loss: 4.1322 - val_loss: 4.1300\n",
      "Epoch 422/1000\n",
      " - 97s - loss: 4.0139 - val_loss: 4.2186\n",
      "Epoch 423/1000\n",
      " - 97s - loss: 4.0966 - val_loss: 4.4832\n",
      "Epoch 424/1000\n",
      " - 97s - loss: 3.8983 - val_loss: 3.7052\n",
      "Epoch 425/1000\n",
      " - 97s - loss: 4.1330 - val_loss: 3.6775\n",
      "Epoch 426/1000\n",
      " - 97s - loss: 3.8602 - val_loss: 4.1547\n",
      "Epoch 427/1000\n",
      " - 97s - loss: 3.9883 - val_loss: 4.0251\n",
      "Epoch 428/1000\n",
      " - 97s - loss: 4.2494 - val_loss: 3.5467\n",
      "Epoch 429/1000\n",
      " - 97s - loss: 3.8455 - val_loss: 3.4983\n",
      "Epoch 430/1000\n",
      " - 97s - loss: 3.9548 - val_loss: 3.6325\n",
      "Epoch 431/1000\n",
      " - 97s - loss: 3.9775 - val_loss: 3.9070\n",
      "Epoch 432/1000\n",
      " - 97s - loss: 3.8254 - val_loss: 3.2770\n",
      "Epoch 433/1000\n",
      " - 96s - loss: 3.8046 - val_loss: 4.2833\n",
      "Epoch 434/1000\n",
      " - 98s - loss: 3.9760 - val_loss: 4.7449\n",
      "Epoch 435/1000\n",
      " - 97s - loss: 4.2078 - val_loss: 4.9269\n",
      "Epoch 436/1000\n",
      " - 97s - loss: 4.1864 - val_loss: 3.6826\n",
      "Epoch 437/1000\n",
      " - 97s - loss: 4.2603 - val_loss: 3.8646\n",
      "Epoch 438/1000\n",
      " - 97s - loss: 4.3425 - val_loss: 4.2260\n",
      "Epoch 439/1000\n",
      " - 97s - loss: 4.0485 - val_loss: 4.0813\n",
      "Epoch 440/1000\n",
      " - 97s - loss: 3.7425 - val_loss: 3.8587\n",
      "Epoch 441/1000\n",
      " - 97s - loss: 4.1187 - val_loss: 3.6777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/1000\n",
      " - 96s - loss: 3.9185 - val_loss: 3.9572\n",
      "Epoch 443/1000\n",
      " - 97s - loss: 4.0673 - val_loss: 4.1164\n",
      "Epoch 444/1000\n",
      " - 97s - loss: 4.1863 - val_loss: 4.0828\n",
      "Epoch 445/1000\n",
      " - 97s - loss: 4.0412 - val_loss: 3.7435\n",
      "Epoch 446/1000\n",
      " - 97s - loss: 4.2280 - val_loss: 3.9290\n",
      "Epoch 447/1000\n",
      " - 98s - loss: 3.8373 - val_loss: 3.6710\n",
      "Epoch 448/1000\n",
      " - 97s - loss: 3.9245 - val_loss: 3.4132\n",
      "Epoch 449/1000\n",
      " - 97s - loss: 3.8682 - val_loss: 4.2295\n",
      "Epoch 450/1000\n",
      " - 97s - loss: 3.9176 - val_loss: 3.8396\n",
      "Epoch 451/1000\n",
      " - 97s - loss: 3.9378 - val_loss: 3.4435\n",
      "Epoch 452/1000\n",
      " - 97s - loss: 3.8048 - val_loss: 3.5889\n",
      "Epoch 453/1000\n",
      " - 97s - loss: 3.7838 - val_loss: 3.7673\n",
      "Epoch 454/1000\n",
      " - 97s - loss: 4.1970 - val_loss: 4.0111\n",
      "Epoch 455/1000\n",
      " - 97s - loss: 4.1434 - val_loss: 3.8284\n",
      "Epoch 456/1000\n",
      " - 97s - loss: 3.8585 - val_loss: 3.4818\n",
      "Epoch 457/1000\n",
      " - 97s - loss: 3.7766 - val_loss: 3.8849\n",
      "Epoch 458/1000\n",
      " - 97s - loss: 3.6881 - val_loss: 4.4651\n",
      "Epoch 459/1000\n",
      " - 97s - loss: 4.3290 - val_loss: 3.4517\n",
      "Epoch 460/1000\n",
      " - 97s - loss: 4.0515 - val_loss: 3.8133\n",
      "Epoch 461/1000\n",
      " - 96s - loss: 3.8272 - val_loss: 3.5808\n",
      "Epoch 462/1000\n",
      " - 97s - loss: 3.7015 - val_loss: 4.3228\n",
      "Epoch 463/1000\n",
      " - 97s - loss: 4.0407 - val_loss: 3.9354\n",
      "Epoch 464/1000\n",
      " - 97s - loss: 3.7480 - val_loss: 3.8545\n",
      "Epoch 465/1000\n",
      " - 97s - loss: 4.1287 - val_loss: 3.6661\n",
      "Epoch 466/1000\n",
      " - 97s - loss: 4.1141 - val_loss: 3.8570\n",
      "Epoch 467/1000\n",
      " - 97s - loss: 3.7576 - val_loss: 3.4627\n",
      "Epoch 468/1000\n",
      " - 97s - loss: 3.9696 - val_loss: 4.1643\n",
      "Epoch 469/1000\n",
      " - 97s - loss: 3.5082 - val_loss: 5.0151\n",
      "Epoch 470/1000\n",
      " - 97s - loss: 3.7733 - val_loss: 4.1759\n",
      "Epoch 471/1000\n",
      " - 97s - loss: 3.8863 - val_loss: 3.5032\n",
      "Epoch 472/1000\n",
      " - 97s - loss: 3.8797 - val_loss: 4.0758\n",
      "Epoch 473/1000\n",
      " - 97s - loss: 3.9797 - val_loss: 3.7322\n",
      "Epoch 474/1000\n",
      " - 96s - loss: 3.9958 - val_loss: 3.3890\n",
      "Epoch 475/1000\n",
      " - 97s - loss: 3.9894 - val_loss: 4.1061\n",
      "Epoch 476/1000\n",
      " - 97s - loss: 3.8675 - val_loss: 3.6194\n",
      "Epoch 477/1000\n",
      " - 97s - loss: 4.0466 - val_loss: 3.8435\n",
      "Epoch 478/1000\n",
      " - 97s - loss: 3.6667 - val_loss: 3.7696\n",
      "Epoch 479/1000\n",
      " - 96s - loss: 3.9874 - val_loss: 3.7431\n",
      "Epoch 480/1000\n",
      " - 97s - loss: 3.8355 - val_loss: 4.0237\n",
      "Epoch 481/1000\n",
      " - 97s - loss: 3.7240 - val_loss: 3.3254\n",
      "Epoch 482/1000\n",
      " - 97s - loss: 3.6771 - val_loss: 3.7237\n",
      "Epoch 483/1000\n",
      " - 97s - loss: 4.3283 - val_loss: 3.5642\n",
      "Epoch 484/1000\n",
      " - 97s - loss: 3.7665 - val_loss: 3.8342\n",
      "Epoch 485/1000\n",
      " - 97s - loss: 4.0689 - val_loss: 4.4378\n",
      "Epoch 486/1000\n",
      " - 97s - loss: 3.9306 - val_loss: 4.6857\n",
      "Epoch 487/1000\n",
      " - 96s - loss: 4.2925 - val_loss: 3.3411\n",
      "Epoch 488/1000\n",
      " - 97s - loss: 3.7595 - val_loss: 4.1928\n",
      "Epoch 489/1000\n",
      " - 97s - loss: 4.1473 - val_loss: 3.2341\n",
      "Epoch 490/1000\n",
      " - 97s - loss: 3.9435 - val_loss: 3.5932\n",
      "Epoch 491/1000\n",
      " - 96s - loss: 3.8593 - val_loss: 4.0368\n",
      "Epoch 492/1000\n",
      " - 97s - loss: 3.7737 - val_loss: 4.4170\n",
      "Epoch 493/1000\n",
      " - 96s - loss: 3.9376 - val_loss: 3.6901\n",
      "Epoch 494/1000\n",
      " - 97s - loss: 3.7909 - val_loss: 3.9818\n",
      "Epoch 495/1000\n",
      " - 97s - loss: 3.8109 - val_loss: 3.7152\n",
      "Epoch 496/1000\n",
      " - 97s - loss: 4.0217 - val_loss: 4.2610\n",
      "Epoch 497/1000\n",
      " - 98s - loss: 3.8052 - val_loss: 3.7717\n",
      "Epoch 498/1000\n",
      " - 97s - loss: 3.7499 - val_loss: 3.5862\n",
      "Epoch 499/1000\n",
      " - 97s - loss: 4.1153 - val_loss: 3.7429\n",
      "Epoch 500/1000\n",
      " - 96s - loss: 3.9092 - val_loss: 3.6621\n",
      "Epoch 501/1000\n",
      " - 97s - loss: 3.9110 - val_loss: 3.8402\n",
      "Epoch 502/1000\n",
      " - 96s - loss: 3.7293 - val_loss: 4.2485\n",
      "Epoch 503/1000\n",
      " - 97s - loss: 4.0274 - val_loss: 3.9144\n",
      "Epoch 504/1000\n",
      " - 97s - loss: 3.5749 - val_loss: 3.7980\n",
      "Epoch 505/1000\n",
      " - 96s - loss: 3.6420 - val_loss: 3.5148\n",
      "Epoch 506/1000\n",
      " - 97s - loss: 3.8495 - val_loss: 3.7789\n",
      "Epoch 507/1000\n",
      " - 96s - loss: 3.7880 - val_loss: 3.7037\n",
      "Epoch 508/1000\n",
      " - 97s - loss: 3.5635 - val_loss: 3.9172\n",
      "Epoch 509/1000\n",
      " - 97s - loss: 3.5929 - val_loss: 4.0076\n",
      "Epoch 510/1000\n",
      " - 97s - loss: 3.6019 - val_loss: 3.5963\n",
      "Epoch 511/1000\n",
      " - 97s - loss: 3.6823 - val_loss: 3.7370\n",
      "Epoch 512/1000\n",
      " - 97s - loss: 3.4815 - val_loss: 3.4697\n",
      "Epoch 513/1000\n",
      " - 97s - loss: 3.7135 - val_loss: 3.9399\n",
      "Epoch 514/1000\n",
      " - 97s - loss: 3.6780 - val_loss: 3.9912\n",
      "Epoch 515/1000\n",
      " - 97s - loss: 3.6315 - val_loss: 4.0915\n",
      "Epoch 516/1000\n",
      " - 97s - loss: 3.3934 - val_loss: 3.5633\n",
      "Epoch 517/1000\n",
      " - 97s - loss: 3.7615 - val_loss: 3.5113\n",
      "Epoch 518/1000\n",
      " - 97s - loss: 3.8953 - val_loss: 3.6465\n",
      "Epoch 519/1000\n",
      " - 97s - loss: 3.8107 - val_loss: 4.2890\n",
      "Epoch 520/1000\n",
      " - 97s - loss: 3.7674 - val_loss: 3.5411\n",
      "Epoch 521/1000\n",
      " - 97s - loss: 3.4479 - val_loss: 3.8464\n",
      "Epoch 522/1000\n",
      " - 97s - loss: 3.5275 - val_loss: 3.7342\n",
      "Epoch 523/1000\n",
      " - 97s - loss: 3.8749 - val_loss: 4.0573\n",
      "Epoch 524/1000\n",
      " - 97s - loss: 3.6299 - val_loss: 3.9922\n",
      "Epoch 525/1000\n",
      " - 97s - loss: 3.8503 - val_loss: 3.2469\n",
      "Epoch 526/1000\n",
      " - 97s - loss: 3.6786 - val_loss: 4.1776\n",
      "Epoch 527/1000\n",
      " - 97s - loss: 3.7924 - val_loss: 3.6844\n",
      "Epoch 528/1000\n",
      " - 97s - loss: 3.5898 - val_loss: 3.8924\n",
      "Epoch 529/1000\n",
      " - 97s - loss: 3.6254 - val_loss: 3.7577\n",
      "Epoch 530/1000\n",
      " - 97s - loss: 3.6724 - val_loss: 3.9246\n",
      "Epoch 531/1000\n",
      " - 98s - loss: 3.6763 - val_loss: 3.4243\n",
      "Epoch 532/1000\n",
      " - 96s - loss: 3.6237 - val_loss: 3.1637\n",
      "Epoch 533/1000\n",
      " - 97s - loss: 3.5540 - val_loss: 3.5328\n",
      "Epoch 534/1000\n",
      " - 97s - loss: 3.4907 - val_loss: 3.6690\n",
      "Epoch 535/1000\n",
      " - 96s - loss: 3.3936 - val_loss: 3.6703\n",
      "Epoch 536/1000\n",
      " - 97s - loss: 3.8021 - val_loss: 3.9032\n",
      "Epoch 537/1000\n",
      " - 97s - loss: 3.8840 - val_loss: 3.7109\n",
      "Epoch 538/1000\n",
      " - 97s - loss: 3.5259 - val_loss: 3.4818\n",
      "Epoch 539/1000\n",
      " - 97s - loss: 3.3329 - val_loss: 3.4057\n",
      "Epoch 540/1000\n",
      " - 97s - loss: 3.7958 - val_loss: 3.6248\n",
      "Epoch 541/1000\n",
      " - 97s - loss: 3.5998 - val_loss: 3.6046\n",
      "Epoch 542/1000\n",
      " - 97s - loss: 3.7103 - val_loss: 3.9803\n",
      "Epoch 543/1000\n",
      " - 97s - loss: 3.7017 - val_loss: 3.1317\n",
      "Epoch 544/1000\n",
      " - 96s - loss: 3.5873 - val_loss: 3.6386\n",
      "Epoch 545/1000\n",
      " - 97s - loss: 3.6542 - val_loss: 3.8209\n",
      "Epoch 546/1000\n",
      " - 97s - loss: 3.5979 - val_loss: 3.8164\n",
      "Epoch 547/1000\n",
      " - 97s - loss: 3.8812 - val_loss: 4.2143\n",
      "Epoch 548/1000\n",
      " - 96s - loss: 3.7853 - val_loss: 4.0133\n",
      "Epoch 549/1000\n",
      " - 98s - loss: 3.5224 - val_loss: 3.6818\n",
      "Epoch 550/1000\n",
      " - 97s - loss: 3.3643 - val_loss: 3.8305\n",
      "Epoch 551/1000\n",
      " - 97s - loss: 3.4860 - val_loss: 3.3234\n",
      "Epoch 552/1000\n",
      " - 97s - loss: 3.9372 - val_loss: 3.9012\n",
      "Epoch 553/1000\n",
      " - 97s - loss: 3.5759 - val_loss: 3.7105\n",
      "Epoch 554/1000\n",
      " - 97s - loss: 3.4847 - val_loss: 3.3282\n",
      "Epoch 555/1000\n",
      " - 97s - loss: 3.5124 - val_loss: 3.2333\n",
      "Epoch 556/1000\n",
      " - 97s - loss: 3.7511 - val_loss: 3.3183\n",
      "Epoch 557/1000\n",
      " - 97s - loss: 3.4009 - val_loss: 3.1143\n",
      "Epoch 558/1000\n",
      " - 97s - loss: 3.4578 - val_loss: 3.4342\n",
      "Epoch 559/1000\n",
      " - 97s - loss: 3.5972 - val_loss: 3.5272\n",
      "Epoch 560/1000\n",
      " - 97s - loss: 3.6580 - val_loss: 3.9432\n",
      "Epoch 561/1000\n",
      " - 97s - loss: 3.8666 - val_loss: 3.4437\n",
      "Epoch 562/1000\n",
      " - 97s - loss: 3.6435 - val_loss: 3.2842\n",
      "Epoch 563/1000\n",
      " - 97s - loss: 3.1838 - val_loss: 3.4704\n",
      "Epoch 564/1000\n",
      " - 97s - loss: 3.7548 - val_loss: 3.9838\n",
      "Epoch 565/1000\n",
      " - 97s - loss: 3.4954 - val_loss: 3.5499\n",
      "Epoch 566/1000\n",
      " - 97s - loss: 3.6679 - val_loss: 3.5593\n",
      "Epoch 567/1000\n",
      " - 98s - loss: 3.4777 - val_loss: 3.7523\n",
      "Epoch 568/1000\n",
      " - 96s - loss: 3.5574 - val_loss: 3.6773\n",
      "Epoch 569/1000\n",
      " - 97s - loss: 3.6600 - val_loss: 3.5230\n",
      "Epoch 570/1000\n",
      " - 97s - loss: 3.7663 - val_loss: 3.7956\n",
      "Epoch 571/1000\n",
      " - 97s - loss: 3.6482 - val_loss: 3.6352\n",
      "Epoch 572/1000\n",
      " - 97s - loss: 3.4140 - val_loss: 3.3229\n",
      "Epoch 573/1000\n",
      " - 97s - loss: 3.6669 - val_loss: 3.7660\n",
      "Epoch 574/1000\n",
      " - 97s - loss: 3.3807 - val_loss: 3.6376\n",
      "Epoch 575/1000\n",
      " - 97s - loss: 3.5002 - val_loss: 3.7644\n",
      "Epoch 576/1000\n",
      " - 97s - loss: 3.6037 - val_loss: 3.5989\n",
      "Epoch 577/1000\n",
      " - 97s - loss: 3.2997 - val_loss: 3.1463\n",
      "Epoch 578/1000\n",
      " - 98s - loss: 3.5929 - val_loss: 2.9939\n",
      "Epoch 579/1000\n",
      " - 97s - loss: 3.5797 - val_loss: 3.7531\n",
      "Epoch 580/1000\n",
      " - 97s - loss: 3.4906 - val_loss: 3.3336\n",
      "Epoch 581/1000\n",
      " - 97s - loss: 3.3467 - val_loss: 3.8813\n",
      "Epoch 582/1000\n",
      " - 98s - loss: 3.5358 - val_loss: 3.2954\n",
      "Epoch 583/1000\n",
      " - 96s - loss: 3.6225 - val_loss: 3.4672\n",
      "Epoch 584/1000\n",
      " - 97s - loss: 3.5477 - val_loss: 3.1617\n",
      "Epoch 585/1000\n",
      " - 97s - loss: 3.5583 - val_loss: 3.5612\n",
      "Epoch 586/1000\n",
      " - 97s - loss: 3.6386 - val_loss: 3.5719\n",
      "Epoch 587/1000\n",
      " - 97s - loss: 3.5061 - val_loss: 3.2956\n",
      "Epoch 588/1000\n",
      " - 96s - loss: 3.4219 - val_loss: 3.8364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/1000\n",
      " - 97s - loss: 3.4886 - val_loss: 4.0180\n",
      "Epoch 590/1000\n",
      " - 96s - loss: 3.4726 - val_loss: 3.5727\n",
      "Epoch 591/1000\n",
      " - 97s - loss: 3.5056 - val_loss: 3.8394\n",
      "Epoch 592/1000\n",
      " - 97s - loss: 3.4388 - val_loss: 3.2871\n",
      "Epoch 593/1000\n",
      " - 97s - loss: 3.3133 - val_loss: 3.8984\n",
      "Epoch 594/1000\n",
      " - 97s - loss: 3.4744 - val_loss: 3.5067\n",
      "Epoch 595/1000\n",
      " - 97s - loss: 3.7340 - val_loss: 3.5003\n",
      "Epoch 596/1000\n",
      " - 97s - loss: 3.4380 - val_loss: 3.3713\n",
      "Epoch 597/1000\n",
      " - 97s - loss: 3.3684 - val_loss: 3.5983\n",
      "Epoch 598/1000\n",
      " - 97s - loss: 3.4021 - val_loss: 3.6887\n",
      "Epoch 599/1000\n",
      " - 97s - loss: 3.5740 - val_loss: 3.8394\n",
      "Epoch 600/1000\n",
      " - 97s - loss: 3.3071 - val_loss: 3.8972\n",
      "Epoch 601/1000\n",
      " - 97s - loss: 3.7257 - val_loss: 4.1233\n",
      "Epoch 602/1000\n",
      " - 97s - loss: 3.3497 - val_loss: 3.7492\n",
      "Epoch 603/1000\n",
      " - 97s - loss: 3.7507 - val_loss: 3.4492\n",
      "Epoch 604/1000\n",
      " - 98s - loss: 3.2570 - val_loss: 3.2971\n",
      "Epoch 605/1000\n",
      " - 97s - loss: 3.3239 - val_loss: 3.3169\n",
      "Epoch 606/1000\n",
      " - 97s - loss: 3.3800 - val_loss: 3.6047\n",
      "Epoch 607/1000\n",
      " - 97s - loss: 3.5614 - val_loss: 3.5670\n",
      "Epoch 608/1000\n",
      " - 97s - loss: 3.0910 - val_loss: 3.3257\n",
      "Epoch 609/1000\n",
      " - 97s - loss: 3.3513 - val_loss: 3.0278\n",
      "Epoch 610/1000\n",
      " - 97s - loss: 3.1433 - val_loss: 3.8294\n",
      "Epoch 611/1000\n",
      " - 97s - loss: 3.5992 - val_loss: 3.5428\n",
      "Epoch 612/1000\n",
      " - 97s - loss: 3.2670 - val_loss: 3.3491\n",
      "Epoch 613/1000\n",
      " - 97s - loss: 3.3444 - val_loss: 3.5002\n",
      "Epoch 614/1000\n",
      " - 97s - loss: 3.3039 - val_loss: 3.3319\n",
      "Epoch 615/1000\n",
      " - 97s - loss: 3.1784 - val_loss: 3.4432\n",
      "Epoch 616/1000\n",
      " - 97s - loss: 2.9571 - val_loss: 3.3717\n",
      "Epoch 617/1000\n",
      " - 97s - loss: 3.0187 - val_loss: 3.1774\n",
      "Epoch 618/1000\n",
      " - 96s - loss: 3.4995 - val_loss: 3.4050\n",
      "Epoch 619/1000\n",
      " - 97s - loss: 3.2415 - val_loss: 4.3523\n",
      "Epoch 620/1000\n",
      " - 96s - loss: 3.3896 - val_loss: 2.9242\n",
      "Epoch 621/1000\n",
      " - 97s - loss: 3.3299 - val_loss: 3.7753\n",
      "Epoch 622/1000\n",
      " - 97s - loss: 3.3749 - val_loss: 3.5523\n",
      "Epoch 623/1000\n",
      " - 98s - loss: 3.3953 - val_loss: 3.5776\n",
      "Epoch 624/1000\n",
      " - 97s - loss: 3.3341 - val_loss: 3.0202\n",
      "Epoch 625/1000\n",
      " - 98s - loss: 3.3895 - val_loss: 3.0476\n",
      "Epoch 626/1000\n",
      " - 97s - loss: 3.4153 - val_loss: 3.7070\n",
      "Epoch 627/1000\n",
      " - 97s - loss: 3.3810 - val_loss: 3.3929\n",
      "Epoch 628/1000\n",
      " - 97s - loss: 3.3368 - val_loss: 2.9854\n",
      "Epoch 629/1000\n",
      " - 97s - loss: 3.3071 - val_loss: 2.8890\n",
      "Epoch 630/1000\n",
      " - 97s - loss: 3.5462 - val_loss: 3.1358\n",
      "Epoch 631/1000\n",
      " - 97s - loss: 3.2913 - val_loss: 3.2064\n",
      "Epoch 632/1000\n",
      " - 98s - loss: 3.2194 - val_loss: 3.2731\n",
      "Epoch 633/1000\n",
      " - 96s - loss: 3.3388 - val_loss: 3.4301\n",
      "Epoch 634/1000\n",
      " - 98s - loss: 3.2642 - val_loss: 3.3669\n",
      "Epoch 635/1000\n",
      " - 97s - loss: 3.2836 - val_loss: 3.7627\n",
      "Epoch 636/1000\n",
      " - 97s - loss: 3.5781 - val_loss: 3.9709\n",
      "Epoch 637/1000\n",
      " - 97s - loss: 3.1448 - val_loss: 3.3577\n",
      "Epoch 638/1000\n",
      " - 97s - loss: 3.4460 - val_loss: 3.4363\n",
      "Epoch 639/1000\n",
      " - 97s - loss: 3.1118 - val_loss: 3.1631\n",
      "Epoch 640/1000\n",
      " - 97s - loss: 3.3718 - val_loss: 3.2910\n",
      "Epoch 641/1000\n",
      " - 97s - loss: 3.2690 - val_loss: 2.9335\n",
      "Epoch 642/1000\n",
      " - 97s - loss: 3.4182 - val_loss: 4.0102\n",
      "Epoch 643/1000\n",
      " - 97s - loss: 3.3144 - val_loss: 3.2609\n",
      "Epoch 644/1000\n",
      " - 97s - loss: 3.5132 - val_loss: 2.9642\n",
      "Epoch 645/1000\n",
      " - 98s - loss: 3.2093 - val_loss: 2.9807\n",
      "Epoch 646/1000\n",
      " - 97s - loss: 3.3011 - val_loss: 3.6009\n",
      "Epoch 647/1000\n",
      " - 97s - loss: 3.4223 - val_loss: 3.5926\n",
      "Epoch 648/1000\n",
      " - 97s - loss: 3.2048 - val_loss: 3.1251\n",
      "Epoch 649/1000\n",
      " - 98s - loss: 3.3868 - val_loss: 3.4357\n",
      "Epoch 650/1000\n",
      " - 97s - loss: 3.1697 - val_loss: 3.6821\n",
      "Epoch 651/1000\n",
      " - 98s - loss: 3.1201 - val_loss: 3.3061\n",
      "Epoch 652/1000\n",
      " - 97s - loss: 3.2163 - val_loss: 3.0845\n",
      "Epoch 653/1000\n",
      " - 97s - loss: 3.4866 - val_loss: 3.5081\n",
      "Epoch 654/1000\n",
      " - 97s - loss: 3.1721 - val_loss: 3.6039\n",
      "Epoch 655/1000\n",
      " - 97s - loss: 3.3903 - val_loss: 2.9434\n",
      "Epoch 656/1000\n",
      " - 97s - loss: 3.3487 - val_loss: 3.2836\n",
      "Epoch 657/1000\n",
      " - 97s - loss: 3.4544 - val_loss: 2.9510\n",
      "Epoch 658/1000\n",
      " - 97s - loss: 3.5951 - val_loss: 3.4782\n",
      "Epoch 659/1000\n",
      " - 97s - loss: 3.2611 - val_loss: 3.6325\n",
      "Epoch 660/1000\n",
      " - 97s - loss: 3.2997 - val_loss: 3.3575\n",
      "Epoch 661/1000\n",
      " - 97s - loss: 3.1318 - val_loss: 3.2780\n",
      "Epoch 662/1000\n",
      " - 97s - loss: 3.4634 - val_loss: 3.3449\n",
      "Epoch 663/1000\n",
      " - 97s - loss: 3.3110 - val_loss: 3.3374\n",
      "Epoch 664/1000\n",
      " - 97s - loss: 3.5434 - val_loss: 3.5704\n",
      "Epoch 665/1000\n",
      " - 97s - loss: 3.0980 - val_loss: 3.6311\n",
      "Epoch 666/1000\n",
      " - 97s - loss: 3.2724 - val_loss: 3.4370\n",
      "Epoch 667/1000\n",
      " - 97s - loss: 3.0656 - val_loss: 3.0931\n",
      "Epoch 668/1000\n",
      " - 97s - loss: 3.0002 - val_loss: 3.1596\n",
      "Epoch 669/1000\n",
      " - 97s - loss: 3.0497 - val_loss: 3.4887\n",
      "Epoch 670/1000\n",
      " - 97s - loss: 3.1781 - val_loss: 3.3623\n",
      "Epoch 671/1000\n",
      " - 97s - loss: 3.4255 - val_loss: 3.2164\n",
      "Epoch 672/1000\n",
      " - 97s - loss: 3.1180 - val_loss: 3.9137\n",
      "Epoch 673/1000\n",
      " - 96s - loss: 3.3680 - val_loss: 3.5797\n",
      "Epoch 674/1000\n",
      " - 97s - loss: 3.2880 - val_loss: 3.1782\n",
      "Epoch 675/1000\n",
      " - 97s - loss: 3.1377 - val_loss: 3.1271\n",
      "Epoch 676/1000\n",
      " - 97s - loss: 3.0871 - val_loss: 3.2310\n",
      "Epoch 677/1000\n",
      " - 96s - loss: 3.2778 - val_loss: 4.0635\n",
      "Epoch 678/1000\n",
      " - 97s - loss: 3.3899 - val_loss: 3.4209\n",
      "Epoch 679/1000\n",
      " - 97s - loss: 3.0761 - val_loss: 2.8482\n",
      "Epoch 680/1000\n",
      " - 97s - loss: 3.1415 - val_loss: 2.6777\n",
      "Epoch 681/1000\n",
      " - 97s - loss: 3.4744 - val_loss: 3.2309\n",
      "Epoch 682/1000\n",
      " - 97s - loss: 3.1885 - val_loss: 3.7136\n",
      "Epoch 683/1000\n",
      " - 97s - loss: 3.2471 - val_loss: 3.0788\n",
      "Epoch 684/1000\n",
      " - 97s - loss: 3.1722 - val_loss: 3.5262\n",
      "Epoch 685/1000\n",
      " - 97s - loss: 2.9333 - val_loss: 3.3355\n",
      "Epoch 686/1000\n",
      " - 97s - loss: 2.9910 - val_loss: 3.2341\n",
      "Epoch 687/1000\n",
      " - 98s - loss: 3.3637 - val_loss: 3.2944\n",
      "Epoch 688/1000\n",
      " - 97s - loss: 3.3929 - val_loss: 3.1399\n",
      "Epoch 689/1000\n",
      " - 97s - loss: 3.4593 - val_loss: 3.3946\n",
      "Epoch 690/1000\n",
      " - 97s - loss: 3.2145 - val_loss: 3.0290\n",
      "Epoch 691/1000\n",
      " - 97s - loss: 3.2048 - val_loss: 2.9766\n",
      "Epoch 692/1000\n",
      " - 97s - loss: 3.3804 - val_loss: 3.1854\n",
      "Epoch 693/1000\n",
      " - 97s - loss: 3.3802 - val_loss: 2.6060\n",
      "Epoch 694/1000\n",
      " - 96s - loss: 3.3106 - val_loss: 3.0874\n",
      "Epoch 695/1000\n",
      " - 97s - loss: 3.1706 - val_loss: 3.3270\n",
      "Epoch 696/1000\n",
      " - 97s - loss: 2.8993 - val_loss: 3.1903\n",
      "Epoch 697/1000\n",
      " - 97s - loss: 3.3241 - val_loss: 4.0238\n",
      "Epoch 698/1000\n",
      " - 96s - loss: 3.3548 - val_loss: 3.1330\n",
      "Epoch 699/1000\n",
      " - 97s - loss: 3.1649 - val_loss: 4.2246\n",
      "Epoch 700/1000\n",
      " - 97s - loss: 3.0197 - val_loss: 3.2741\n",
      "Epoch 701/1000\n",
      " - 97s - loss: 3.2939 - val_loss: 3.7697\n",
      "Epoch 702/1000\n",
      " - 97s - loss: 3.0848 - val_loss: 3.5045\n",
      "Epoch 703/1000\n",
      " - 97s - loss: 2.8566 - val_loss: 3.1482\n",
      "Epoch 704/1000\n",
      " - 97s - loss: 3.3763 - val_loss: 3.4584\n",
      "Epoch 705/1000\n",
      " - 97s - loss: 3.2461 - val_loss: 3.2272\n",
      "Epoch 706/1000\n",
      " - 97s - loss: 2.9132 - val_loss: 2.9853\n",
      "Epoch 707/1000\n",
      " - 97s - loss: 2.8092 - val_loss: 3.4759\n",
      "Epoch 708/1000\n",
      " - 97s - loss: 3.0660 - val_loss: 3.2056\n",
      "Epoch 709/1000\n",
      " - 97s - loss: 3.1411 - val_loss: 2.9100\n",
      "Epoch 710/1000\n",
      " - 97s - loss: 2.9723 - val_loss: 2.9252\n",
      "Epoch 711/1000\n",
      " - 96s - loss: 2.8184 - val_loss: 2.6727\n",
      "Epoch 712/1000\n",
      " - 96s - loss: 3.1433 - val_loss: 2.9989\n",
      "Epoch 713/1000\n",
      " - 97s - loss: 3.1775 - val_loss: 2.9835\n",
      "Epoch 714/1000\n",
      " - 97s - loss: 3.0714 - val_loss: 2.9517\n",
      "Epoch 715/1000\n",
      " - 97s - loss: 3.1373 - val_loss: 3.2226\n",
      "Epoch 716/1000\n",
      " - 97s - loss: 3.1311 - val_loss: 3.2226\n",
      "Epoch 717/1000\n",
      " - 97s - loss: 3.3435 - val_loss: 3.2779\n",
      "Epoch 718/1000\n",
      " - 96s - loss: 2.9619 - val_loss: 3.6963\n",
      "Epoch 719/1000\n",
      " - 97s - loss: 2.9873 - val_loss: 3.0518\n",
      "Epoch 720/1000\n",
      " - 97s - loss: 2.9740 - val_loss: 3.4440\n",
      "Epoch 721/1000\n",
      " - 97s - loss: 3.1479 - val_loss: 3.4889\n",
      "Epoch 722/1000\n",
      " - 97s - loss: 2.9479 - val_loss: 3.2810\n",
      "Epoch 723/1000\n",
      " - 96s - loss: 2.8996 - val_loss: 3.2240\n",
      "Epoch 724/1000\n",
      " - 96s - loss: 3.3290 - val_loss: 2.9952\n",
      "Epoch 725/1000\n",
      " - 97s - loss: 3.0276 - val_loss: 2.8187\n",
      "Epoch 726/1000\n",
      " - 97s - loss: 3.0957 - val_loss: 3.4656\n",
      "Epoch 727/1000\n",
      " - 97s - loss: 2.9437 - val_loss: 2.6562\n",
      "Epoch 728/1000\n",
      " - 97s - loss: 2.8721 - val_loss: 2.7296\n",
      "Epoch 729/1000\n",
      " - 97s - loss: 3.0737 - val_loss: 3.1239\n",
      "Epoch 730/1000\n",
      " - 97s - loss: 3.0593 - val_loss: 3.0971\n",
      "Epoch 731/1000\n",
      " - 96s - loss: 3.0601 - val_loss: 2.6980\n",
      "Epoch 732/1000\n",
      " - 97s - loss: 2.9281 - val_loss: 3.0267\n",
      "Epoch 733/1000\n",
      " - 97s - loss: 2.9031 - val_loss: 3.5134\n",
      "Epoch 734/1000\n",
      " - 97s - loss: 3.0200 - val_loss: 2.6757\n",
      "Epoch 735/1000\n",
      " - 97s - loss: 2.8611 - val_loss: 2.9079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 736/1000\n",
      " - 97s - loss: 3.2199 - val_loss: 3.2684\n",
      "Epoch 737/1000\n",
      " - 97s - loss: 3.0830 - val_loss: 3.6393\n",
      "Epoch 738/1000\n",
      " - 97s - loss: 3.0322 - val_loss: 3.1005\n",
      "Epoch 739/1000\n",
      " - 97s - loss: 3.0893 - val_loss: 2.7407\n",
      "Epoch 740/1000\n",
      " - 97s - loss: 3.0339 - val_loss: 3.1640\n",
      "Epoch 741/1000\n",
      " - 97s - loss: 2.8529 - val_loss: 2.8058\n",
      "Epoch 742/1000\n",
      " - 97s - loss: 3.0296 - val_loss: 3.1948\n",
      "Epoch 743/1000\n",
      " - 97s - loss: 3.0832 - val_loss: 2.9628\n",
      "Epoch 744/1000\n",
      " - 97s - loss: 2.9536 - val_loss: 3.3593\n",
      "Epoch 745/1000\n",
      " - 98s - loss: 3.2383 - val_loss: 3.1955\n",
      "Epoch 746/1000\n",
      " - 97s - loss: 3.0136 - val_loss: 2.7355\n",
      "Epoch 747/1000\n",
      " - 97s - loss: 2.9685 - val_loss: 3.2802\n",
      "Epoch 748/1000\n",
      " - 97s - loss: 3.1701 - val_loss: 3.1077\n",
      "Epoch 749/1000\n",
      " - 97s - loss: 2.9349 - val_loss: 3.1482\n",
      "Epoch 750/1000\n",
      " - 97s - loss: 2.9932 - val_loss: 2.4845\n",
      "Epoch 751/1000\n",
      " - 98s - loss: 3.1733 - val_loss: 2.9936\n",
      "Epoch 752/1000\n",
      " - 97s - loss: 3.1591 - val_loss: 2.9543\n",
      "Epoch 753/1000\n",
      " - 97s - loss: 3.0894 - val_loss: 2.5839\n",
      "Epoch 754/1000\n",
      " - 97s - loss: 3.2046 - val_loss: 3.1717\n",
      "Epoch 755/1000\n",
      " - 97s - loss: 2.7747 - val_loss: 2.4767\n",
      "Epoch 756/1000\n",
      " - 98s - loss: 3.1120 - val_loss: 2.4382\n",
      "Epoch 757/1000\n",
      " - 97s - loss: 3.0958 - val_loss: 3.1080\n",
      "Epoch 758/1000\n",
      " - 97s - loss: 2.8403 - val_loss: 3.0813\n",
      "Epoch 759/1000\n",
      " - 96s - loss: 3.2900 - val_loss: 3.0042\n",
      "Epoch 760/1000\n",
      " - 97s - loss: 3.1868 - val_loss: 3.3274\n",
      "Epoch 761/1000\n",
      " - 97s - loss: 3.0247 - val_loss: 2.8285\n",
      "Epoch 762/1000\n",
      " - 97s - loss: 3.0900 - val_loss: 2.7407\n",
      "Epoch 763/1000\n",
      " - 97s - loss: 3.2233 - val_loss: 3.2689\n",
      "Epoch 764/1000\n",
      " - 98s - loss: 3.1775 - val_loss: 3.3107\n",
      "Epoch 765/1000\n",
      " - 97s - loss: 3.2257 - val_loss: 2.7188\n",
      "Epoch 766/1000\n",
      " - 98s - loss: 3.2552 - val_loss: 2.7743\n",
      "Epoch 767/1000\n",
      " - 97s - loss: 2.9311 - val_loss: 2.8590\n",
      "Epoch 768/1000\n",
      " - 97s - loss: 2.9767 - val_loss: 3.2928\n",
      "Epoch 769/1000\n",
      " - 97s - loss: 3.3850 - val_loss: 3.3662\n",
      "Epoch 770/1000\n",
      " - 97s - loss: 2.8951 - val_loss: 2.8851\n",
      "Epoch 771/1000\n",
      " - 97s - loss: 2.9037 - val_loss: 3.5706\n",
      "Epoch 772/1000\n",
      " - 97s - loss: 3.0095 - val_loss: 2.9934\n",
      "Epoch 773/1000\n",
      " - 97s - loss: 2.9707 - val_loss: 2.8615\n",
      "Epoch 774/1000\n",
      " - 97s - loss: 2.7566 - val_loss: 3.3618\n",
      "Epoch 775/1000\n",
      " - 98s - loss: 3.1408 - val_loss: 3.7326\n",
      "Epoch 776/1000\n",
      " - 97s - loss: 2.9907 - val_loss: 3.7155\n",
      "Epoch 777/1000\n",
      " - 97s - loss: 3.0183 - val_loss: 3.2072\n",
      "Epoch 778/1000\n",
      " - 97s - loss: 2.8190 - val_loss: 3.3065\n",
      "Epoch 779/1000\n",
      " - 97s - loss: 2.9228 - val_loss: 2.7156\n",
      "Epoch 780/1000\n",
      " - 97s - loss: 2.9059 - val_loss: 3.2669\n",
      "Epoch 781/1000\n",
      " - 98s - loss: 2.7103 - val_loss: 3.0604\n",
      "Epoch 782/1000\n",
      " - 97s - loss: 3.1819 - val_loss: 2.8228\n",
      "Epoch 783/1000\n",
      " - 98s - loss: 2.8792 - val_loss: 3.2040\n",
      "Epoch 784/1000\n",
      " - 97s - loss: 3.1112 - val_loss: 3.1616\n",
      "Epoch 785/1000\n",
      " - 98s - loss: 3.0460 - val_loss: 2.9293\n",
      "Epoch 786/1000\n",
      " - 97s - loss: 3.0662 - val_loss: 3.1994\n",
      "Epoch 787/1000\n",
      " - 98s - loss: 2.8666 - val_loss: 2.9526\n",
      "Epoch 788/1000\n",
      " - 97s - loss: 2.8985 - val_loss: 2.7954\n",
      "Epoch 789/1000\n",
      " - 98s - loss: 3.2007 - val_loss: 3.1784\n",
      "Epoch 790/1000\n",
      " - 97s - loss: 2.8098 - val_loss: 3.4560\n",
      "Epoch 791/1000\n",
      " - 97s - loss: 2.8281 - val_loss: 3.1859\n",
      "Epoch 792/1000\n",
      " - 97s - loss: 3.0261 - val_loss: 2.7544\n",
      "Epoch 793/1000\n",
      " - 98s - loss: 3.0007 - val_loss: 3.3028\n",
      "Epoch 794/1000\n",
      " - 97s - loss: 2.8901 - val_loss: 2.9464\n",
      "Epoch 795/1000\n",
      " - 97s - loss: 3.1399 - val_loss: 3.5091\n",
      "Epoch 796/1000\n",
      " - 97s - loss: 3.0335 - val_loss: 2.8066\n",
      "Epoch 797/1000\n",
      " - 97s - loss: 2.6693 - val_loss: 2.9155\n",
      "Epoch 798/1000\n",
      " - 97s - loss: 2.9466 - val_loss: 3.2595\n",
      "Epoch 799/1000\n",
      " - 96s - loss: 2.9740 - val_loss: 3.3658\n",
      "Epoch 800/1000\n",
      " - 97s - loss: 3.1416 - val_loss: 2.9606\n",
      "Epoch 801/1000\n",
      " - 97s - loss: 2.9214 - val_loss: 3.2155\n",
      "Epoch 802/1000\n",
      " - 97s - loss: 3.1228 - val_loss: 2.8648\n",
      "Epoch 803/1000\n",
      " - 97s - loss: 3.0153 - val_loss: 2.8756\n",
      "Epoch 804/1000\n",
      " - 98s - loss: 2.9278 - val_loss: 2.8608\n",
      "Epoch 805/1000\n",
      " - 97s - loss: 3.1140 - val_loss: 2.9475\n",
      "Epoch 806/1000\n",
      " - 97s - loss: 2.9387 - val_loss: 2.9019\n",
      "Epoch 807/1000\n",
      " - 97s - loss: 2.8256 - val_loss: 2.8949\n",
      "Epoch 808/1000\n",
      " - 96s - loss: 3.0558 - val_loss: 2.9536\n",
      "Epoch 809/1000\n",
      " - 97s - loss: 3.0767 - val_loss: 2.7648\n",
      "Epoch 810/1000\n",
      " - 97s - loss: 3.0138 - val_loss: 2.3020\n",
      "Epoch 811/1000\n",
      " - 97s - loss: 3.0440 - val_loss: 2.8311\n",
      "Epoch 812/1000\n",
      " - 97s - loss: 2.7229 - val_loss: 2.6607\n",
      "Epoch 813/1000\n",
      " - 98s - loss: 2.7191 - val_loss: 3.1951\n",
      "Epoch 814/1000\n",
      " - 97s - loss: 3.0299 - val_loss: 3.2278\n",
      "Epoch 815/1000\n",
      " - 98s - loss: 2.7244 - val_loss: 2.4631\n",
      "Epoch 816/1000\n",
      " - 97s - loss: 2.8716 - val_loss: 2.8204\n",
      "Epoch 817/1000\n",
      " - 97s - loss: 2.9993 - val_loss: 3.0388\n",
      "Epoch 818/1000\n",
      " - 97s - loss: 2.7362 - val_loss: 2.8629\n",
      "Epoch 819/1000\n",
      " - 97s - loss: 2.8505 - val_loss: 3.0650\n",
      "Epoch 820/1000\n",
      " - 97s - loss: 2.8310 - val_loss: 2.6766\n",
      "Epoch 821/1000\n",
      " - 97s - loss: 3.1267 - val_loss: 2.9934\n",
      "Epoch 822/1000\n",
      " - 97s - loss: 2.6709 - val_loss: 2.9761\n",
      "Epoch 823/1000\n",
      " - 97s - loss: 2.8550 - val_loss: 3.2763\n",
      "Epoch 824/1000\n",
      " - 97s - loss: 2.9047 - val_loss: 2.3674\n",
      "Epoch 825/1000\n",
      " - 97s - loss: 2.7741 - val_loss: 3.2473\n",
      "Epoch 826/1000\n",
      " - 98s - loss: 2.9816 - val_loss: 3.0843\n",
      "Epoch 827/1000\n",
      " - 97s - loss: 2.6371 - val_loss: 3.1381\n",
      "Epoch 828/1000\n",
      " - 98s - loss: 2.5517 - val_loss: 3.3875\n",
      "Epoch 829/1000\n",
      " - 97s - loss: 2.8464 - val_loss: 2.8978\n",
      "Epoch 830/1000\n",
      " - 97s - loss: 2.7649 - val_loss: 3.0733\n",
      "Epoch 831/1000\n",
      " - 97s - loss: 2.7240 - val_loss: 3.0290\n",
      "Epoch 832/1000\n",
      " - 97s - loss: 2.9992 - val_loss: 3.0257\n",
      "Epoch 833/1000\n",
      " - 97s - loss: 2.7114 - val_loss: 3.3570\n",
      "Epoch 834/1000\n",
      " - 97s - loss: 3.0501 - val_loss: 3.2842\n",
      "Epoch 835/1000\n",
      " - 97s - loss: 2.6030 - val_loss: 2.5082\n",
      "Epoch 836/1000\n",
      " - 97s - loss: 2.8158 - val_loss: 3.2625\n",
      "Epoch 837/1000\n",
      " - 98s - loss: 2.9972 - val_loss: 2.9497\n",
      "Epoch 838/1000\n",
      " - 97s - loss: 2.7993 - val_loss: 2.6906\n",
      "Epoch 839/1000\n",
      " - 97s - loss: 2.9054 - val_loss: 2.8031\n",
      "Epoch 840/1000\n",
      " - 97s - loss: 2.9731 - val_loss: 2.8442\n",
      "Epoch 841/1000\n",
      " - 97s - loss: 2.8255 - val_loss: 2.9872\n",
      "Epoch 842/1000\n",
      " - 97s - loss: 2.9953 - val_loss: 2.8068\n",
      "Epoch 843/1000\n",
      " - 97s - loss: 2.5222 - val_loss: 2.8084\n",
      "Epoch 844/1000\n",
      " - 97s - loss: 2.7590 - val_loss: 3.4738\n",
      "Epoch 845/1000\n",
      " - 97s - loss: 2.6839 - val_loss: 2.8930\n",
      "Epoch 846/1000\n",
      " - 98s - loss: 2.9409 - val_loss: 3.2451\n",
      "Epoch 847/1000\n",
      " - 97s - loss: 2.8405 - val_loss: 2.7955\n",
      "Epoch 848/1000\n",
      " - 97s - loss: 2.9754 - val_loss: 3.0751\n",
      "Epoch 849/1000\n",
      " - 97s - loss: 2.9359 - val_loss: 3.2058\n",
      "Epoch 850/1000\n",
      " - 98s - loss: 2.9798 - val_loss: 2.7150\n",
      "Epoch 851/1000\n",
      " - 97s - loss: 2.7656 - val_loss: 3.0297\n",
      "Epoch 852/1000\n",
      " - 97s - loss: 3.0006 - val_loss: 3.4406\n",
      "Epoch 853/1000\n",
      " - 96s - loss: 2.9865 - val_loss: 2.8656\n",
      "Epoch 854/1000\n",
      " - 97s - loss: 2.7297 - val_loss: 3.3316\n",
      "Epoch 855/1000\n",
      " - 97s - loss: 3.1323 - val_loss: 3.0959\n",
      "Epoch 856/1000\n",
      " - 97s - loss: 2.9058 - val_loss: 3.4212\n",
      "Epoch 857/1000\n",
      " - 97s - loss: 2.8205 - val_loss: 2.8821\n",
      "Epoch 858/1000\n",
      " - 97s - loss: 2.5664 - val_loss: 3.0082\n",
      "Epoch 859/1000\n",
      " - 97s - loss: 2.5020 - val_loss: 2.6947\n",
      "Epoch 860/1000\n",
      " - 97s - loss: 2.8747 - val_loss: 2.9236\n",
      "Epoch 861/1000\n",
      " - 97s - loss: 2.8157 - val_loss: 3.0002\n",
      "Epoch 862/1000\n",
      " - 97s - loss: 2.7263 - val_loss: 3.2516\n",
      "Epoch 863/1000\n",
      " - 98s - loss: 2.7642 - val_loss: 2.8881\n",
      "Epoch 864/1000\n",
      " - 97s - loss: 2.7164 - val_loss: 3.0133\n",
      "Epoch 865/1000\n",
      " - 98s - loss: 2.7703 - val_loss: 2.7463\n",
      "Epoch 866/1000\n",
      " - 97s - loss: 2.8436 - val_loss: 2.9779\n",
      "Epoch 867/1000\n",
      " - 97s - loss: 2.8931 - val_loss: 2.8153\n",
      "Epoch 868/1000\n",
      " - 97s - loss: 2.9145 - val_loss: 2.8257\n",
      "Epoch 869/1000\n",
      " - 97s - loss: 2.9579 - val_loss: 3.0101\n",
      "Epoch 870/1000\n",
      " - 97s - loss: 2.7346 - val_loss: 2.7270\n",
      "Epoch 871/1000\n",
      " - 97s - loss: 2.8266 - val_loss: 2.6861\n",
      "Epoch 872/1000\n",
      " - 97s - loss: 2.9846 - val_loss: 2.9431\n",
      "Epoch 873/1000\n",
      " - 97s - loss: 2.9990 - val_loss: 2.6258\n",
      "Epoch 874/1000\n",
      " - 97s - loss: 2.8302 - val_loss: 2.7865\n",
      "Epoch 875/1000\n",
      " - 98s - loss: 2.5994 - val_loss: 2.6780\n",
      "Epoch 876/1000\n",
      " - 97s - loss: 2.9780 - val_loss: 3.0317\n",
      "Epoch 877/1000\n",
      " - 97s - loss: 3.0419 - val_loss: 2.5654\n",
      "Epoch 878/1000\n",
      " - 97s - loss: 3.1075 - val_loss: 3.0301\n",
      "Epoch 879/1000\n",
      " - 97s - loss: 2.8917 - val_loss: 2.9751\n",
      "Epoch 880/1000\n",
      " - 97s - loss: 2.7983 - val_loss: 2.8063\n",
      "Epoch 881/1000\n",
      " - 97s - loss: 2.7893 - val_loss: 2.9465\n",
      "Epoch 882/1000\n",
      " - 97s - loss: 2.8088 - val_loss: 2.6392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 883/1000\n",
      " - 97s - loss: 2.7984 - val_loss: 2.9896\n",
      "Epoch 884/1000\n",
      " - 98s - loss: 2.7222 - val_loss: 2.7175\n",
      "Epoch 885/1000\n",
      " - 97s - loss: 2.6134 - val_loss: 2.6087\n",
      "Epoch 886/1000\n",
      " - 98s - loss: 2.9789 - val_loss: 2.9717\n",
      "Epoch 887/1000\n",
      " - 98s - loss: 2.8086 - val_loss: 2.7997\n",
      "Epoch 888/1000\n",
      " - 98s - loss: 2.6106 - val_loss: 2.8658\n",
      "Epoch 889/1000\n",
      " - 97s - loss: 2.5722 - val_loss: 2.7079\n",
      "Epoch 890/1000\n",
      " - 98s - loss: 2.8376 - val_loss: 3.0870\n",
      "Epoch 891/1000\n",
      " - 97s - loss: 2.7181 - val_loss: 2.9593\n",
      "Epoch 892/1000\n",
      " - 98s - loss: 3.0166 - val_loss: 2.8092\n",
      "Epoch 893/1000\n",
      " - 97s - loss: 2.7090 - val_loss: 2.8541\n",
      "Epoch 894/1000\n",
      " - 97s - loss: 2.7169 - val_loss: 3.2789\n",
      "Epoch 895/1000\n",
      " - 97s - loss: 2.9465 - val_loss: 2.7592\n",
      "Epoch 896/1000\n",
      " - 97s - loss: 2.9352 - val_loss: 2.7480\n",
      "Epoch 897/1000\n",
      " - 98s - loss: 2.5769 - val_loss: 2.9617\n",
      "Epoch 898/1000\n",
      " - 97s - loss: 2.6750 - val_loss: 2.5827\n",
      "Epoch 899/1000\n",
      " - 98s - loss: 2.8778 - val_loss: 3.2797\n",
      "Epoch 900/1000\n",
      " - 97s - loss: 2.8694 - val_loss: 2.2931\n",
      "Epoch 901/1000\n",
      " - 98s - loss: 3.0722 - val_loss: 2.3678\n",
      "Epoch 902/1000\n",
      " - 97s - loss: 2.7163 - val_loss: 3.3288\n",
      "Epoch 903/1000\n",
      " - 97s - loss: 2.6567 - val_loss: 2.2036\n",
      "Epoch 904/1000\n",
      " - 97s - loss: 2.6227 - val_loss: 2.9595\n",
      "Epoch 905/1000\n",
      " - 97s - loss: 2.4879 - val_loss: 2.8421\n",
      "Epoch 906/1000\n",
      " - 98s - loss: 2.5599 - val_loss: 2.6464\n",
      "Epoch 907/1000\n",
      " - 97s - loss: 2.6416 - val_loss: 2.9248\n",
      "Epoch 908/1000\n",
      " - 98s - loss: 2.7940 - val_loss: 2.8485\n",
      "Epoch 909/1000\n",
      " - 97s - loss: 2.5092 - val_loss: 2.7106\n",
      "Epoch 910/1000\n",
      " - 97s - loss: 2.7535 - val_loss: 2.9610\n",
      "Epoch 911/1000\n",
      " - 97s - loss: 2.7638 - val_loss: 3.2649\n",
      "Epoch 912/1000\n",
      " - 97s - loss: 2.7899 - val_loss: 2.4996\n",
      "Epoch 913/1000\n",
      " - 97s - loss: 2.7972 - val_loss: 2.7627\n",
      "Epoch 914/1000\n",
      " - 97s - loss: 2.5251 - val_loss: 3.1104\n",
      "Epoch 915/1000\n",
      " - 98s - loss: 2.4542 - val_loss: 2.9488\n",
      "Epoch 916/1000\n",
      " - 97s - loss: 2.7388 - val_loss: 3.1515\n",
      "Epoch 917/1000\n",
      " - 97s - loss: 2.5040 - val_loss: 2.6709\n",
      "Epoch 918/1000\n",
      " - 97s - loss: 2.9965 - val_loss: 2.8584\n",
      "Epoch 919/1000\n",
      " - 98s - loss: 2.5149 - val_loss: 2.9479\n",
      "Epoch 920/1000\n",
      " - 97s - loss: 2.6267 - val_loss: 3.0253\n",
      "Epoch 921/1000\n",
      " - 98s - loss: 2.6317 - val_loss: 2.6109\n",
      "Epoch 922/1000\n",
      " - 96s - loss: 2.6104 - val_loss: 2.6017\n",
      "Epoch 923/1000\n",
      " - 97s - loss: 2.5707 - val_loss: 2.9602\n",
      "Epoch 924/1000\n",
      " - 97s - loss: 2.4371 - val_loss: 2.7154\n",
      "Epoch 925/1000\n",
      " - 97s - loss: 2.8682 - val_loss: 2.9200\n",
      "Epoch 926/1000\n",
      " - 97s - loss: 3.0941 - val_loss: 2.7528\n",
      "Epoch 927/1000\n",
      " - 98s - loss: 2.6522 - val_loss: 2.8668\n",
      "Epoch 928/1000\n",
      " - 97s - loss: 2.6535 - val_loss: 2.6795\n",
      "Epoch 929/1000\n",
      " - 98s - loss: 2.6900 - val_loss: 2.6734\n",
      "Epoch 930/1000\n",
      " - 97s - loss: 2.5893 - val_loss: 3.0230\n",
      "Epoch 931/1000\n",
      " - 98s - loss: 2.5677 - val_loss: 2.5843\n",
      "Epoch 932/1000\n",
      " - 97s - loss: 2.5618 - val_loss: 3.0968\n",
      "Epoch 933/1000\n",
      " - 97s - loss: 2.7285 - val_loss: 2.9370\n",
      "Epoch 934/1000\n",
      " - 97s - loss: 2.7836 - val_loss: 2.7606\n",
      "Epoch 935/1000\n",
      " - 97s - loss: 2.7448 - val_loss: 2.5987\n",
      "Epoch 936/1000\n",
      " - 97s - loss: 2.4851 - val_loss: 2.7240\n",
      "Epoch 937/1000\n",
      " - 97s - loss: 2.7225 - val_loss: 3.1202\n",
      "Epoch 938/1000\n",
      " - 97s - loss: 2.5489 - val_loss: 3.1601\n",
      "Epoch 939/1000\n",
      " - 97s - loss: 2.5726 - val_loss: 2.7178\n",
      "Epoch 940/1000\n",
      " - 97s - loss: 2.9130 - val_loss: 2.9441\n",
      "Epoch 941/1000\n",
      " - 97s - loss: 2.6699 - val_loss: 2.7653\n",
      "Epoch 942/1000\n",
      " - 97s - loss: 2.4828 - val_loss: 2.6947\n",
      "Epoch 943/1000\n",
      " - 97s - loss: 2.9049 - val_loss: 2.7379\n",
      "Epoch 944/1000\n",
      " - 97s - loss: 2.5184 - val_loss: 3.0255\n",
      "Epoch 945/1000\n",
      " - 97s - loss: 2.6699 - val_loss: 2.4625\n",
      "Epoch 946/1000\n",
      " - 96s - loss: 2.5963 - val_loss: 2.8806\n",
      "Epoch 947/1000\n",
      " - 97s - loss: 2.7736 - val_loss: 3.2052\n",
      "Epoch 948/1000\n",
      " - 97s - loss: 2.7043 - val_loss: 2.9001\n",
      "Epoch 949/1000\n",
      " - 97s - loss: 2.4886 - val_loss: 2.5328\n",
      "Epoch 950/1000\n",
      " - 97s - loss: 2.5768 - val_loss: 2.8367\n",
      "Epoch 951/1000\n",
      " - 97s - loss: 2.8114 - val_loss: 2.4782\n",
      "Epoch 952/1000\n",
      " - 97s - loss: 2.7325 - val_loss: 2.8530\n",
      "Epoch 953/1000\n",
      " - 97s - loss: 2.6230 - val_loss: 2.8517\n",
      "Epoch 954/1000\n",
      " - 97s - loss: 2.9491 - val_loss: 2.6444\n",
      "Epoch 955/1000\n",
      " - 97s - loss: 2.5750 - val_loss: 2.8007\n",
      "Epoch 956/1000\n",
      " - 98s - loss: 2.7103 - val_loss: 2.7212\n",
      "Epoch 957/1000\n",
      " - 97s - loss: 2.5411 - val_loss: 2.7035\n",
      "Epoch 958/1000\n",
      " - 97s - loss: 2.5713 - val_loss: 2.4618\n",
      "Epoch 959/1000\n",
      " - 97s - loss: 2.5354 - val_loss: 2.8004\n",
      "Epoch 960/1000\n",
      " - 97s - loss: 2.5990 - val_loss: 3.1462\n",
      "Epoch 961/1000\n",
      " - 97s - loss: 2.5117 - val_loss: 2.5172\n",
      "Epoch 962/1000\n",
      " - 97s - loss: 2.6345 - val_loss: 2.8807\n",
      "Epoch 963/1000\n",
      " - 97s - loss: 2.5976 - val_loss: 2.6870\n",
      "Epoch 964/1000\n",
      " - 97s - loss: 2.7576 - val_loss: 2.8614\n",
      "Epoch 965/1000\n",
      " - 97s - loss: 2.6349 - val_loss: 2.5729\n",
      "Epoch 966/1000\n",
      " - 97s - loss: 2.5536 - val_loss: 2.7309\n",
      "Epoch 967/1000\n",
      " - 97s - loss: 2.6181 - val_loss: 3.0084\n",
      "Epoch 968/1000\n",
      " - 97s - loss: 2.9690 - val_loss: 2.6475\n",
      "Epoch 969/1000\n",
      " - 98s - loss: 2.5296 - val_loss: 2.5855\n",
      "Epoch 970/1000\n",
      " - 97s - loss: 2.7021 - val_loss: 2.8037\n",
      "Epoch 971/1000\n",
      " - 98s - loss: 2.8819 - val_loss: 2.5746\n",
      "Epoch 972/1000\n",
      " - 97s - loss: 2.8280 - val_loss: 2.9332\n",
      "Epoch 973/1000\n",
      " - 97s - loss: 2.6495 - val_loss: 2.7724\n",
      "Epoch 974/1000\n",
      " - 97s - loss: 2.6477 - val_loss: 2.6240\n",
      "Epoch 975/1000\n",
      " - 97s - loss: 2.7417 - val_loss: 2.6683\n",
      "Epoch 976/1000\n",
      " - 97s - loss: 2.4315 - val_loss: 3.1689\n",
      "Epoch 977/1000\n",
      " - 97s - loss: 2.6751 - val_loss: 2.8468\n",
      "Epoch 978/1000\n",
      " - 97s - loss: 2.6585 - val_loss: 3.2962\n",
      "Epoch 979/1000\n",
      " - 96s - loss: 2.7228 - val_loss: 2.6931\n",
      "Epoch 980/1000\n",
      " - 98s - loss: 2.6031 - val_loss: 2.7769\n",
      "Epoch 981/1000\n",
      " - 97s - loss: 2.6197 - val_loss: 2.5828\n",
      "Epoch 982/1000\n",
      " - 97s - loss: 2.7505 - val_loss: 2.7324\n",
      "Epoch 983/1000\n",
      " - 97s - loss: 2.5275 - val_loss: 3.2430\n",
      "Epoch 984/1000\n",
      " - 97s - loss: 2.5540 - val_loss: 2.7621\n",
      "Epoch 985/1000\n",
      " - 98s - loss: 2.5135 - val_loss: 2.8437\n",
      "Epoch 986/1000\n",
      " - 97s - loss: 2.9772 - val_loss: 2.8359\n",
      "Epoch 987/1000\n",
      " - 97s - loss: 2.6534 - val_loss: 2.6230\n",
      "Epoch 988/1000\n",
      " - 97s - loss: 2.5837 - val_loss: 2.3905\n",
      "Epoch 989/1000\n",
      " - 97s - loss: 2.6036 - val_loss: 2.8832\n",
      "Epoch 990/1000\n",
      " - 97s - loss: 2.7478 - val_loss: 2.8669\n",
      "Epoch 991/1000\n",
      " - 97s - loss: 2.4960 - val_loss: 2.5019\n",
      "Epoch 992/1000\n",
      " - 97s - loss: 2.7859 - val_loss: 3.0244\n",
      "Epoch 993/1000\n",
      " - 98s - loss: 2.5389 - val_loss: 2.1728\n",
      "Epoch 994/1000\n",
      " - 97s - loss: 2.5039 - val_loss: 2.4300\n",
      "Epoch 995/1000\n",
      " - 97s - loss: 2.9207 - val_loss: 2.5723\n",
      "Epoch 996/1000\n",
      " - 97s - loss: 2.6238 - val_loss: 2.7674\n",
      "Epoch 997/1000\n",
      " - 98s - loss: 2.3270 - val_loss: 2.8594\n",
      "Epoch 998/1000\n",
      " - 97s - loss: 2.5287 - val_loss: 2.8808\n",
      "Epoch 999/1000\n",
      " - 97s - loss: 2.4847 - val_loss: 2.4700\n",
      "Epoch 1000/1000\n",
      " - 97s - loss: 2.5473 - val_loss: 3.1656\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = triplet_model.fit_generator(train_generator, steps_per_epoch=67, epochs=1000, \n",
    "                                      validation_data=test_generator, validation_steps=50, \n",
    "                                      verbose=2, callbacks=callbacks)\n",
    "\n",
    "base_model.save(path + '/facenet-model.h5')\n",
    "pickle.dump(history.history, open(path + '/facenet-history.p', 'wb'))\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training process\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.plot(train_loss, label='Training Loss')\n",
    "ax.plot(val_loss, label='Validation Loss')\n",
    "ax.set_title('Loss vs. Epochs', fontsize=16)\n",
    "ax.set_xlabel('Epochs', fontsize=14)\n",
    "ax.set_ylabel('Loss', fontsize=14)\n",
    "ax.legend(fontsize=14)\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
